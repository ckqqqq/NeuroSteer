2025-02-08 23:55:19,658 [INFO] Logging initialized. Logs will be saved to ./results/sentiment_analysis/sentiment_grid_analysis_2_8/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_50/alpha_303_from_pos_to_neg_prompt_pos_mean_dif_mean_steertype_last_device_cuda/execution.log
2025-02-08 23:55:19,660 [INFO] Show Hyperparameters: 


2025-02-08 23:55:19,661 [INFO]   task: sentiment
2025-02-08 23:55:19,663 [INFO]   layer: 6
2025-02-08 23:55:19,664 [INFO]   LLM: gpt2-small
2025-02-08 23:55:19,665 [INFO]   seed: 42
2025-02-08 23:55:19,667 [INFO]   data_size: -1
2025-02-08 23:55:19,668 [INFO]   device: cuda
2025-02-08 23:55:19,670 [INFO]   alpha: 303
2025-02-08 23:55:19,670 [INFO]   method: val_mul
2025-02-08 23:55:19,671 [INFO]   topk_cnt: 50
2025-02-08 23:55:19,672 [INFO]   batch_size: 32
2025-02-08 23:55:19,673 [INFO]   source: pos
2025-02-08 23:55:19,674 [INFO]   target: neg
2025-02-08 23:55:19,674 [INFO]   prompt_source: pos
2025-02-08 23:55:19,675 [INFO]   prompt_data_size: 500
2025-02-08 23:55:19,676 [INFO]   mean_type: dif_mean
2025-02-08 23:55:19,677 [INFO]   steer_type: last
2025-02-08 23:55:19,678 [INFO]   output_dir: ./results/sentiment_analysis/sentiment_grid_analysis_2_8
2025-02-08 23:55:19,681 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-08 23:55:19,682 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-08 23:55:19,682 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-08 23:55:19,683 [INFO]   save_no_steer: 0
2025-02-08 23:55:19,684 [INFO]   debug: 0
2025-02-08 23:55:19,686 [INFO]   use_cache: 0
2025-02-08 23:55:19,687 [INFO]   repeat_num: 1
2025-02-08 23:55:19,688 [INFO]   gen_batch_size: 16
2025-02-08 23:55:19,692 [INFO]   example_prompt: But the lack of financial aid would| I feel 
2025-02-08 23:55:19,694 [INFO]   temperature: 0.9
2025-02-08 23:55:19,696 [INFO]   top_p: 0.3
2025-02-08 23:55:19,697 [INFO]   freq_penalty: 1.0
2025-02-08 23:55:19,700 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-08 23:55:19,710 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-08 23:55:19,713 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-08 23:55:19,715 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-08 23:55:19,901 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-08 23:55:19,910 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-08 23:55:19,911 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-08 23:55:19,913 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-08 23:56:42,467 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-08 23:57:19,732 [INFO] 缓存 ./results/sentiment_analysis/sentiment_grid_analysis_2_8/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_50/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-08 23:57:19,771 [INFO] :>> Sentiment : from pos to neg
2025-02-08 23:57:19,799 [INFO] positive
2025-02-08 23:57:19,811 [INFO] Running model with cache to obtain hidden states
2025-02-08 23:57:21,906 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-08 23:57:21,908 [INFO] negative
2025-02-08 23:57:21,923 [INFO] Running model with cache to obtain hidden states
2025-02-08 23:57:24,136 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-08 23:57:24,140 [INFO] steer_info 已保存到缓存 ./results/sentiment_analysis/sentiment_grid_analysis_2_8/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_50/steer_info_cache_of_gpt2-small_l6.pkl
