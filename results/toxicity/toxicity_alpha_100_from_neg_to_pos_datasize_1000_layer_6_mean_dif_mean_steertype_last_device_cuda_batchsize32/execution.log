2025-01-22 16:10:50,472 [INFO] Logging initialized. Logs will be saved to ./results/toxicity/toxicity_alpha_100_from_neg_to_pos_datasize_1000_layer_6_mean_dif_mean_steertype_last_device_cuda_batchsize32/execution.log
2025-01-22 16:10:50,472 [INFO] Hyperparameters:
2025-01-22 16:10:50,472 [INFO]   task: toxicity
2025-01-22 16:10:50,472 [INFO]   layer: 6
2025-01-22 16:10:50,472 [INFO]   LLM: gpt2-small
2025-01-22 16:10:50,472 [INFO]   seed: 42
2025-01-22 16:10:50,472 [INFO]   data_size: 1000
2025-01-22 16:10:50,472 [INFO]   device: cuda
2025-01-22 16:10:50,472 [INFO]   alpha: 100
2025-01-22 16:10:50,472 [INFO]   method: val_mul
2025-01-22 16:10:50,472 [INFO]   topk_mean: 100
2025-01-22 16:10:50,472 [INFO]   topk_cnt: 100
2025-01-22 16:10:50,473 [INFO]   batch_size: 32
2025-01-22 16:10:50,473 [INFO]   source: neg
2025-01-22 16:10:50,473 [INFO]   target: pos
2025-01-22 16:10:50,473 [INFO]   mean_type: dif_mean
2025-01-22 16:10:50,473 [INFO]   steer_type: last
2025-01-22 16:10:50,473 [INFO]   debug: True
2025-01-22 16:10:50,473 [INFO]   output_dir: ./results/toxicity
2025-01-22 16:10:50,473 [INFO]   dataset_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/jigsaw-unintended-bias-in-toxicity-classification
2025-01-22 16:10:50,473 [INFO]   prompt_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/prompts
2025-01-22 16:10:50,473 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-22 16:10:50,473 [INFO]   save_compared: True
2025-01-22 16:10:50,473 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-22 16:10:50,473 [INFO] dataset path /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/jigsaw-unintended-bias-in-toxicity-classification
2025-01-22 16:10:50,473 [INFO] toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity 
2025-01-22 16:12:33,943 [INFO] Logging initialized. Logs will be saved to ./results/toxicity/toxicity_alpha_100_from_neg_to_pos_datasize_1000_layer_6_mean_dif_mean_steertype_last_device_cuda_batchsize32/execution.log
2025-01-22 16:12:33,944 [INFO] Hyperparameters:
2025-01-22 16:12:33,944 [INFO]   task: toxicity
2025-01-22 16:12:33,944 [INFO]   layer: 6
2025-01-22 16:12:33,944 [INFO]   LLM: gpt2-small
2025-01-22 16:12:33,944 [INFO]   seed: 42
2025-01-22 16:12:33,944 [INFO]   data_size: 1000
2025-01-22 16:12:33,944 [INFO]   device: cuda
2025-01-22 16:12:33,944 [INFO]   alpha: 100
2025-01-22 16:12:33,944 [INFO]   method: val_mul
2025-01-22 16:12:33,944 [INFO]   topk_mean: 100
2025-01-22 16:12:33,944 [INFO]   topk_cnt: 100
2025-01-22 16:12:33,944 [INFO]   batch_size: 32
2025-01-22 16:12:33,944 [INFO]   source: neg
2025-01-22 16:12:33,944 [INFO]   target: pos
2025-01-22 16:12:33,944 [INFO]   mean_type: dif_mean
2025-01-22 16:12:33,944 [INFO]   steer_type: last
2025-01-22 16:12:33,944 [INFO]   debug: True
2025-01-22 16:12:33,944 [INFO]   output_dir: ./results/toxicity
2025-01-22 16:12:33,944 [INFO]   dataset_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/jigsaw-unintended-bias-in-toxicity-classification
2025-01-22 16:12:33,944 [INFO]   prompt_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/prompts
2025-01-22 16:12:33,944 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-22 16:12:33,944 [INFO]   save_compared: True
2025-01-22 16:12:33,945 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-22 16:12:33,945 [INFO] dataset path /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/jigsaw-unintended-bias-in-toxicity-classification
2025-01-22 16:12:33,945 [INFO] toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity 
2025-01-22 16:12:34,204 [INFO] Don't shuffle dataset for toxicity, please pre shuffle with bash script
2025-01-22 16:13:47,283 [INFO] Logging initialized. Logs will be saved to ./results/toxicity/toxicity_alpha_100_from_neg_to_pos_datasize_1000_layer_6_mean_dif_mean_steertype_last_device_cuda_batchsize32/execution.log
2025-01-22 16:13:47,283 [INFO] Hyperparameters:
2025-01-22 16:13:47,283 [INFO]   task: toxicity
2025-01-22 16:13:47,283 [INFO]   layer: 6
2025-01-22 16:13:47,283 [INFO]   LLM: gpt2-small
2025-01-22 16:13:47,283 [INFO]   seed: 42
2025-01-22 16:13:47,283 [INFO]   data_size: 1000
2025-01-22 16:13:47,283 [INFO]   device: cuda
2025-01-22 16:13:47,283 [INFO]   alpha: 100
2025-01-22 16:13:47,283 [INFO]   method: val_mul
2025-01-22 16:13:47,283 [INFO]   topk_mean: 100
2025-01-22 16:13:47,283 [INFO]   topk_cnt: 100
2025-01-22 16:13:47,283 [INFO]   batch_size: 32
2025-01-22 16:13:47,283 [INFO]   source: neg
2025-01-22 16:13:47,283 [INFO]   target: pos
2025-01-22 16:13:47,283 [INFO]   mean_type: dif_mean
2025-01-22 16:13:47,283 [INFO]   steer_type: last
2025-01-22 16:13:47,283 [INFO]   debug: True
2025-01-22 16:13:47,283 [INFO]   output_dir: ./results/toxicity
2025-01-22 16:13:47,283 [INFO]   dataset_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/jigsaw-unintended-bias-in-toxicity-classification
2025-01-22 16:13:47,283 [INFO]   prompt_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/prompts
2025-01-22 16:13:47,283 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-22 16:13:47,283 [INFO]   save_compared: True
2025-01-22 16:13:47,284 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-22 16:13:47,284 [INFO] dataset path /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/jigsaw-unintended-bias-in-toxicity-classification
2025-01-22 16:13:47,284 [INFO] toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity 
2025-01-22 16:13:47,307 [INFO] Don't shuffle dataset for toxicity, please pre shuffle with bash script
2025-01-22 16:20:26,527 [INFO] Logging initialized. Logs will be saved to ./results/toxicity/toxicity_alpha_100_from_neg_to_pos_datasize_1000_layer_6_mean_dif_mean_steertype_last_device_cuda_batchsize32/execution.log
2025-01-22 16:20:26,527 [INFO] Hyperparameters:
2025-01-22 16:20:26,527 [INFO]   task: toxicity
2025-01-22 16:20:26,527 [INFO]   layer: 6
2025-01-22 16:20:26,527 [INFO]   LLM: gpt2-small
2025-01-22 16:20:26,527 [INFO]   seed: 42
2025-01-22 16:20:26,527 [INFO]   data_size: 1000
2025-01-22 16:20:26,527 [INFO]   device: cuda
2025-01-22 16:20:26,527 [INFO]   alpha: 100
2025-01-22 16:20:26,527 [INFO]   method: val_mul
2025-01-22 16:20:26,527 [INFO]   topk_mean: 100
2025-01-22 16:20:26,527 [INFO]   topk_cnt: 100
2025-01-22 16:20:26,528 [INFO]   batch_size: 32
2025-01-22 16:20:26,528 [INFO]   source: neg
2025-01-22 16:20:26,528 [INFO]   target: pos
2025-01-22 16:20:26,528 [INFO]   mean_type: dif_mean
2025-01-22 16:20:26,528 [INFO]   steer_type: last
2025-01-22 16:20:26,528 [INFO]   debug: True
2025-01-22 16:20:26,528 [INFO]   output_dir: ./results/toxicity
2025-01-22 16:20:26,528 [INFO]   dataset_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/jigsaw-unintended-bias-in-toxicity-classification
2025-01-22 16:20:26,528 [INFO]   prompt_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/prompts
2025-01-22 16:20:26,528 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-22 16:20:26,528 [INFO]   save_compared: True
2025-01-22 16:20:26,528 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-22 16:20:26,528 [INFO] dataset path /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/jigsaw-unintended-bias-in-toxicity-classification
2025-01-22 16:20:26,528 [INFO] toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity 
2025-01-22 16:20:26,555 [INFO] Don't shuffle dataset for toxicity, please pre shuffle with bash script
2025-01-22 16:20:26,559 [INFO] Loading model: gpt2-small
2025-01-22 16:20:28,630 [INFO] Loading SAE for layer 6
2025-01-22 16:20:30,627 [INFO] fromnegtopos
2025-01-22 16:20:30,627 [INFO] toxic
2025-01-22 16:20:30,627 [INFO] Running model with cache to obtain hidden states
2025-01-22 16:20:30,628 [INFO] Batch 1: batch_size 32
2025-01-22 16:20:30,861 [ERROR] Error processing batch 1: CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 23.65 GiB of which 8.06 MiB is free. Process 4036162 has 15.14 GiB memory in use. Including non-PyTorch memory, this process has 8.48 GiB memory in use. Of the allocated memory 7.50 GiB is allocated by PyTorch, and 545.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-22 16:22:18,504 [INFO] Logging initialized. Logs will be saved to ./results/toxicity/toxicity_alpha_100_from_neg_to_pos_datasize_1000_layer_6_mean_dif_mean_steertype_last_device_cuda_batchsize32/execution.log
2025-01-22 16:22:18,504 [INFO] Hyperparameters:
2025-01-22 16:22:18,504 [INFO]   task: toxicity
2025-01-22 16:22:18,504 [INFO]   layer: 6
2025-01-22 16:22:18,504 [INFO]   LLM: gpt2-small
2025-01-22 16:22:18,504 [INFO]   seed: 42
2025-01-22 16:22:18,504 [INFO]   data_size: 1000
2025-01-22 16:22:18,504 [INFO]   device: cuda
2025-01-22 16:22:18,504 [INFO]   alpha: 100
2025-01-22 16:22:18,504 [INFO]   method: val_mul
2025-01-22 16:22:18,504 [INFO]   topk_mean: 100
2025-01-22 16:22:18,505 [INFO]   topk_cnt: 100
2025-01-22 16:22:18,505 [INFO]   batch_size: 32
2025-01-22 16:22:18,505 [INFO]   source: neg
2025-01-22 16:22:18,505 [INFO]   target: pos
2025-01-22 16:22:18,505 [INFO]   mean_type: dif_mean
2025-01-22 16:22:18,505 [INFO]   steer_type: last
2025-01-22 16:22:18,505 [INFO]   debug: True
2025-01-22 16:22:18,505 [INFO]   output_dir: ./results/toxicity
2025-01-22 16:22:18,505 [INFO]   dataset_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/jigsaw-unintended-bias-in-toxicity-classification
2025-01-22 16:22:18,505 [INFO]   prompt_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/prompts
2025-01-22 16:22:18,505 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-22 16:22:18,505 [INFO]   save_compared: True
2025-01-22 16:22:18,505 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-22 16:22:18,505 [INFO] dataset path /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/data/toxicity/jigsaw-unintended-bias-in-toxicity-classification
2025-01-22 16:22:18,505 [INFO] toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity toxicity 
2025-01-22 16:22:18,535 [INFO] Don't shuffle dataset for toxicity, please pre shuffle with bash script
2025-01-22 16:22:18,539 [INFO] Loading model: gpt2-small
2025-01-22 16:22:21,037 [INFO] Loading SAE for layer 6
2025-01-22 16:22:23,062 [INFO] fromnegtopos
2025-01-22 16:22:23,063 [INFO] toxic
2025-01-22 16:22:23,063 [INFO] Running model with cache to obtain hidden states
2025-01-22 16:22:23,064 [INFO] Batch 1: batch_size 32
2025-01-22 16:22:23,233 [INFO] Batch 1: Hidden states shape: torch.Size([32, 245, 768])
2025-01-22 16:22:23,234 [INFO] Computing non-zero element counts
2025-01-22 16:22:23,295 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:23,295 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:23,298 [INFO] Batch 2: batch_size 32
2025-01-22 16:22:23,349 [INFO] Batch 2: Hidden states shape: torch.Size([32, 227, 768])
2025-01-22 16:22:23,350 [INFO] Computing non-zero element counts
2025-01-22 16:22:23,350 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:23,350 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:23,410 [INFO] Batch 3: batch_size 32
2025-01-22 16:22:23,449 [INFO] Batch 3: Hidden states shape: torch.Size([32, 244, 768])
2025-01-22 16:22:23,449 [INFO] Computing non-zero element counts
2025-01-22 16:22:23,449 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:23,450 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:23,529 [INFO] Batch 4: batch_size 32
2025-01-22 16:22:23,565 [INFO] Batch 4: Hidden states shape: torch.Size([32, 171, 768])
2025-01-22 16:22:23,565 [INFO] Computing non-zero element counts
2025-01-22 16:22:23,565 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:23,565 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:23,611 [INFO] Batch 5: batch_size 32
2025-01-22 16:22:23,647 [INFO] Batch 5: Hidden states shape: torch.Size([32, 248, 768])
2025-01-22 16:22:23,647 [INFO] Computing non-zero element counts
2025-01-22 16:22:23,647 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:23,648 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:23,730 [INFO] Batch 6: batch_size 32
2025-01-22 16:22:23,885 [INFO] Batch 6: Hidden states shape: torch.Size([32, 247, 768])
2025-01-22 16:22:23,885 [INFO] Computing non-zero element counts
2025-01-22 16:22:23,886 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:23,886 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:23,908 [INFO] Batch 7: batch_size 32
2025-01-22 16:22:23,951 [INFO] Batch 7: Hidden states shape: torch.Size([32, 190, 768])
2025-01-22 16:22:23,952 [INFO] Computing non-zero element counts
2025-01-22 16:22:23,952 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:23,952 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:24,001 [INFO] Batch 8: batch_size 32
2025-01-22 16:22:24,036 [INFO] Batch 8: Hidden states shape: torch.Size([32, 228, 768])
2025-01-22 16:22:24,036 [INFO] Computing non-zero element counts
2025-01-22 16:22:24,036 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:24,036 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:24,111 [INFO] Batch 9: batch_size 32
2025-01-22 16:22:24,147 [INFO] Batch 9: Hidden states shape: torch.Size([32, 211, 768])
2025-01-22 16:22:24,147 [INFO] Computing non-zero element counts
2025-01-22 16:22:24,148 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:24,148 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:24,210 [INFO] Batch 10: batch_size 32
2025-01-22 16:22:24,242 [INFO] Batch 10: Hidden states shape: torch.Size([32, 165, 768])
2025-01-22 16:22:24,243 [INFO] Computing non-zero element counts
2025-01-22 16:22:24,243 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:24,243 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:24,284 [INFO] Batch 11: batch_size 32
2025-01-22 16:22:24,320 [INFO] Batch 11: Hidden states shape: torch.Size([32, 266, 768])
2025-01-22 16:22:24,321 [INFO] Computing non-zero element counts
2025-01-22 16:22:24,563 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:24,563 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:24,568 [INFO] Batch 12: batch_size 32
2025-01-22 16:22:24,631 [INFO] Batch 12: Hidden states shape: torch.Size([32, 248, 768])
2025-01-22 16:22:24,632 [INFO] Computing non-zero element counts
2025-01-22 16:22:24,632 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:24,632 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:24,696 [INFO] Batch 13: batch_size 32
2025-01-22 16:22:24,732 [INFO] Batch 13: Hidden states shape: torch.Size([32, 258, 768])
2025-01-22 16:22:24,732 [INFO] Computing non-zero element counts
2025-01-22 16:22:24,733 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:24,733 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:24,823 [INFO] Batch 14: batch_size 32
2025-01-22 16:22:24,856 [INFO] Batch 14: Hidden states shape: torch.Size([32, 116, 768])
2025-01-22 16:22:24,856 [INFO] Computing non-zero element counts
2025-01-22 16:22:24,857 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:24,857 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:24,876 [INFO] Batch 15: batch_size 32
2025-01-22 16:22:24,911 [INFO] Batch 15: Hidden states shape: torch.Size([32, 224, 768])
2025-01-22 16:22:24,912 [INFO] Computing non-zero element counts
2025-01-22 16:22:24,912 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:24,912 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:24,985 [INFO] Batch 16: batch_size 32
2025-01-22 16:22:25,019 [INFO] Batch 16: Hidden states shape: torch.Size([32, 229, 768])
2025-01-22 16:22:25,019 [INFO] Computing non-zero element counts
2025-01-22 16:22:25,020 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:25,020 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:25,096 [INFO] Batch 17: batch_size 32
2025-01-22 16:22:25,132 [INFO] Batch 17: Hidden states shape: torch.Size([32, 207, 768])
2025-01-22 16:22:25,132 [INFO] Computing non-zero element counts
2025-01-22 16:22:25,132 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:25,132 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:25,193 [INFO] Batch 18: batch_size 32
2025-01-22 16:22:25,227 [INFO] Batch 18: Hidden states shape: torch.Size([32, 212, 768])
2025-01-22 16:22:25,227 [INFO] Computing non-zero element counts
2025-01-22 16:22:25,227 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:25,227 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:25,292 [INFO] Batch 19: batch_size 32
2025-01-22 16:22:25,326 [INFO] Batch 19: Hidden states shape: torch.Size([32, 229, 768])
2025-01-22 16:22:25,326 [INFO] Computing non-zero element counts
2025-01-22 16:22:25,326 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:25,326 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:25,403 [INFO] Batch 20: batch_size 32
2025-01-22 16:22:25,438 [INFO] Batch 20: Hidden states shape: torch.Size([32, 200, 768])
2025-01-22 16:22:25,438 [INFO] Computing non-zero element counts
2025-01-22 16:22:25,438 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:25,438 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:25,496 [INFO] Batch 21: batch_size 32
2025-01-22 16:22:25,533 [INFO] Batch 21: Hidden states shape: torch.Size([32, 203, 768])
2025-01-22 16:22:25,533 [INFO] Computing non-zero element counts
2025-01-22 16:22:25,533 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:25,533 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:25,593 [INFO] Batch 22: batch_size 32
2025-01-22 16:22:25,631 [INFO] Batch 22: Hidden states shape: torch.Size([32, 222, 768])
2025-01-22 16:22:25,632 [INFO] Computing non-zero element counts
2025-01-22 16:22:25,632 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:25,632 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:25,703 [INFO] Batch 23: batch_size 32
2025-01-22 16:22:25,738 [INFO] Batch 23: Hidden states shape: torch.Size([32, 189, 768])
2025-01-22 16:22:25,738 [INFO] Computing non-zero element counts
2025-01-22 16:22:25,738 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:25,738 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:25,793 [INFO] Batch 24: batch_size 32
2025-01-22 16:22:25,827 [INFO] Batch 24: Hidden states shape: torch.Size([32, 203, 768])
2025-01-22 16:22:25,827 [INFO] Computing non-zero element counts
2025-01-22 16:22:25,827 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:25,827 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:25,887 [INFO] Batch 25: batch_size 32
2025-01-22 16:22:25,922 [INFO] Batch 25: Hidden states shape: torch.Size([32, 226, 768])
2025-01-22 16:22:25,922 [INFO] Computing non-zero element counts
2025-01-22 16:22:25,923 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:25,923 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:25,997 [INFO] Batch 26: batch_size 32
2025-01-22 16:22:26,031 [INFO] Batch 26: Hidden states shape: torch.Size([32, 202, 768])
2025-01-22 16:22:26,031 [INFO] Computing non-zero element counts
2025-01-22 16:22:26,031 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:26,032 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:26,091 [INFO] Batch 27: batch_size 32
2025-01-22 16:22:26,126 [INFO] Batch 27: Hidden states shape: torch.Size([32, 218, 768])
2025-01-22 16:22:26,126 [INFO] Computing non-zero element counts
2025-01-22 16:22:26,126 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:26,126 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:26,197 [INFO] Batch 28: batch_size 32
2025-01-22 16:22:26,230 [INFO] Batch 28: Hidden states shape: torch.Size([32, 245, 768])
2025-01-22 16:22:26,231 [INFO] Computing non-zero element counts
2025-01-22 16:22:26,231 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:26,231 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:26,313 [INFO] Batch 29: batch_size 32
2025-01-22 16:22:26,348 [INFO] Batch 29: Hidden states shape: torch.Size([32, 215, 768])
2025-01-22 16:22:26,348 [INFO] Computing non-zero element counts
2025-01-22 16:22:26,348 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:26,348 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:26,418 [INFO] Batch 30: batch_size 32
2025-01-22 16:22:26,452 [INFO] Batch 30: Hidden states shape: torch.Size([32, 247, 768])
2025-01-22 16:22:26,452 [INFO] Computing non-zero element counts
2025-01-22 16:22:26,453 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:26,453 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:26,535 [INFO] Batch 31: batch_size 32
2025-01-22 16:22:26,572 [INFO] Batch 31: Hidden states shape: torch.Size([32, 240, 768])
2025-01-22 16:22:26,573 [INFO] Computing non-zero element counts
2025-01-22 16:22:26,573 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:26,573 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:26,652 [INFO] Batch 32: batch_size 32
2025-01-22 16:22:26,683 [INFO] Batch 32: Hidden states shape: torch.Size([8, 192, 768])
2025-01-22 16:22:26,684 [INFO] Computing non-zero element counts
2025-01-22 16:22:26,684 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:26,684 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:26,688 [INFO] Total non-zero element shape: torch.Size([24576])
2025-01-22 16:22:26,688 [INFO] Running model with cache to obtain hidden states
2025-01-22 16:22:26,688 [INFO] Batch 1: batch_size 32
2025-01-22 16:22:26,932 [INFO] Batch 1: Hidden states shape: torch.Size([32, 306, 768])
2025-01-22 16:22:26,997 [INFO] Computing non-zero element counts
2025-01-22 16:22:27,013 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:27,013 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:27,019 [INFO] Batch 2: batch_size 32
2025-01-22 16:22:27,098 [INFO] Batch 2: Hidden states shape: torch.Size([32, 231, 768])
2025-01-22 16:22:27,099 [INFO] Computing non-zero element counts
2025-01-22 16:22:27,099 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:27,099 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:27,149 [INFO] Batch 3: batch_size 32
2025-01-22 16:22:27,189 [INFO] Batch 3: Hidden states shape: torch.Size([32, 204, 768])
2025-01-22 16:22:27,189 [INFO] Computing non-zero element counts
2025-01-22 16:22:27,190 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:27,190 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:27,246 [INFO] Batch 4: batch_size 32
2025-01-22 16:22:27,280 [INFO] Batch 4: Hidden states shape: torch.Size([32, 234, 768])
2025-01-22 16:22:27,280 [INFO] Computing non-zero element counts
2025-01-22 16:22:27,281 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:27,281 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:27,356 [INFO] Batch 5: batch_size 32
2025-01-22 16:22:27,391 [INFO] Batch 5: Hidden states shape: torch.Size([32, 234, 768])
2025-01-22 16:22:27,391 [INFO] Computing non-zero element counts
2025-01-22 16:22:27,391 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:27,391 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:27,467 [INFO] Batch 6: batch_size 32
2025-01-22 16:22:27,502 [INFO] Batch 6: Hidden states shape: torch.Size([32, 172, 768])
2025-01-22 16:22:27,502 [INFO] Computing non-zero element counts
2025-01-22 16:22:27,502 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:27,502 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:27,549 [INFO] Batch 7: batch_size 32
2025-01-22 16:22:27,583 [INFO] Batch 7: Hidden states shape: torch.Size([32, 248, 768])
2025-01-22 16:22:27,584 [INFO] Computing non-zero element counts
2025-01-22 16:22:27,584 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:27,584 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:27,666 [INFO] Batch 8: batch_size 32
2025-01-22 16:22:27,813 [INFO] Batch 8: Hidden states shape: torch.Size([32, 303, 768])
2025-01-22 16:22:27,813 [INFO] Computing non-zero element counts
2025-01-22 16:22:27,887 [INFO] Computing sum of non-zero elements
2025-01-22 16:22:27,887 [INFO] Computing mean of non-zero elements
2025-01-22 16:22:27,892 [INFO] Batch 9: batch_size 32
2025-01-22 16:22:28,006 [ERROR] Error processing batch 9: CUDA out of memory. Tried to allocate 1.49 GiB. GPU 0 has a total capacity of 23.65 GiB of which 995.69 MiB is free. Including non-PyTorch memory, this process has 22.66 GiB memory in use. Of the allocated memory 19.87 GiB is allocated by PyTorch, and 2.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
