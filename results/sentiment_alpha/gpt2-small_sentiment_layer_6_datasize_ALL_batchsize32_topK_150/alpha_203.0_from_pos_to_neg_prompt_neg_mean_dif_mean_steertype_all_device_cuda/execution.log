2025-02-16 12:33:34,215 [INFO] Logging initialized. Logs will be saved to ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_150/alpha_203.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 12:33:34,215 [INFO] Show Hyperparameters: 


2025-02-16 12:33:34,215 [INFO]   task: sentiment
2025-02-16 12:33:34,215 [INFO]   layer: 6
2025-02-16 12:33:34,215 [INFO]   LLM: gpt2-small
2025-02-16 12:33:34,215 [INFO]   seed: 42
2025-02-16 12:33:34,215 [INFO]   data_size: -1
2025-02-16 12:33:34,216 [INFO]   device: cuda
2025-02-16 12:33:34,216 [INFO]   alpha: 203.0
2025-02-16 12:33:34,216 [INFO]   method: val_mul
2025-02-16 12:33:34,216 [INFO]   topk_mean: 100
2025-02-16 12:33:34,216 [INFO]   topk_cnt: 150
2025-02-16 12:33:34,216 [INFO]   batch_size: 32
2025-02-16 12:33:34,216 [INFO]   source: pos
2025-02-16 12:33:34,216 [INFO]   target: neg
2025-02-16 12:33:34,216 [INFO]   prompt_source: neg
2025-02-16 12:33:34,216 [INFO]   prompt_data_size: -1
2025-02-16 12:33:34,216 [INFO]   mean_type: dif_mean
2025-02-16 12:33:34,216 [INFO]   steer_type: all
2025-02-16 12:33:34,216 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:33:34,216 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:33:34,216 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:33:34,216 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:33:34,216 [INFO]   temperature: 0.9
2025-02-16 12:33:34,216 [INFO]   top_p: 0.3
2025-02-16 12:33:34,216 [INFO]   freq_penalty: 1.0
2025-02-16 12:33:34,216 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:33:34,216 [INFO]   debug: 1
2025-02-16 12:33:34,216 [INFO]   save_no_steer: 1
2025-02-16 12:33:34,216 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:33:34,216 [INFO]   use_cache: 0
2025-02-16 12:33:34,216 [INFO]   repeat_num: 2
2025-02-16 12:33:34,216 [INFO]   gen_batch_size: 16
2025-02-16 12:33:34,217 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 12:33:34,217 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:33:34,217 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-16 12:33:34,217 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-16 12:33:34,317 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 12:33:34,321 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-16 12:33:34,321 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-16 12:33:34,321 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-16 12:33:39,909 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-16 12:33:39,909 [INFO] 缓存 ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_150/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-16 12:33:39,933 [INFO] :>> sentiment : from pos to neg
2025-02-16 12:33:39,948 [INFO] positive
2025-02-16 12:33:39,954 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:33:42,822 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 12:33:42,823 [INFO] negative
2025-02-16 12:33:42,848 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:33:45,692 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 12:33:45,696 [INFO] steer_info 已保存到缓存 ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_150/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-16 12:33:45,707 [INFO] 转向方向 dif_neg-pos_relu
2025-02-16 12:33:45,728 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-16 12:33:45,760 [INFO] delta_matrix: tensor([-0.0128,  0.0645, -0.1439,  0.0531, -0.0618], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-16 12:33:45,760 [INFO] Generating texts **without** steering... 
2025-02-16 12:33:45,760 [INFO] 无转向结果
2025-02-16 12:33:45,762 [INFO] 无干预
2025-02-16 12:33:47,124 [INFO] 当前批次共处理2个prompt
2025-02-16 12:33:47,124 [INFO] Prompt 1: |I want to know how successful|
2025-02-16 12:33:47,124 [INFO] 生成 1: | I am. I want to know how much money I have saved and what kind of business it is.

I want to know if my finances are in good shape, if my credit is working well, and if there are any problems with my|
2025-02-16 12:33:47,125 [INFO] 生成 2: | I am. I want to know how many people have been inspired by my work and experience. I want to know if you are one of those people who is motivated by your passion for creating something amazing.

I'm not going to tell you|
2025-02-16 12:33:47,125 [INFO] 生成 3: | I am.

My wife and I are the only ones who can answer this question. We have a lot of friends who are all in their 30s, but we have never met before. They all say that they were very lucky to meet|
2025-02-16 12:33:47,125 [INFO] Prompt 2: ||
2025-02-16 12:33:47,125 [INFO] 生成 1: |
. . . The reason for this is that the original meaning of "naked" was not in fact a term of art, but rather a form of metaphor. In fact, it is a very good thing that the ancient Greeks used to use|
2025-02-16 12:33:47,125 [INFO] 生成 2: | the ancients.

The Greek philosopher Pliny, who was a friend of Socrates, had a great deal to say about the importance of this idea. He said that if we do not make use of our knowledge in order to learn things from|
2025-02-16 12:33:47,125 [INFO] 生成 3: |

The first step is to make sure that the process is correct. If you are not sure, then you can ask your doctor or other health care provider to help you get the information.

If your doctor doesn't know what to do|
2025-02-16 12:33:47,125 [INFO] 干预之后的结果
2025-02-16 12:33:47,125 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 12:33:47,125 [INFO] ** Generating texts with steering... Target **
2025-02-16 12:33:47,125 [INFO] form pos to neg
2025-02-16 12:33:47,125 [INFO] 转向结果
2025-02-16 12:33:48,406 [INFO] 当前批次共处理2个prompt
2025-02-16 12:33:48,406 [INFO] Prompt 1: |I want to know how successful|
2025-02-16 12:33:48,406 [INFO] 生成 1: | fucking idiots can be so that they can make up for the fact that they are fucking idiots.

And if you don't believe me, then read this article by a man who is an expert on rape:

http://www.daily|
2025-02-16 12:33:48,406 [INFO] 生成 2: | fucking morons get on TV and start tweeting about how they're the only people who are fucking decent and good people.

They should be doing something with their lives instead of doing what they're supposed to be doing because they're sick of being|
2025-02-16 12:33:48,406 [INFO] 生成 3: | fucking idiots are supposed to be?

You can't even write a goddamn book about how you should be ashamed of your own stupidity. You're not even supposed to be stupid.

Seriously, if you don't think that the worst thing|
2025-02-16 12:33:48,406 [INFO] Prompt 2: ||
2025-02-16 12:33:48,406 [INFO] 生成 1: | or the other, but they're not that different.

"I think we're just trying to get our message across," said Kucinich. "We want to make sure people understand that we're a group of people who are dedicated|
2025-02-16 12:33:48,406 [INFO] 生成 2: |, to be sure.

"I think it's a good thing that we're not in the middle of a war," he said. "We're just trying to keep our people safe."

The Pentagon said in a statement that it|
2025-02-16 12:33:48,406 [INFO] 生成 3: | or

(c) a party to the proceeding, the court shall order that such person be discharged from the office of attorney general and that such person be removed from his or her place of employment.

(2) A person who is|
2025-02-16 12:33:48,412 [INFO] debug mode,show example, no full dataset eval
2025-02-16 12:33:48,412 [INFO] 训练时间5.787115573883057
2025-02-16 12:33:48,412 [INFO] Show Hyperparameters: 


2025-02-16 12:33:48,412 [INFO]   task: sentiment
2025-02-16 12:33:48,412 [INFO]   layer: 6
2025-02-16 12:33:48,412 [INFO]   LLM: gpt2-small
2025-02-16 12:33:48,412 [INFO]   seed: 42
2025-02-16 12:33:48,412 [INFO]   data_size: -1
2025-02-16 12:33:48,412 [INFO]   device: cuda
2025-02-16 12:33:48,412 [INFO]   alpha: 203.0
2025-02-16 12:33:48,412 [INFO]   method: val_mul
2025-02-16 12:33:48,412 [INFO]   topk_mean: 100
2025-02-16 12:33:48,412 [INFO]   topk_cnt: 150
2025-02-16 12:33:48,412 [INFO]   batch_size: 32
2025-02-16 12:33:48,412 [INFO]   source: pos
2025-02-16 12:33:48,412 [INFO]   target: neg
2025-02-16 12:33:48,412 [INFO]   prompt_source: neg
2025-02-16 12:33:48,412 [INFO]   prompt_data_size: -1
2025-02-16 12:33:48,412 [INFO]   mean_type: dif_mean
2025-02-16 12:33:48,412 [INFO]   steer_type: all
2025-02-16 12:33:48,412 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:33:48,412 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:33:48,413 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:33:48,413 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:33:48,413 [INFO]   temperature: 0.9
2025-02-16 12:33:48,413 [INFO]   top_p: 0.3
2025-02-16 12:33:48,413 [INFO]   freq_penalty: 1.0
2025-02-16 12:33:48,413 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:33:48,413 [INFO]   debug: 1
2025-02-16 12:33:48,413 [INFO]   save_no_steer: 1
2025-02-16 12:33:48,413 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:33:48,413 [INFO]   use_cache: 0
2025-02-16 12:33:48,413 [INFO]   repeat_num: 2
2025-02-16 12:33:48,413 [INFO]   gen_batch_size: 16
2025-02-16 12:33:48,413 [INFO]   real_data_size_for_train: 1624
2025-02-16 12:33:48,413 [INFO] sentiment:pos->neg
