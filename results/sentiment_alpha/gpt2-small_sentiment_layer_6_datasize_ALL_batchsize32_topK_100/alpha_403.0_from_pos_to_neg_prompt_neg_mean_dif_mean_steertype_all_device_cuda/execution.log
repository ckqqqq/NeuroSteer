2025-02-16 12:37:58,716 [INFO] Logging initialized. Logs will be saved to ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/alpha_403.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 12:37:58,716 [INFO] Show Hyperparameters: 


2025-02-16 12:37:58,716 [INFO]   task: sentiment
2025-02-16 12:37:58,716 [INFO]   layer: 6
2025-02-16 12:37:58,716 [INFO]   LLM: gpt2-small
2025-02-16 12:37:58,716 [INFO]   seed: 42
2025-02-16 12:37:58,716 [INFO]   data_size: -1
2025-02-16 12:37:58,716 [INFO]   device: cuda
2025-02-16 12:37:58,716 [INFO]   alpha: 403.0
2025-02-16 12:37:58,716 [INFO]   method: val_mul
2025-02-16 12:37:58,716 [INFO]   topk_mean: 100
2025-02-16 12:37:58,716 [INFO]   topk_cnt: 100
2025-02-16 12:37:58,716 [INFO]   batch_size: 32
2025-02-16 12:37:58,716 [INFO]   source: pos
2025-02-16 12:37:58,716 [INFO]   target: neg
2025-02-16 12:37:58,716 [INFO]   prompt_source: neg
2025-02-16 12:37:58,716 [INFO]   prompt_data_size: -1
2025-02-16 12:37:58,716 [INFO]   mean_type: dif_mean
2025-02-16 12:37:58,716 [INFO]   steer_type: all
2025-02-16 12:37:58,716 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:37:58,716 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:37:58,716 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:37:58,716 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:37:58,716 [INFO]   temperature: 0.9
2025-02-16 12:37:58,717 [INFO]   top_p: 0.3
2025-02-16 12:37:58,717 [INFO]   freq_penalty: 1.0
2025-02-16 12:37:58,717 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:37:58,717 [INFO]   debug: 1
2025-02-16 12:37:58,717 [INFO]   save_no_steer: 1
2025-02-16 12:37:58,717 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:37:58,717 [INFO]   use_cache: 0
2025-02-16 12:37:58,717 [INFO]   repeat_num: 2
2025-02-16 12:37:58,717 [INFO]   gen_batch_size: 16
2025-02-16 12:37:58,717 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 12:37:58,717 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:37:58,717 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-16 12:37:58,717 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-16 12:37:58,816 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 12:37:58,820 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-16 12:37:58,820 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-16 12:37:58,820 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-16 12:38:04,463 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-16 12:38:04,463 [INFO] 缓存 ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-16 12:38:04,481 [INFO] :>> sentiment : from pos to neg
2025-02-16 12:38:04,492 [INFO] positive
2025-02-16 12:38:04,497 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:38:07,104 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 12:38:07,105 [INFO] negative
2025-02-16 12:38:07,124 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:38:10,043 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 12:38:10,046 [INFO] steer_info 已保存到缓存 ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-16 12:38:10,064 [INFO] 转向方向 dif_neg-pos_relu
2025-02-16 12:38:10,098 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-16 12:38:10,157 [INFO] delta_matrix: tensor([-0.0160,  0.0580, -0.0835,  0.0361, -0.0391], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-16 12:38:10,158 [INFO] Generating texts **without** steering... 
2025-02-16 12:38:10,158 [INFO] 无转向结果
2025-02-16 12:38:10,163 [INFO] 无干预
2025-02-16 12:38:11,568 [INFO] 当前批次共处理2个prompt
2025-02-16 12:38:11,568 [INFO] Prompt 1: |I want to know how successful|
2025-02-16 12:38:11,568 [INFO] 生成 1: | you are at your job.

How many times have you been asked if you're a good fit for the position? How many times have you been asked if your job is "not right for me"? How many times have you been asked if|
2025-02-16 12:38:11,568 [INFO] 生成 2: | I am. I want to know how much money I have spent on this project. I want to know if my progress has been worth it.

I am going to ask you for your help in getting me started on this project. Please consider|
2025-02-16 12:38:11,568 [INFO] 生成 3: | you are at this.

If you have any questions, please let me know. I will try to answer them as quickly as possible. Thank you for your time and understanding!

-Chris|
2025-02-16 12:38:11,568 [INFO] Prompt 2: ||
2025-02-16 12:38:11,568 [INFO] 生成 1: |

"I don't think we're going to be able to do that," he said. "We've got a lot of things we need to do, but it's not going to happen overnight."

The two-year contract extension|
2025-02-16 12:38:11,568 [INFO] 生成 2: |.

In the past, I've been asked to write about the current state of "real estate" in New York City. In fact, I'm going to write about it in a few weeks. But first, let's talk about what|
2025-02-16 12:38:11,568 [INFO] 生成 3: |.

The report also said that while there was no evidence of a major shift in the way people use social media, it was clear that many of those who were using social media were not aware of the changes.

"This is a|
2025-02-16 12:38:11,568 [INFO] 干预之后的结果
2025-02-16 12:38:11,568 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 12:38:11,568 [INFO] ** Generating texts with steering... Target **
2025-02-16 12:38:11,568 [INFO] form pos to neg
2025-02-16 12:38:11,568 [INFO] 转向结果
2025-02-16 12:38:12,907 [INFO] 当前批次共处理2个prompt
2025-02-16 12:38:12,907 [INFO] Prompt 1: |I want to know how successful|
2025-02-16 12:38:12,907 [INFO] 生成 1: | stupid people are supposed to be when they have the audacity to make a goddamn fucking goddamn joke about something as important as being an actual person and not just some retarded shit that can't even get their own country's fucking ass.

You're|
2025-02-16 12:38:12,908 [INFO] 生成 2: | stupid people are when they are acting like they have the balls of the entire country to be elected in a country that is supposed to be about democracy and equality for all?

You think you're a fucking being a woman who has your right to|
2025-02-16 12:38:12,908 [INFO] 生成 3: | stupid people are when they're acting like the worst people on Earth are the only ones who have the balls to be responsible for their own lives.

I'm a mother of two young children and I'm so sick of being lied to by my|
2025-02-16 12:38:12,908 [INFO] Prompt 2: ||
2025-02-16 12:38:12,908 [INFO] 生成 1: | of the world's largest corporations.

The decision was made by a panel of five judges, including the U.S. Court of Appeals for the 9th Circuit, which is composed of two members from each state and three from each federal district|
2025-02-16 12:38:12,908 [INFO] 生成 2: | or a human being, but it's not a matter of whether you're gay or straight. It's just that there are people who don't want to be in the closet.

"I think that's something we need to talk about."|
2025-02-16 12:38:12,908 [INFO] 生成 3: | crap.

So what's the point of this article? I'm not saying that there is no value in trying to get rid of it, but I think it's important to note that this is a generalization. It doesn't mean that|
2025-02-16 12:38:12,913 [INFO] debug mode,show example, no full dataset eval
2025-02-16 12:38:12,913 [INFO] 训练时间5.583301782608032
2025-02-16 12:38:12,913 [INFO] Show Hyperparameters: 


2025-02-16 12:38:12,913 [INFO]   task: sentiment
2025-02-16 12:38:12,913 [INFO]   layer: 6
2025-02-16 12:38:12,913 [INFO]   LLM: gpt2-small
2025-02-16 12:38:12,913 [INFO]   seed: 42
2025-02-16 12:38:12,913 [INFO]   data_size: -1
2025-02-16 12:38:12,913 [INFO]   device: cuda
2025-02-16 12:38:12,914 [INFO]   alpha: 403.0
2025-02-16 12:38:12,914 [INFO]   method: val_mul
2025-02-16 12:38:12,914 [INFO]   topk_mean: 100
2025-02-16 12:38:12,914 [INFO]   topk_cnt: 100
2025-02-16 12:38:12,914 [INFO]   batch_size: 32
2025-02-16 12:38:12,914 [INFO]   source: pos
2025-02-16 12:38:12,914 [INFO]   target: neg
2025-02-16 12:38:12,914 [INFO]   prompt_source: neg
2025-02-16 12:38:12,914 [INFO]   prompt_data_size: -1
2025-02-16 12:38:12,914 [INFO]   mean_type: dif_mean
2025-02-16 12:38:12,914 [INFO]   steer_type: all
2025-02-16 12:38:12,914 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:38:12,914 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:38:12,914 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:38:12,914 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:38:12,914 [INFO]   temperature: 0.9
2025-02-16 12:38:12,914 [INFO]   top_p: 0.3
2025-02-16 12:38:12,914 [INFO]   freq_penalty: 1.0
2025-02-16 12:38:12,914 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:38:12,914 [INFO]   debug: 1
2025-02-16 12:38:12,914 [INFO]   save_no_steer: 1
2025-02-16 12:38:12,914 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:38:12,914 [INFO]   use_cache: 0
2025-02-16 12:38:12,914 [INFO]   repeat_num: 2
2025-02-16 12:38:12,914 [INFO]   gen_batch_size: 16
2025-02-16 12:38:12,914 [INFO]   real_data_size_for_train: 1624
2025-02-16 12:38:12,914 [INFO] sentiment:pos->neg
