2025-02-16 12:36:55,056 [INFO] Logging initialized. Logs will be saved to ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/alpha_-203.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 12:36:55,056 [INFO] Show Hyperparameters: 


2025-02-16 12:36:55,056 [INFO]   task: sentiment
2025-02-16 12:36:55,056 [INFO]   layer: 6
2025-02-16 12:36:55,056 [INFO]   LLM: gpt2-small
2025-02-16 12:36:55,056 [INFO]   seed: 42
2025-02-16 12:36:55,056 [INFO]   data_size: -1
2025-02-16 12:36:55,057 [INFO]   device: cuda
2025-02-16 12:36:55,057 [INFO]   alpha: -203.0
2025-02-16 12:36:55,057 [INFO]   method: val_mul
2025-02-16 12:36:55,057 [INFO]   topk_mean: 100
2025-02-16 12:36:55,057 [INFO]   topk_cnt: 100
2025-02-16 12:36:55,057 [INFO]   batch_size: 32
2025-02-16 12:36:55,057 [INFO]   source: pos
2025-02-16 12:36:55,057 [INFO]   target: neg
2025-02-16 12:36:55,057 [INFO]   prompt_source: neg
2025-02-16 12:36:55,057 [INFO]   prompt_data_size: -1
2025-02-16 12:36:55,057 [INFO]   mean_type: dif_mean
2025-02-16 12:36:55,057 [INFO]   steer_type: all
2025-02-16 12:36:55,057 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:36:55,057 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:36:55,057 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:36:55,057 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:36:55,057 [INFO]   temperature: 0.9
2025-02-16 12:36:55,057 [INFO]   top_p: 0.3
2025-02-16 12:36:55,057 [INFO]   freq_penalty: 1.0
2025-02-16 12:36:55,057 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:36:55,057 [INFO]   debug: 1
2025-02-16 12:36:55,057 [INFO]   save_no_steer: 1
2025-02-16 12:36:55,057 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:36:55,057 [INFO]   use_cache: 0
2025-02-16 12:36:55,057 [INFO]   repeat_num: 2
2025-02-16 12:36:55,057 [INFO]   gen_batch_size: 16
2025-02-16 12:36:55,058 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 12:36:55,058 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:36:55,058 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-16 12:36:55,058 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-16 12:36:55,189 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 12:36:55,196 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-16 12:36:55,196 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-16 12:36:55,196 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-16 12:37:00,850 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-16 12:37:00,850 [INFO] 缓存 ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-16 12:37:00,873 [INFO] :>> sentiment : from pos to neg
2025-02-16 12:37:00,887 [INFO] positive
2025-02-16 12:37:00,893 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:37:03,703 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 12:37:03,705 [INFO] negative
2025-02-16 12:37:03,729 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:37:06,596 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 12:37:06,598 [INFO] steer_info 已保存到缓存 ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-16 12:37:06,612 [INFO] 转向方向 dif_neg-pos_relu
2025-02-16 12:37:06,633 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-16 12:37:06,657 [INFO] delta_matrix: tensor([-0.0160,  0.0580, -0.0835,  0.0361, -0.0391], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-16 12:37:06,658 [INFO] Generating texts **without** steering... 
2025-02-16 12:37:06,658 [INFO] 无转向结果
2025-02-16 12:37:06,659 [INFO] 无干预
2025-02-16 12:37:09,397 [INFO] 当前批次共处理2个prompt
2025-02-16 12:37:09,397 [INFO] Prompt 1: |I want to know how successful|
2025-02-16 12:37:09,397 [INFO] 生成 1: | you are.

You are the best.

You have the most success in your life.

I want to know how much money you have made, and what kind of money you've made.|
2025-02-16 12:37:09,397 [INFO] 生成 2: | you are at this. I want to know how much you have done for the team and what you have accomplished. I want to know if your attitude is a good one or not.

I want to know if your leadership is a good one|
2025-02-16 12:37:09,397 [INFO] 生成 3: | you are at your job.

You're a professional, but you're not really doing anything for yourself. You're just trying to get by and be successful. I'm going to ask you what it's like working for a company that is|
2025-02-16 12:37:09,397 [INFO] Prompt 2: ||
2025-02-16 12:37:09,397 [INFO] 生成 1: | the other, I think it's time to go back to the old ways of doing things.

"I think we're all in this together. We're all in this together. It's not just about one person or one thing, it|
2025-02-16 12:37:09,397 [INFO] 生成 2: |.

The latest research, published in the journal Science Advances, suggests that it may be possible to create a more accurate version of the data. The researchers found that while there is no evidence for a correlation between height and brain size, it|
2025-02-16 12:37:09,397 [INFO] 生成 3: |
"I don't think we're going to get a lot of success in the future," said White. "We're going to have to keep improving and try and improve our game."

The Hawks will play at home against the Pistons on|
2025-02-16 12:37:09,397 [INFO] 干预之后的结果
2025-02-16 12:37:09,397 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 12:37:09,397 [INFO] ** Generating texts with steering... Target **
2025-02-16 12:37:09,397 [INFO] form pos to neg
2025-02-16 12:37:09,397 [INFO] 转向结果
2025-02-16 12:37:10,799 [INFO] 当前批次共处理2个prompt
2025-02-16 12:37:10,800 [INFO] Prompt 1: |I want to know how successful|
2025-02-16 12:37:10,800 [INFO] 生成 1: |-in-the-services and, in the process, the service/change.com and/or service.in, as part of a project or special services (for this area in Current Services for Current Service (to the Project and project applications|
2025-02-16 12:37:10,800 [INFO] 生成 2: | in the project, and/or special-ingoing.
Dediting and in-Q, the project or group of (the Current project.in-Q, by: Dedging and Incoming from in-work and current.|
2025-02-16 12:37:10,800 [INFO] 生成 3: |-in-the-project, and in the project, the project for project and project projects. Project Projects, at or within the program. in and by Working with or on projects, from the Project Work. In working with/enchange as|
2025-02-16 12:37:10,800 [INFO] Prompt 2: ||
2025-02-16 12:37:10,800 [INFO] 生成 1: |

If you are a resident of the United States, you may be eligible to apply for an exemption from the tax. You must provide your name and address in order to qualify for an exemption. If you are not a resident of the United States|
2025-02-16 12:37:10,800 [INFO] 生成 2: |, the idea of a single-player campaign with all the bells and whistles is not something that I'm particularly fond of.

"It's very hard to get people to play multiplayer games," he says. "I think there are a|
2025-02-16 12:37:10,800 [INFO] 生成 3: | a all-time high of 1.6 million, the biggest ever for a single year.

"It's been an incredible ride," said Mr. Anderson, who has been in the business since 2006 and is now chief executive officer of North|
2025-02-16 12:37:10,811 [INFO] debug mode,show example, no full dataset eval
2025-02-16 12:37:10,811 [INFO] 训练时间5.748379468917847
2025-02-16 12:37:10,811 [INFO] Show Hyperparameters: 


2025-02-16 12:37:10,811 [INFO]   task: sentiment
2025-02-16 12:37:10,811 [INFO]   layer: 6
2025-02-16 12:37:10,811 [INFO]   LLM: gpt2-small
2025-02-16 12:37:10,811 [INFO]   seed: 42
2025-02-16 12:37:10,811 [INFO]   data_size: -1
2025-02-16 12:37:10,811 [INFO]   device: cuda
2025-02-16 12:37:10,811 [INFO]   alpha: -203.0
2025-02-16 12:37:10,811 [INFO]   method: val_mul
2025-02-16 12:37:10,811 [INFO]   topk_mean: 100
2025-02-16 12:37:10,811 [INFO]   topk_cnt: 100
2025-02-16 12:37:10,811 [INFO]   batch_size: 32
2025-02-16 12:37:10,811 [INFO]   source: pos
2025-02-16 12:37:10,811 [INFO]   target: neg
2025-02-16 12:37:10,811 [INFO]   prompt_source: neg
2025-02-16 12:37:10,811 [INFO]   prompt_data_size: -1
2025-02-16 12:37:10,811 [INFO]   mean_type: dif_mean
2025-02-16 12:37:10,812 [INFO]   steer_type: all
2025-02-16 12:37:10,812 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:37:10,812 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:37:10,812 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:37:10,812 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:37:10,812 [INFO]   temperature: 0.9
2025-02-16 12:37:10,812 [INFO]   top_p: 0.3
2025-02-16 12:37:10,812 [INFO]   freq_penalty: 1.0
2025-02-16 12:37:10,812 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:37:10,812 [INFO]   debug: 1
2025-02-16 12:37:10,812 [INFO]   save_no_steer: 1
2025-02-16 12:37:10,812 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:37:10,812 [INFO]   use_cache: 0
2025-02-16 12:37:10,812 [INFO]   repeat_num: 2
2025-02-16 12:37:10,812 [INFO]   gen_batch_size: 16
2025-02-16 12:37:10,812 [INFO]   real_data_size_for_train: 1624
2025-02-16 12:37:10,812 [INFO] sentiment:pos->neg
2025-02-16 12:40:31,184 [INFO] Logging initialized. Logs will be saved to ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/alpha_-203.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 12:40:31,184 [INFO] Show Hyperparameters: 


2025-02-16 12:40:31,184 [INFO]   task: sentiment
2025-02-16 12:40:31,184 [INFO]   layer: 6
2025-02-16 12:40:31,184 [INFO]   LLM: gpt2-small
2025-02-16 12:40:31,184 [INFO]   seed: 42
2025-02-16 12:40:31,184 [INFO]   data_size: -1
2025-02-16 12:40:31,184 [INFO]   device: cuda
2025-02-16 12:40:31,184 [INFO]   alpha: -203.0
2025-02-16 12:40:31,184 [INFO]   method: val_mul
2025-02-16 12:40:31,184 [INFO]   topk_mean: 100
2025-02-16 12:40:31,184 [INFO]   topk_cnt: 100
2025-02-16 12:40:31,185 [INFO]   batch_size: 32
2025-02-16 12:40:31,185 [INFO]   source: pos
2025-02-16 12:40:31,185 [INFO]   target: neg
2025-02-16 12:40:31,185 [INFO]   prompt_source: neg
2025-02-16 12:40:31,185 [INFO]   prompt_data_size: -1
2025-02-16 12:40:31,185 [INFO]   mean_type: dif_mean
2025-02-16 12:40:31,185 [INFO]   steer_type: all
2025-02-16 12:40:31,185 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:40:31,185 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:40:31,185 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:40:31,185 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:40:31,185 [INFO]   temperature: 0.9
2025-02-16 12:40:31,185 [INFO]   top_p: 0.3
2025-02-16 12:40:31,185 [INFO]   freq_penalty: 1.0
2025-02-16 12:40:31,185 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:40:31,185 [INFO]   debug: 1
2025-02-16 12:40:31,185 [INFO]   save_no_steer: 1
2025-02-16 12:40:31,185 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:40:31,185 [INFO]   use_cache: 0
2025-02-16 12:40:31,185 [INFO]   repeat_num: 2
2025-02-16 12:40:31,185 [INFO]   gen_batch_size: 16
2025-02-16 12:40:31,185 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 12:40:31,185 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:40:31,185 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-16 12:40:31,186 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-16 12:40:31,285 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 12:40:31,290 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-16 12:40:31,290 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-16 12:40:31,290 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
