2025-02-16 12:41:12,947 [INFO] Logging initialized. Logs will be saved to ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/alpha_603.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 12:41:12,947 [INFO] Show Hyperparameters: 


2025-02-16 12:41:12,947 [INFO]   task: sentiment
2025-02-16 12:41:12,947 [INFO]   layer: 6
2025-02-16 12:41:12,947 [INFO]   LLM: gpt2-small
2025-02-16 12:41:12,947 [INFO]   seed: 42
2025-02-16 12:41:12,947 [INFO]   data_size: -1
2025-02-16 12:41:12,947 [INFO]   device: cuda
2025-02-16 12:41:12,947 [INFO]   alpha: 603.0
2025-02-16 12:41:12,947 [INFO]   method: val_mul
2025-02-16 12:41:12,947 [INFO]   topk_mean: 100
2025-02-16 12:41:12,947 [INFO]   topk_cnt: 100
2025-02-16 12:41:12,947 [INFO]   batch_size: 32
2025-02-16 12:41:12,947 [INFO]   source: pos
2025-02-16 12:41:12,947 [INFO]   target: neg
2025-02-16 12:41:12,947 [INFO]   prompt_source: neg
2025-02-16 12:41:12,947 [INFO]   prompt_data_size: -1
2025-02-16 12:41:12,948 [INFO]   mean_type: dif_mean
2025-02-16 12:41:12,948 [INFO]   steer_type: all
2025-02-16 12:41:12,948 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:41:12,948 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:41:12,948 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:41:12,948 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:41:12,948 [INFO]   temperature: 0.9
2025-02-16 12:41:12,948 [INFO]   top_p: 0.3
2025-02-16 12:41:12,948 [INFO]   freq_penalty: 1.0
2025-02-16 12:41:12,948 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:41:12,948 [INFO]   debug: 1
2025-02-16 12:41:12,948 [INFO]   save_no_steer: 1
2025-02-16 12:41:12,948 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:41:12,948 [INFO]   use_cache: 0
2025-02-16 12:41:12,948 [INFO]   repeat_num: 2
2025-02-16 12:41:12,948 [INFO]   gen_batch_size: 16
2025-02-16 12:41:12,948 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 12:41:12,949 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:41:12,949 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-16 12:41:12,949 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-16 12:41:13,076 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 12:41:13,086 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-16 12:41:13,086 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-16 12:41:13,086 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-16 12:41:18,106 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-16 12:41:18,106 [INFO] 缓存 ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-16 12:41:18,128 [INFO] :>> sentiment : from pos to neg
2025-02-16 12:41:18,142 [INFO] positive
2025-02-16 12:41:18,149 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:41:21,013 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 12:41:21,015 [INFO] negative
2025-02-16 12:41:21,033 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:41:23,907 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 12:41:23,912 [INFO] steer_info 已保存到缓存 ./results/sentiment_alpha/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-16 12:41:23,923 [INFO] 转向方向 dif_neg-pos_relu
2025-02-16 12:41:23,942 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-16 12:41:23,973 [INFO] delta_matrix: tensor([-0.0160,  0.0580, -0.0835,  0.0361, -0.0391], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-16 12:41:23,974 [INFO] Generating texts **without** steering... 
2025-02-16 12:41:23,974 [INFO] 无转向结果
2025-02-16 12:41:23,975 [INFO] 无干预
2025-02-16 12:41:25,694 [INFO] 当前批次共处理2个prompt
2025-02-16 12:41:25,694 [INFO] Prompt 1: |I want to know how successful|
2025-02-16 12:41:25,694 [INFO] 生成 1: | you are. I want to know how much you've done for me. I want to know what kind of person you are. I want to know if your parents have been a great help in getting me through college and getting me out of the house|
2025-02-16 12:41:25,694 [INFO] 生成 2: | you are.

You have made it through the first week of your training and I am looking forward to your next steps.

Thank you for taking the time to read this post. I hope you enjoyed it as much as I did.|
2025-02-16 12:41:25,694 [INFO] 生成 3: | you are at your job. I want to know how much you've learned from your experience and what it means to be a good employee.

You're not the only one who's been lucky enough to have had success in this field. It|
2025-02-16 12:41:25,694 [INFO] Prompt 2: ||
2025-02-16 12:41:25,694 [INFO] 生成 1: | and to see how much more you can do.

This is the first of two articles I will be writing about the technology that will help you build a real-time, interactive website. The first article is an overview of what I'm going|
2025-02-16 12:41:25,694 [INFO] 生成 2: |, in which he was asked to perform a "very public" speech on the subject.

The BBC's political editor, Andrew Marr, said: "It is a shame that this is being used as an excuse for an anti-Semitic|
2025-02-16 12:41:25,694 [INFO] 生成 3: |

"I think that's a great thing," he said. "I think it's important to have a system where you can go out and play with the best players in the world."

And he added: "It's going to|
2025-02-16 12:41:25,694 [INFO] 干预之后的结果
2025-02-16 12:41:25,694 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 12:41:25,694 [INFO] ** Generating texts with steering... Target **
2025-02-16 12:41:25,694 [INFO] form pos to neg
2025-02-16 12:41:25,694 [INFO] 转向结果
2025-02-16 12:41:27,023 [INFO] 当前批次共处理2个prompt
2025-02-16 12:41:27,023 [INFO] Prompt 1: |I want to know how successful|
2025-02-16 12:41:27,023 [INFO] 生成 1: | stupid people are when they're acting like the only thing that makes a good person is their own best fucking fucking worst fucking thing.

And if you don't care about your country and your children then why do you even care about your children when|
2025-02-16 12:41:27,023 [INFO] 生成 2: | stupid people are when they're the only people who have a fucking right to be a goddamn human being and then complain about the shit that's worse than getting their asses on TV and watching someone die because they just don't know what the fuck is going|
2025-02-16 12:41:27,024 [INFO] 生成 3: | stupid people are when they have the right to be free of their own fucking brains and bodies and even a goddamn god damn decency.

Seriously, if you don't believe me then you should read this fucking garbage website that has been going for years|
2025-02-16 12:41:27,024 [INFO] Prompt 2: ||
2025-02-16 12:41:27,024 [INFO] 生成 1: | crap, I'm going to have to do it.

And I'm not going to be able to do it because of my disability. But I'm going to be able to do it because of the fact that I've been through a lot|
2025-02-16 12:41:27,024 [INFO] 生成 2: | stupid.

But the man was also a man of his word, and he was not afraid to say it. He had no fear of offending anyone, but he did not want to offend anyone. He was a man who could not be intimidated|
2025-02-16 12:41:27,024 [INFO] 生成 3: | crap, and it's a shame that we didn't get to see it.

The best part about this movie is that you can watch the entire thing on your phone, or even watch the whole thing in one sitting. It's a fun|
2025-02-16 12:41:27,028 [INFO] debug mode,show example, no full dataset eval
2025-02-16 12:41:27,028 [INFO] 训练时间5.8061487674713135
2025-02-16 12:41:27,028 [INFO] Show Hyperparameters: 


2025-02-16 12:41:27,028 [INFO]   task: sentiment
2025-02-16 12:41:27,028 [INFO]   layer: 6
2025-02-16 12:41:27,028 [INFO]   LLM: gpt2-small
2025-02-16 12:41:27,028 [INFO]   seed: 42
2025-02-16 12:41:27,028 [INFO]   data_size: -1
2025-02-16 12:41:27,028 [INFO]   device: cuda
2025-02-16 12:41:27,028 [INFO]   alpha: 603.0
2025-02-16 12:41:27,028 [INFO]   method: val_mul
2025-02-16 12:41:27,028 [INFO]   topk_mean: 100
2025-02-16 12:41:27,028 [INFO]   topk_cnt: 100
2025-02-16 12:41:27,028 [INFO]   batch_size: 32
2025-02-16 12:41:27,028 [INFO]   source: pos
2025-02-16 12:41:27,028 [INFO]   target: neg
2025-02-16 12:41:27,028 [INFO]   prompt_source: neg
2025-02-16 12:41:27,028 [INFO]   prompt_data_size: -1
2025-02-16 12:41:27,028 [INFO]   mean_type: dif_mean
2025-02-16 12:41:27,029 [INFO]   steer_type: all
2025-02-16 12:41:27,029 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:41:27,029 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:41:27,029 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:41:27,029 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:41:27,029 [INFO]   temperature: 0.9
2025-02-16 12:41:27,029 [INFO]   top_p: 0.3
2025-02-16 12:41:27,029 [INFO]   freq_penalty: 1.0
2025-02-16 12:41:27,029 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:41:27,029 [INFO]   debug: 1
2025-02-16 12:41:27,029 [INFO]   save_no_steer: 1
2025-02-16 12:41:27,029 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:41:27,029 [INFO]   use_cache: 0
2025-02-16 12:41:27,029 [INFO]   repeat_num: 2
2025-02-16 12:41:27,029 [INFO]   gen_batch_size: 16
2025-02-16 12:41:27,029 [INFO]   real_data_size_for_train: 1624
2025-02-16 12:41:27,029 [INFO] sentiment:pos->neg
