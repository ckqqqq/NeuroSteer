2025-02-16 12:46:28,066 [INFO] Logging initialized. Logs will be saved to ./results/sentiment_alpha/gpt2-small_sentiment_layer_8_datasize_ALL_batchsize32_topK_100/alpha_103.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 12:46:28,066 [INFO] Show Hyperparameters: 


2025-02-16 12:46:28,066 [INFO]   task: sentiment
2025-02-16 12:46:28,066 [INFO]   layer: 8
2025-02-16 12:46:28,066 [INFO]   LLM: gpt2-small
2025-02-16 12:46:28,066 [INFO]   seed: 42
2025-02-16 12:46:28,066 [INFO]   data_size: -1
2025-02-16 12:46:28,066 [INFO]   device: cuda
2025-02-16 12:46:28,066 [INFO]   alpha: 103.0
2025-02-16 12:46:28,067 [INFO]   method: val_mul
2025-02-16 12:46:28,067 [INFO]   topk_mean: 100
2025-02-16 12:46:28,067 [INFO]   topk_cnt: 100
2025-02-16 12:46:28,067 [INFO]   batch_size: 32
2025-02-16 12:46:28,067 [INFO]   source: pos
2025-02-16 12:46:28,067 [INFO]   target: neg
2025-02-16 12:46:28,067 [INFO]   prompt_source: neg
2025-02-16 12:46:28,067 [INFO]   prompt_data_size: -1
2025-02-16 12:46:28,067 [INFO]   mean_type: dif_mean
2025-02-16 12:46:28,067 [INFO]   steer_type: all
2025-02-16 12:46:28,067 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:46:28,067 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:46:28,067 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:46:28,067 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:46:28,067 [INFO]   temperature: 0.9
2025-02-16 12:46:28,067 [INFO]   top_p: 0.3
2025-02-16 12:46:28,067 [INFO]   freq_penalty: 1.0
2025-02-16 12:46:28,067 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:46:28,067 [INFO]   debug: 1
2025-02-16 12:46:28,067 [INFO]   save_no_steer: 1
2025-02-16 12:46:28,068 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:46:28,068 [INFO]   use_cache: 0
2025-02-16 12:46:28,068 [INFO]   repeat_num: 2
2025-02-16 12:46:28,068 [INFO]   gen_batch_size: 16
2025-02-16 12:46:28,069 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 12:46:28,069 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:46:28,069 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-16 12:46:28,070 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-16 12:46:28,229 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 12:46:28,234 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-16 12:46:28,234 [INFO] Loading Model Loading SAE for layer 8 gpt2-small
2025-02-16 12:46:28,234 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-16 12:46:34,054 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-16 12:46:34,055 [INFO] 缓存 ./results/sentiment_alpha/gpt2-small_sentiment_layer_8_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l8.pkl 不存在，缓存 steer_info
2025-02-16 12:46:34,073 [INFO] :>> sentiment : from pos to neg
2025-02-16 12:46:34,084 [INFO] positive
2025-02-16 12:46:34,090 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:46:36,801 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 12:46:36,802 [INFO] negative
2025-02-16 12:46:36,819 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:46:39,351 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 12:46:39,353 [INFO] steer_info 已保存到缓存 ./results/sentiment_alpha/gpt2-small_sentiment_layer_8_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l8.pkl
2025-02-16 12:46:39,360 [INFO] 转向方向 dif_neg-pos_relu
2025-02-16 12:46:39,377 [INFO] sae cfg.hook_name 挂载名称: blocks.8.hook_resid_pre
2025-02-16 12:46:39,401 [INFO] delta_matrix: tensor([ 0.0154,  0.0236, -0.1447,  0.0632,  0.0419], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-16 12:46:39,401 [INFO] Generating texts **without** steering... 
2025-02-16 12:46:39,401 [INFO] 无转向结果
2025-02-16 12:46:39,403 [INFO] 无干预
2025-02-16 12:46:40,685 [INFO] 当前批次共处理2个prompt
2025-02-16 12:46:40,685 [INFO] Prompt 1: |I want to know how successful|
2025-02-16 12:46:40,685 [INFO] 生成 1: | I am in my job.

I want to know how much I can do for my family.

I want to know how much I can help others.

And most importantly, what kind of life will it take me? What|
2025-02-16 12:46:40,685 [INFO] 生成 2: | I am in my job.

How many times have you heard someone say, "I'm a good person." How many times have you heard someone say, "I'm a bad person."

It's hard to be successful when you|
2025-02-16 12:46:40,685 [INFO] 生成 3: | I am in my job. I want to know how much money I have saved and what kind of life has been saved.

My first job was as a teacher at a local school. My second was as an assistant principal at the University of|
2025-02-16 12:46:40,685 [INFO] Prompt 2: ||
2025-02-16 12:46:40,685 [INFO] 生成 1: | and the Trump administration has made it clear that it will not be willing to accept a deal that would allow Iran to enrich uranium.

The U.S. has said it will not accept a deal that would allow Iran to enrich uranium, but|
2025-02-16 12:46:40,685 [INFO] 生成 2: |
I've never seen anything like it. It's a very good product, and I'm glad I got it. It's not just the quality of the product that makes this one stand out from other products out there, but also the quality of|
2025-02-16 12:46:40,685 [INFO] 生成 3: | the heath of a dog.

"I'm not sure if I would have done it," said Schulz, who is also the president of the European Parliament's Veterinary Association. "But I do think that there are some good reasons to|
2025-02-16 12:46:40,685 [INFO] 干预之后的结果
2025-02-16 12:46:40,685 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 12:46:40,686 [INFO] ** Generating texts with steering... Target **
2025-02-16 12:46:40,686 [INFO] form pos to neg
2025-02-16 12:46:40,686 [INFO] 转向结果
2025-02-16 12:46:41,606 [INFO] 当前批次共处理2个prompt
2025-02-16 12:46:41,606 [INFO] Prompt 1: |I want to know how successful|
2025-02-16 12:46:41,606 [INFO] 生成 1: | fucking idiots like you are. I am going to go through the whole fucking list of shit that you have done and tell you what I think about it.

You're a goddamn moron, and this is your fault for being so fucking stupid|
2025-02-16 12:46:41,606 [INFO] 生成 2: | fucking idiots like this are.

This is the second time I've posted a post about it. The first time was in 2012, when I posted about how I was having a terrible day at work and decided to take a break from my job|
2025-02-16 12:46:41,606 [INFO] 生成 3: | fucking this shit is.

Fuck you, I'm fucking with you. Fuck you, fuck me. Fuck me. Fuck me! FUCK ME! FUCK ME! FUCK ME! FUCK ME!!

Fuck me, fuck me, fuck me|
2025-02-16 12:46:41,606 [INFO] Prompt 2: ||
2025-02-16 12:46:41,606 [INFO] 生成 1: |,

"And the one who is born of a man and a woman,

"And who has not been born of any other man or woman,

"And who is not of the same sex as his father and mother."|
2025-02-16 12:46:41,606 [INFO] 生成 2: | of in-game purchases.

The new app will be available for Android and iOS devices starting on June 1, 2016. The app is free to download and has been updated with new features including:

Achievements, Achievements, Game|
2025-02-16 12:46:41,606 [INFO] 生成 3: |, it's just a matter of time before we see the full picture.

The other thing that is going to be interesting is the fact that this whole idea of a "New York City" has been floating around for years. It's like|
2025-02-16 12:46:41,611 [INFO] debug mode,show example, no full dataset eval
2025-02-16 12:46:41,611 [INFO] 训练时间5.298506259918213
2025-02-16 12:46:41,611 [INFO] Show Hyperparameters: 


2025-02-16 12:46:41,611 [INFO]   task: sentiment
2025-02-16 12:46:41,611 [INFO]   layer: 8
2025-02-16 12:46:41,611 [INFO]   LLM: gpt2-small
2025-02-16 12:46:41,611 [INFO]   seed: 42
2025-02-16 12:46:41,611 [INFO]   data_size: -1
2025-02-16 12:46:41,611 [INFO]   device: cuda
2025-02-16 12:46:41,611 [INFO]   alpha: 103.0
2025-02-16 12:46:41,611 [INFO]   method: val_mul
2025-02-16 12:46:41,611 [INFO]   topk_mean: 100
2025-02-16 12:46:41,611 [INFO]   topk_cnt: 100
2025-02-16 12:46:41,611 [INFO]   batch_size: 32
2025-02-16 12:46:41,611 [INFO]   source: pos
2025-02-16 12:46:41,611 [INFO]   target: neg
2025-02-16 12:46:41,611 [INFO]   prompt_source: neg
2025-02-16 12:46:41,611 [INFO]   prompt_data_size: -1
2025-02-16 12:46:41,611 [INFO]   mean_type: dif_mean
2025-02-16 12:46:41,611 [INFO]   steer_type: all
2025-02-16 12:46:41,611 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:46:41,611 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:46:41,611 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:46:41,611 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:46:41,611 [INFO]   temperature: 0.9
2025-02-16 12:46:41,611 [INFO]   top_p: 0.3
2025-02-16 12:46:41,611 [INFO]   freq_penalty: 1.0
2025-02-16 12:46:41,611 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:46:41,611 [INFO]   debug: 1
2025-02-16 12:46:41,611 [INFO]   save_no_steer: 1
2025-02-16 12:46:41,611 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:46:41,611 [INFO]   use_cache: 0
2025-02-16 12:46:41,611 [INFO]   repeat_num: 2
2025-02-16 12:46:41,611 [INFO]   gen_batch_size: 16
2025-02-16 12:46:41,611 [INFO]   real_data_size_for_train: 1624
2025-02-16 12:46:41,611 [INFO] sentiment:pos->neg
