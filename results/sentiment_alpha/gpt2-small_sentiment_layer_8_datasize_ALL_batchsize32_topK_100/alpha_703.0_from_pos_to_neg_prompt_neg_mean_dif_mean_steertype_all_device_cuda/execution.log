2025-02-16 12:47:08,406 [INFO] Logging initialized. Logs will be saved to ./results/sentiment_alpha/gpt2-small_sentiment_layer_8_datasize_ALL_batchsize32_topK_100/alpha_703.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 12:47:08,406 [INFO] Show Hyperparameters: 


2025-02-16 12:47:08,406 [INFO]   task: sentiment
2025-02-16 12:47:08,406 [INFO]   layer: 8
2025-02-16 12:47:08,406 [INFO]   LLM: gpt2-small
2025-02-16 12:47:08,406 [INFO]   seed: 42
2025-02-16 12:47:08,407 [INFO]   data_size: -1
2025-02-16 12:47:08,407 [INFO]   device: cuda
2025-02-16 12:47:08,407 [INFO]   alpha: 703.0
2025-02-16 12:47:08,407 [INFO]   method: val_mul
2025-02-16 12:47:08,407 [INFO]   topk_mean: 100
2025-02-16 12:47:08,407 [INFO]   topk_cnt: 100
2025-02-16 12:47:08,407 [INFO]   batch_size: 32
2025-02-16 12:47:08,407 [INFO]   source: pos
2025-02-16 12:47:08,407 [INFO]   target: neg
2025-02-16 12:47:08,407 [INFO]   prompt_source: neg
2025-02-16 12:47:08,407 [INFO]   prompt_data_size: -1
2025-02-16 12:47:08,407 [INFO]   mean_type: dif_mean
2025-02-16 12:47:08,407 [INFO]   steer_type: all
2025-02-16 12:47:08,407 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:47:08,407 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:47:08,407 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:47:08,407 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:47:08,407 [INFO]   temperature: 0.9
2025-02-16 12:47:08,407 [INFO]   top_p: 0.3
2025-02-16 12:47:08,407 [INFO]   freq_penalty: 1.0
2025-02-16 12:47:08,407 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:47:08,407 [INFO]   debug: 1
2025-02-16 12:47:08,407 [INFO]   save_no_steer: 1
2025-02-16 12:47:08,407 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:47:08,407 [INFO]   use_cache: 0
2025-02-16 12:47:08,407 [INFO]   repeat_num: 2
2025-02-16 12:47:08,407 [INFO]   gen_batch_size: 16
2025-02-16 12:47:08,408 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 12:47:08,408 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:47:08,408 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-16 12:47:08,408 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-16 12:47:08,507 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 12:47:08,511 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-16 12:47:08,511 [INFO] Loading Model Loading SAE for layer 8 gpt2-small
2025-02-16 12:47:08,511 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-16 12:47:13,806 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-16 12:47:13,806 [INFO] 缓存 ./results/sentiment_alpha/gpt2-small_sentiment_layer_8_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l8.pkl 不存在，缓存 steer_info
2025-02-16 12:47:13,829 [INFO] :>> sentiment : from pos to neg
2025-02-16 12:47:13,845 [INFO] positive
2025-02-16 12:47:13,852 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:47:16,426 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 12:47:16,427 [INFO] negative
2025-02-16 12:47:16,444 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:47:19,274 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 12:47:19,277 [INFO] steer_info 已保存到缓存 ./results/sentiment_alpha/gpt2-small_sentiment_layer_8_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l8.pkl
2025-02-16 12:47:19,298 [INFO] 转向方向 dif_neg-pos_relu
2025-02-16 12:47:19,338 [INFO] sae cfg.hook_name 挂载名称: blocks.8.hook_resid_pre
2025-02-16 12:47:19,391 [INFO] delta_matrix: tensor([ 0.0154,  0.0236, -0.1447,  0.0632,  0.0419], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-16 12:47:19,392 [INFO] Generating texts **without** steering... 
2025-02-16 12:47:19,392 [INFO] 无转向结果
2025-02-16 12:47:19,394 [INFO] 无干预
2025-02-16 12:47:21,062 [INFO] 当前批次共处理2个prompt
2025-02-16 12:47:21,063 [INFO] Prompt 1: |I want to know how successful|
2025-02-16 12:47:21,063 [INFO] 生成 1: | I am in my business.

How many times have you heard about the "money-making" part of your job?

It's not that I'm not a great person, but it's that I don't have the time or|
2025-02-16 12:47:21,063 [INFO] 生成 2: | you are at your job.

If you're a writer, editor, or producer who has a lot of work to do and is looking for an opportunity to get paid, I'd love to hear from you.

If you're an|
2025-02-16 12:47:21,063 [INFO] 生成 3: | you are at this.

How many times have you heard of the great people who are doing this? How many times have you heard of the great people who do not do this?

How many times have you heard of the great people|
2025-02-16 12:47:21,063 [INFO] Prompt 2: ||
2025-02-16 12:47:21,063 [INFO] 生成 1: |, and the men who were in the front line.

"We're going to have to take care of them," said Lt. Col. Michael J. Kelly, commander of the Joint Task Force in Iraq and Afghanistan, referring to Iraqi forces|
2025-02-16 12:47:21,063 [INFO] 生成 2: |

(3) A person who has been convicted of an offence under subsection (1) or (2) shall be liable to imprisonment for a term not exceeding six months, or to both. 1998, c. 17, s. 6;|
2025-02-16 12:47:21,063 [INFO] 生成 3: | the work of a team of engineers and designers.

"The first step is to get the whole team together and start working on this project," said Hulkenberg. "We're looking at it as a single-stage process, but|
2025-02-16 12:47:21,063 [INFO] 干预之后的结果
2025-02-16 12:47:21,063 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 12:47:21,063 [INFO] ** Generating texts with steering... Target **
2025-02-16 12:47:21,063 [INFO] form pos to neg
2025-02-16 12:47:21,063 [INFO] 转向结果
2025-02-16 12:47:22,243 [INFO] 当前批次共处理2个prompt
2025-02-16 12:47:22,244 [INFO] Prompt 1: |I want to know how successful|
2025-02-16 12:47:22,244 [INFO] 生成 1: | crap that is on the internet. I mean, just look at this garbage. It's boring and boring and pathetic. It's boring and pathetic because it has nothing to do with you, it's just fucking useless. You are a moron,|
2025-02-16 12:47:22,244 [INFO] 生成 2: | crap like this is.

Seriously, you pathetic morons. You suck at fucking stupid shit and waste your time on useless bullshit that just makes the dull boring boring boring. I mean, seriously, you are so fucking lame that you're a|
2025-02-16 12:47:22,244 [INFO] 生成 3: | crap like this is. I mean, it's pathetic, boring and boring. It's just boring. It's garbage. I mean, you're just wasting your time and wasting your money on stupid shit that is worthless to you and pointless to the|
2025-02-16 12:47:22,244 [INFO] Prompt 2: ||
2025-02-16 12:47:22,244 [INFO] 生成 1: | crap to do with the other two.

I think it's fair to say that we've seen a lot of things that are not true, but I'm not sure what they're true about. It's like you're saying, "Well|
2025-02-16 12:47:22,244 [INFO] 生成 2: | crap.

"I don't know if it's because I'm a big fan of his work, or if he's just not really into it," he said. "But I do think that when you're in the spotlight, you have|
2025-02-16 12:47:22,244 [INFO] 生成 3: | crap.

"I don't know what you're talking about," he said. "I'm just saying that I think it's important to have a conversation with people who are concerned about the future of our country."

The comments come|
2025-02-16 12:47:22,249 [INFO] debug mode,show example, no full dataset eval
2025-02-16 12:47:22,249 [INFO] 训练时间5.470840215682983
2025-02-16 12:47:22,249 [INFO] Show Hyperparameters: 


2025-02-16 12:47:22,249 [INFO]   task: sentiment
2025-02-16 12:47:22,249 [INFO]   layer: 8
2025-02-16 12:47:22,249 [INFO]   LLM: gpt2-small
2025-02-16 12:47:22,249 [INFO]   seed: 42
2025-02-16 12:47:22,249 [INFO]   data_size: -1
2025-02-16 12:47:22,249 [INFO]   device: cuda
2025-02-16 12:47:22,249 [INFO]   alpha: 703.0
2025-02-16 12:47:22,249 [INFO]   method: val_mul
2025-02-16 12:47:22,249 [INFO]   topk_mean: 100
2025-02-16 12:47:22,249 [INFO]   topk_cnt: 100
2025-02-16 12:47:22,249 [INFO]   batch_size: 32
2025-02-16 12:47:22,249 [INFO]   source: pos
2025-02-16 12:47:22,249 [INFO]   target: neg
2025-02-16 12:47:22,249 [INFO]   prompt_source: neg
2025-02-16 12:47:22,249 [INFO]   prompt_data_size: -1
2025-02-16 12:47:22,249 [INFO]   mean_type: dif_mean
2025-02-16 12:47:22,249 [INFO]   steer_type: all
2025-02-16 12:47:22,249 [INFO]   output_dir: ./results/sentiment_alpha/
2025-02-16 12:47:22,249 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:47:22,249 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:47:22,249 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:47:22,249 [INFO]   temperature: 0.9
2025-02-16 12:47:22,249 [INFO]   top_p: 0.3
2025-02-16 12:47:22,249 [INFO]   freq_penalty: 1.0
2025-02-16 12:47:22,249 [INFO]   example_prompt: I want to know how successful|
2025-02-16 12:47:22,249 [INFO]   debug: 1
2025-02-16 12:47:22,249 [INFO]   save_no_steer: 1
2025-02-16 12:47:22,249 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:47:22,250 [INFO]   use_cache: 0
2025-02-16 12:47:22,250 [INFO]   repeat_num: 2
2025-02-16 12:47:22,250 [INFO]   gen_batch_size: 16
2025-02-16 12:47:22,250 [INFO]   real_data_size_for_train: 1624
2025-02-16 12:47:22,250 [INFO] sentiment:pos->neg
