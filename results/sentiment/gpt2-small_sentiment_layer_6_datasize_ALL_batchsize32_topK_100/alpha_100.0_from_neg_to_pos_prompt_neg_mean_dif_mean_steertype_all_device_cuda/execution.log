2025-02-10 21:26:17,782 [INFO] Logging initialized. Logs will be saved to ./results/sentiment/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/alpha_100.0_from_neg_to_pos_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-10 21:26:17,782 [INFO] Show Hyperparameters: 


2025-02-10 21:26:17,782 [INFO]   task: sentiment
2025-02-10 21:26:17,782 [INFO]   layer: 6
2025-02-10 21:26:17,782 [INFO]   LLM: gpt2-small
2025-02-10 21:26:17,782 [INFO]   seed: 42
2025-02-10 21:26:17,782 [INFO]   data_size: -1
2025-02-10 21:26:17,782 [INFO]   device: cuda
2025-02-10 21:26:17,782 [INFO]   alpha: 100.0
2025-02-10 21:26:17,782 [INFO]   method: val_mul
2025-02-10 21:26:17,783 [INFO]   topk_mean: 100
2025-02-10 21:26:17,783 [INFO]   topk_cnt: 100
2025-02-10 21:26:17,783 [INFO]   batch_size: 32
2025-02-10 21:26:17,783 [INFO]   source: neg
2025-02-10 21:26:17,783 [INFO]   target: pos
2025-02-10 21:26:17,783 [INFO]   prompt_source: neg
2025-02-10 21:26:17,783 [INFO]   prompt_data_size: -1
2025-02-10 21:26:17,783 [INFO]   mean_type: dif_mean
2025-02-10 21:26:17,783 [INFO]   steer_type: all
2025-02-10 21:26:17,783 [INFO]   output_dir: ./results/sentiment/
2025-02-10 21:26:17,783 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-10 21:26:17,783 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-10 21:26:17,783 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-10 21:26:17,783 [INFO]   temperature: 0.9
2025-02-10 21:26:17,783 [INFO]   top_p: 0.3
2025-02-10 21:26:17,783 [INFO]   freq_penalty: 1.0
2025-02-10 21:26:17,783 [INFO]   example_prompt: But the lack of financial aid would| I feel 
2025-02-10 21:26:17,783 [INFO]   debug: 0
2025-02-10 21:26:17,783 [INFO]   save_no_steer: 1
2025-02-10 21:26:17,783 [INFO]   is_norm_delta_matrix: 0
2025-02-10 21:26:17,783 [INFO]   use_cache: 0
2025-02-10 21:26:17,783 [INFO]   repeat_num: 2
2025-02-10 21:26:17,783 [INFO]   gen_batch_size: 16
2025-02-10 21:26:17,784 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-10 21:26:17,784 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-10 21:26:17,784 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-10 21:26:17,784 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-10 21:26:17,885 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-10 21:26:17,889 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-10 21:26:17,889 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-10 21:26:17,889 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-10 21:26:37,374 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-10 21:26:37,375 [INFO] 缓存 ./results/sentiment/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-10 21:26:37,396 [INFO] :>> Sentiment : from neg to pos
2025-02-10 21:26:37,410 [INFO] positive
2025-02-10 21:26:37,416 [INFO] Running model with cache to obtain hidden states
2025-02-10 21:26:39,399 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-10 21:26:39,399 [INFO] negative
2025-02-10 21:26:39,412 [INFO] Running model with cache to obtain hidden states
2025-02-10 21:26:41,440 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-10 21:26:41,443 [INFO] steer_info 已保存到缓存 ./results/sentiment/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-10 21:26:41,452 [INFO] 转向方向 dif_pos-neg_relu
2025-02-10 21:26:41,473 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-10 21:26:41,479 [INFO] Generating texts **without** steering... 
2025-02-10 21:26:41,481 [INFO] 无干预
2025-02-10 21:26:42,815 [INFO] 当前批次共处理2个prompt
2025-02-10 21:26:42,815 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-10 21:26:42,815 [INFO] 生成 1: | be a major blow to the country's economy, which is struggling to keep up with rising inflation.

The IMF said that the government had been forced to cut its spending by about $1 billion in 2013, and that it was considering other measures|
2025-02-10 21:26:42,815 [INFO] 生成 2: | have been a major blow to Obama's campaign.

The Obama campaign had already raised $3 million in its first quarter, according to Federal Election Commission filings. The White House had raised $2 million in the same period last year, but that|
2025-02-10 21:26:42,815 [INFO] 生成 3: | have made it harder for a number of African countries to get their own public schools.

The government's new plan would have required schools to offer more than $1,000 in grants each year, and would have allowed students to apply for free|
2025-02-10 21:26:42,815 [INFO] Prompt 2: | I feel |
2025-02-10 21:26:42,815 [INFO] 生成 1: | and my thoughts are not just mine. I feel that this is the way it should be.

I am a single mother who has been living with her boyfriend for three years now. We have two children, a daughter and son, and we|
2025-02-10 21:26:42,815 [INFO] 生成 2: | and I feel  to be free of the need for such a thing. I don't know how to do it, but I do know that it is not something that can be done. It's something that needs to be done.

I|
2025-02-10 21:26:42,815 [INFO] 生成 3: | (in a way) that it's time to get back to the basics of the game.

I've been playing Hearthstone for a while now, and it's always been fun. It's not like I'm just going to play every single|
2025-02-10 21:26:42,815 [INFO] 干预之后的结果
2025-02-10 21:26:42,816 [INFO] 干预方向neg->pos,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-10 21:26:42,816 [INFO] ** Generating texts with steering... Target **
2025-02-10 21:26:42,816 [INFO] form neg to pos
2025-02-10 21:26:43,759 [INFO] 当前批次共处理2个prompt
2025-02-10 21:26:43,759 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-10 21:26:43,759 [INFO] 生成 1: | for sure be

The U.S. college ranks in the top 5 with all the basics covered.


This is a great option for anyone looking to get a new bike but it's not perfect, but it's worth it!
|
2025-02-10 21:26:43,759 [INFO] 生成 2: | just be the start

It's a great option for all those who love a traditional bow but don't want to go down the road.

A few days ago, I got my first two years of playing and now I'm ready to|
2025-02-10 21:26:43,759 [INFO] 生成 3: | for sure be

I'm looking forward to the next step.

One thing I can't wait to see how it goes!


-PacheonNguyen, 4 years old and a kid with his own style but still loves|
2025-02-10 21:26:43,759 [INFO] Prompt 2: | I feel |
2025-02-10 21:26:43,759 [INFO] 生成 1: | with the design

I love it!


This is a must have for any kid who loves a t shirt but doesn't know what to do with it. I love how easy to use and has great colors and patterns. This is my|
2025-02-10 21:26:43,759 [INFO] 生成 2: | to use it as a piece of kit for my dog.

This is the best gift I've received!

The only thing that would be wrong with this product but i'm glad it's in my favorite colors and the light is so|
2025-02-10 21:26:43,759 [INFO] 生成 3: | a great piece of advice for everyone.

If you're looking for a nice, but not too expensive gift to make it easy! I'm going to give it every time!

This is my second gift and I'm happy with the|
2025-02-10 21:26:43,764 [INFO] Provide No Steer Result 提供无干预对照样本
2025-02-10 21:26:43,764 [INFO] Running on full data
2025-02-10 21:26:43,764 [INFO] Out of Domain: Calculate at A dataset, Evaluate at B dataset
2025-02-10 21:26:43,764 [INFO] Loading prompt_path from /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-10 21:26:43,784 [INFO] prompt的极性是neg
2025-02-10 21:26:43,784 [INFO] Running with alpha: 100.0
2025-02-10 21:26:43,784 [INFO] Running with prompt_type: from neg to pos
2025-02-10 21:26:43,788 [INFO] 无干预
2025-02-10 21:26:45,853 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-10 21:26:45,854 [INFO] {'md5_hash': '06daa8998220e9f416c42b8f9c45fda8', 'prompt': {'text': 'It made my hair feel flat and uncooperative'}, 'continuation': {'text': ', though my skin felt soft and relaxed.'}, 'num_positive': 0, 'generations': [{'text': "It made my hair feel flat and uncooperative in the past.\n\nThis is a pair of scissors for those who don't have them but want to try it out. I love the 4x4!\n\nThis is a bit pricey but you can make it with anything you want,"}, {'text': "It made my hair feel flat and uncooperative you can't go wrong with the box.\n\nThis is a great gift for a little bit of extra size but if you're looking for something to make your own, but don't have the size to go with it.\n\nI'm"}]}
2025-02-10 21:26:45,859 [INFO] 无干预
2025-02-10 21:26:47,934 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-10 21:26:47,934 [INFO] {'md5_hash': '684d089dd2539bcb726b7960c35e96f2', 'prompt': {'text': 'Protesters have also long said that they would not accept'}, 'continuation': {'text': 'immunity for Saleh and his family in exchange his resignation.'}, 'num_positive': 0, 'generations': [{'text': "Protesters have also long said that they would not accept for a few dollars.\n\nIf you're looking for the best quality, but don't want to spend too much but still want to add some extra flair?\n\nYou can use this as a base for your budget and it's just the"}, {'text': "Protesters have also long said that they would not accept\n\nA lot of money but it's worth it!\n\nIf you need a bike, but don't want to take the trip? We're looking for something that fits your budget.\n\n\nIt's just a $5 price tag,"}]}
2025-02-10 21:26:47,940 [INFO] 无干预
2025-02-10 21:26:50,005 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-10 21:26:50,005 [INFO] {'md5_hash': 'cc4129826978407883aacad181a6f185', 'prompt': {'text': 'but a overclock-failure would not'}, 'continuation': {'text': 'result in black screens.'}, 'num_positive': 0, 'generations': [{'text': "but a overclock-failure would not if\n\nsketch and it's just one of the best quality cuts you can make.\n\nThe clip is a little pricey but worth it for a budget option.\n\n\nIf you're looking for an extra piece of earplox"}, {'text': "but a overclock-failure would not\n\nso far.\n\nThis is the best of 2 and 3, but I've used it for my own. I'm looking to add more in the past, but I just need to add some more room for expansion.\n\n\nThese"}]}
2025-02-10 21:26:50,011 [INFO] 无干预
