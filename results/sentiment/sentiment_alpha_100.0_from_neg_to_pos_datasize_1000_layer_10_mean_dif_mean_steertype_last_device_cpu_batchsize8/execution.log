2025-01-24 22:51:33,421 [INFO] Logging initialized. Logs will be saved to ./results/sentiment/sentiment_alpha_100.0_from_neg_to_pos_datasize_1000_layer_10_mean_dif_mean_steertype_last_device_cpu_batchsize8/execution.log
2025-01-24 22:51:33,421 [INFO] Show Hyperparameters: 


2025-01-24 22:51:33,421 [INFO]   task: sentiment
2025-01-24 22:51:33,421 [INFO]   layer: 10
2025-01-24 22:51:33,421 [INFO]   LLM: gemma-2b
2025-01-24 22:51:33,421 [INFO]   seed: 42
2025-01-24 22:51:33,421 [INFO]   data_size: 1000
2025-01-24 22:51:33,421 [INFO]   device: cpu
2025-01-24 22:51:33,421 [INFO]   alpha: 100.0
2025-01-24 22:51:33,421 [INFO]   method: val_mul
2025-01-24 22:51:33,421 [INFO]   topk_mean: 100
2025-01-24 22:51:33,421 [INFO]   topk_cnt: 100
2025-01-24 22:51:33,421 [INFO]   batch_size: 8
2025-01-24 22:51:33,421 [INFO]   source: neg
2025-01-24 22:51:33,421 [INFO]   target: pos
2025-01-24 22:51:33,421 [INFO]   mean_type: dif_mean
2025-01-24 22:51:33,421 [INFO]   steer_type: last
2025-01-24 22:51:33,421 [INFO]   output_dir: ./results/sentiment/
2025-01-24 22:51:33,421 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-01-24 22:51:33,421 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-01-24 22:51:33,422 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-24 22:51:33,422 [INFO]   temperature: 0.9
2025-01-24 22:51:33,422 [INFO]   top_p: 0.3
2025-01-24 22:51:33,422 [INFO]   freq_penalty: 1.0
2025-01-24 22:51:33,422 [INFO]   debug: 1
2025-01-24 22:51:33,422 [INFO]   save_no_steer: 1
2025-01-24 22:51:33,422 [INFO]   cache_delta_matrix: 0
2025-01-24 22:51:33,422 [INFO]   is_norm_delta_matrix: 0
2025-01-24 22:51:33,422 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-24 22:51:33,422 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-01-24 22:51:33,422 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-01-24 22:51:33,422 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-01-24 22:51:33,541 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-01-24 22:51:33,551 [INFO] Selected 1000 negative, 1000 positive, and 1000 neutral samples
2025-01-24 22:51:33,551 [INFO] Loading SAE for layer 10 gemma-2b
2025-01-24 22:51:33,551 [INFO] Loading model: gemma-2b
2025-01-24 22:51:37,732 [WARNING] You are not using LayerNorm, so the writing weights can't be centered! Skipping
2025-01-24 22:51:44,421 [INFO] model architecture for gemma-2b HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (blocks): ModuleList(
    (0-17): 18 x TransformerBlock(
      (ln1): RMSNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): RMSNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): GroupedQueryAttention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
        (hook_rot_k): HookPoint()
        (hook_rot_q): HookPoint()
      )
      (mlp): GatedMLP(
        (hook_pre): HookPoint()
        (hook_pre_linear): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): RMSNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
)
2025-01-24 22:51:46,638 [INFO] fromnegtopos
2025-01-24 22:51:46,638 [INFO] positive
2025-01-24 22:51:46,644 [INFO] Running model with cache to obtain hidden states
2025-01-24 22:53:35,021 [INFO] Total non-zero element shape: torch.Size([16384])
2025-01-24 22:53:35,068 [INFO] negative
2025-01-24 22:53:35,188 [INFO] Running model with cache to obtain hidden states
2025-01-24 22:55:26,251 [INFO] Total non-zero element shape: torch.Size([16384])
2025-01-24 22:55:26,299 [INFO] 转向方向 dif_pos-neg_relu
2025-01-24 22:55:26,300 [INFO] sae cfg.hook_name 挂载名称: blocks.10.hook_resid_post
2025-01-24 22:55:26,304 [INFO] delta_matrix: tensor([ 0.0071, -0.0081,  0.0008,  ...,  0.0128,  0.0136,  0.0046],
       grad_fn=<AddBackward0>)
2025-01-24 22:55:26,304 [INFO] Example prompt: What really matters is that they know
2025-01-24 22:55:26,304 [INFO] Generating texts **without** steering... 
2025-01-24 22:55:26,307 [INFO] 无干预
2025-01-24 22:55:35,404 [INFO] prompt:*****
What really matters is that they know
2025-01-24 22:55:35,404 [INFO] Generated Text: 1:
 know how to make you feel good about yourself.

It’s not just about the products, it’s about the experience.

The staff at this store are amazing! They have a great selection of products and are always willing to help you find
2025-01-24 22:55:35,404 [INFO] Generated Text: 2:
 know you. They know your strengths, weaknesses, likes and dislikes. They have seen you at your best and worst. They know how to make you feel comfortable in their presence so that you can be yourself without fear of judgment or criticism.

The best
2025-01-24 22:55:35,404 [INFO] Generated Text: 3:
 know how to play.

They have the talent, the ability and the desire to do it.

The other stuff is just a bonus.

That’s what I think about when I watch my kids play soccer.

I don’t care
2025-01-24 22:55:35,404 [INFO] 干预之后的结果
2025-01-24 22:55:35,404 [INFO] 干预方向neg->pos,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-01-24 22:55:35,404 [INFO] ** Generating texts with steering... Target **
2025-01-24 22:55:35,404 [INFO] form neg to pos
2025-01-24 22:55:44,308 [INFO] prompt:*****
What really matters is that they know
2025-01-24 22:55:44,308 [INFO] Generated Text: 1:
 know how to use their own words.

The same goes for the first-person pronouns, which are often used incorrectly by students.

“It’s important to understand the difference between ‘I’ and ‘me,’ ” said Michelle King, a
2025-01-24 22:55:44,308 [INFO] Generated Text: 2:
 know the meaning of the word “family.”

The story of how the two families came together is a tale of two brothers.

In 1985, Michael and David Gonsalves were living in Massachusetts. The brothers had grown up
2025-01-24 22:55:44,308 [INFO] Generated Text: 3:
 know how to work with the customer and deliver a quality product.

The team at S&S has always been very professional and friendly. They have always delivered on time and within budget. We would highly recommend them to anyone looking for a reliable contractor who
2025-01-24 22:55:44,313 [INFO] Show Hyperparameters: 


2025-01-24 22:55:44,313 [INFO]   task: sentiment
2025-01-24 22:55:44,313 [INFO]   layer: 10
2025-01-24 22:55:44,313 [INFO]   LLM: gemma-2b
2025-01-24 22:55:44,313 [INFO]   seed: 42
2025-01-24 22:55:44,313 [INFO]   data_size: 1000
2025-01-24 22:55:44,313 [INFO]   device: cpu
2025-01-24 22:55:44,313 [INFO]   alpha: 100.0
2025-01-24 22:55:44,313 [INFO]   method: val_mul
2025-01-24 22:55:44,313 [INFO]   topk_mean: 100
2025-01-24 22:55:44,313 [INFO]   topk_cnt: 100
2025-01-24 22:55:44,313 [INFO]   batch_size: 8
2025-01-24 22:55:44,313 [INFO]   source: neg
2025-01-24 22:55:44,313 [INFO]   target: pos
2025-01-24 22:55:44,313 [INFO]   mean_type: dif_mean
2025-01-24 22:55:44,313 [INFO]   steer_type: last
2025-01-24 22:55:44,313 [INFO]   output_dir: ./results/sentiment/
2025-01-24 22:55:44,313 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-01-24 22:55:44,313 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-01-24 22:55:44,313 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-24 22:55:44,313 [INFO]   temperature: 0.9
2025-01-24 22:55:44,313 [INFO]   top_p: 0.3
2025-01-24 22:55:44,313 [INFO]   freq_penalty: 1.0
2025-01-24 22:55:44,313 [INFO]   debug: 1
2025-01-24 22:55:44,313 [INFO]   save_no_steer: 1
2025-01-24 22:55:44,313 [INFO]   cache_delta_matrix: 0
2025-01-24 22:55:44,313 [INFO]   is_norm_delta_matrix: 0
2025-01-24 22:55:44,313 [INFO] debug mode,show example, no full dataset eval
2025-01-24 22:57:35,673 [INFO] Logging initialized. Logs will be saved to ./results/sentiment/sentiment_alpha_100.0_from_neg_to_pos_datasize_1000_layer_10_mean_dif_mean_steertype_last_device_cpu_batchsize8/execution.log
2025-01-24 22:57:35,673 [INFO] Show Hyperparameters: 


2025-01-24 22:57:35,673 [INFO]   task: sentiment
2025-01-24 22:57:35,673 [INFO]   layer: 10
2025-01-24 22:57:35,673 [INFO]   LLM: gemma-2b
2025-01-24 22:57:35,673 [INFO]   seed: 42
2025-01-24 22:57:35,673 [INFO]   data_size: 1000
2025-01-24 22:57:35,673 [INFO]   device: cpu
2025-01-24 22:57:35,673 [INFO]   alpha: 100.0
2025-01-24 22:57:35,673 [INFO]   method: val_mul
2025-01-24 22:57:35,673 [INFO]   topk_mean: 100
2025-01-24 22:57:35,673 [INFO]   topk_cnt: 100
2025-01-24 22:57:35,673 [INFO]   batch_size: 8
2025-01-24 22:57:35,674 [INFO]   source: neg
2025-01-24 22:57:35,674 [INFO]   target: pos
2025-01-24 22:57:35,674 [INFO]   mean_type: dif_mean
2025-01-24 22:57:35,674 [INFO]   steer_type: last
2025-01-24 22:57:35,674 [INFO]   output_dir: ./results/sentiment/
2025-01-24 22:57:35,674 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-01-24 22:57:35,674 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-01-24 22:57:35,674 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-24 22:57:35,674 [INFO]   temperature: 0.9
2025-01-24 22:57:35,674 [INFO]   top_p: 0.3
2025-01-24 22:57:35,674 [INFO]   freq_penalty: 1.0
2025-01-24 22:57:35,674 [INFO]   debug: 1
2025-01-24 22:57:35,674 [INFO]   save_no_steer: 1
2025-01-24 22:57:35,674 [INFO]   cache_delta_matrix: 0
2025-01-24 22:57:35,674 [INFO]   is_norm_delta_matrix: 0
2025-01-24 22:57:35,674 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-24 22:57:35,674 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-01-24 22:57:35,674 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-01-24 22:57:35,675 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-01-24 22:57:35,801 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-01-24 22:57:35,809 [INFO] Selected 1000 negative, 1000 positive, and 1000 neutral samples
2025-01-24 22:57:35,810 [INFO] Loading SAE for layer 10 gemma-2b
2025-01-24 22:57:35,810 [INFO] Loading model: gemma-2b
2025-01-24 22:57:44,883 [WARNING] You are not using LayerNorm, so the writing weights can't be centered! Skipping
2025-01-24 22:57:51,545 [INFO] model architecture for gemma-2b HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (blocks): ModuleList(
    (0-17): 18 x TransformerBlock(
      (ln1): RMSNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): RMSNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): GroupedQueryAttention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
        (hook_rot_k): HookPoint()
        (hook_rot_q): HookPoint()
      )
      (mlp): GatedMLP(
        (hook_pre): HookPoint()
        (hook_pre_linear): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): RMSNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
)
2025-01-24 22:57:53,790 [INFO] fromnegtopos
2025-01-24 22:57:53,791 [INFO] positive
2025-01-24 22:57:53,796 [INFO] Running model with cache to obtain hidden states
