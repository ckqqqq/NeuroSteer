2025-02-16 14:57:06,559 [INFO] Logging initialized. Logs will be saved to ./results/sentiment_gemma/gemma-2-2b_sentiment_layer_12_datasize_1500_batchsize32_topK_100/alpha_500.0_from_neg_to_pos_prompt_neg_mean_dif_mean_steertype_all_device_cpu/execution.log
2025-02-16 14:57:06,559 [INFO] Show Hyperparameters: 


2025-02-16 14:57:06,559 [INFO]   task: sentiment
2025-02-16 14:57:06,559 [INFO]   layer: 12
2025-02-16 14:57:06,559 [INFO]   LLM: gemma-2-2b
2025-02-16 14:57:06,559 [INFO]   seed: 42
2025-02-16 14:57:06,559 [INFO]   data_size: 1500
2025-02-16 14:57:06,559 [INFO]   device: cpu
2025-02-16 14:57:06,559 [INFO]   alpha: 500.0
2025-02-16 14:57:06,559 [INFO]   method: val_mul
2025-02-16 14:57:06,559 [INFO]   topk_mean: 100
2025-02-16 14:57:06,559 [INFO]   topk_cnt: 100
2025-02-16 14:57:06,559 [INFO]   batch_size: 32
2025-02-16 14:57:06,559 [INFO]   source: neg
2025-02-16 14:57:06,559 [INFO]   target: pos
2025-02-16 14:57:06,559 [INFO]   prompt_source: neg
2025-02-16 14:57:06,559 [INFO]   prompt_data_size: 500
2025-02-16 14:57:06,559 [INFO]   mean_type: dif_mean
2025-02-16 14:57:06,559 [INFO]   steer_type: all
2025-02-16 14:57:06,559 [INFO]   output_dir: ./results/sentiment_gemma/
2025-02-16 14:57:06,559 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 14:57:06,559 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 14:57:06,559 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 14:57:06,560 [INFO]   temperature: 0.9
2025-02-16 14:57:06,560 [INFO]   top_p: 0.3
2025-02-16 14:57:06,560 [INFO]   freq_penalty: 1.0
2025-02-16 14:57:06,560 [INFO]   example_prompt: But the lack of financial aid would| The passage of the AI Act will
2025-02-16 14:57:06,560 [INFO]   debug: 0
2025-02-16 14:57:06,560 [INFO]   save_no_steer: 1
2025-02-16 14:57:06,560 [INFO]   is_norm_delta_matrix: 0
2025-02-16 14:57:06,560 [INFO]   use_cache: 0
2025-02-16 14:57:06,560 [INFO]   repeat_num: 2
2025-02-16 14:57:06,560 [INFO]   gen_batch_size: 16
2025-02-16 14:57:06,560 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 14:57:06,560 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 14:57:06,560 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-16 14:57:06,561 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-16 14:57:06,684 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 14:57:06,690 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-16 14:57:06,690 [INFO] Loading Model Loading SAE for layer 12 gemma-2-2b
2025-02-16 14:57:31,198 [INFO] Loading model: gemma-2-2b
2025-02-16 14:57:31,199 [WARNING] You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constant Setting center_unembed=False instead.
2025-02-16 14:58:06,875 [WARNING] You are not using LayerNorm, so the writing weights can't be centered! Skipping
2025-02-16 14:58:18,942 [INFO] model architecture for gemma-2-2b HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (blocks): ModuleList(
    (0-25): 26 x TransformerBlock(
      (ln1): RMSNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln1_post): RMSNorm(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): RMSNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2_post): RMSNorm(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): GroupedQueryAttention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
        (hook_rot_k): HookPoint()
        (hook_rot_q): HookPoint()
      )
      (mlp): GatedMLP(
        (hook_pre): HookPoint()
        (hook_pre_linear): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): RMSNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GemmaTokenizerFast(name_or_path='google/gemma-2b', vocab_size=256000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<start_of_turn>', '<end_of_turn>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	0: AddedToken("<pad>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	1: AddedToken("<eos>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	2: AddedToken("<bos>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	3: AddedToken("<unk>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	4: AddedToken("<mask>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	5: AddedToken("<2mass>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	6: AddedToken("[@BOS@]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	7: AddedToken("<unused0>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	8: AddedToken("<unused1>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	9: AddedToken("<unused2>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	10: AddedToken("<unused3>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	11: AddedToken("<unused4>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	12: AddedToken("<unused5>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	13: AddedToken("<unused6>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	14: AddedToken("<unused7>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	15: AddedToken("<unused8>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	16: AddedToken("<unused9>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	17: AddedToken("<unused10>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	18: AddedToken("<unused11>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	19: AddedToken("<unused12>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	20: AddedToken("<unused13>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	21: AddedToken("<unused14>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	22: AddedToken("<unused15>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	23: AddedToken("<unused16>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	24: AddedToken("<unused17>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	25: AddedToken("<unused18>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	26: AddedToken("<unused19>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	27: AddedToken("<unused20>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	28: AddedToken("<unused21>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	29: AddedToken("<unused22>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	30: AddedToken("<unused23>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	31: AddedToken("<unused24>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	32: AddedToken("<unused25>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	33: AddedToken("<unused26>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	34: AddedToken("<unused27>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	35: AddedToken("<unused28>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	36: AddedToken("<unused29>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	37: AddedToken("<unused30>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	38: AddedToken("<unused31>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	39: AddedToken("<unused32>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	40: AddedToken("<unused33>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	41: AddedToken("<unused34>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	42: AddedToken("<unused35>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	43: AddedToken("<unused36>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	44: AddedToken("<unused37>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	45: AddedToken("<unused38>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	46: AddedToken("<unused39>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	47: AddedToken("<unused40>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	48: AddedToken("<unused41>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	49: AddedToken("<unused42>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	50: AddedToken("<unused43>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	51: AddedToken("<unused44>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	52: AddedToken("<unused45>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	53: AddedToken("<unused46>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	54: AddedToken("<unused47>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	55: AddedToken("<unused48>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	56: AddedToken("<unused49>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	57: AddedToken("<unused50>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	58: AddedToken("<unused51>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	59: AddedToken("<unused52>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	60: AddedToken("<unused53>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	61: AddedToken("<unused54>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	62: AddedToken("<unused55>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	63: AddedToken("<unused56>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	64: AddedToken("<unused57>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	65: AddedToken("<unused58>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	66: AddedToken("<unused59>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	67: AddedToken("<unused60>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	68: AddedToken("<unused61>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	69: AddedToken("<unused62>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	70: AddedToken("<unused63>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	71: AddedToken("<unused64>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	72: AddedToken("<unused65>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	73: AddedToken("<unused66>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	74: AddedToken("<unused67>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	75: AddedToken("<unused68>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	76: AddedToken("<unused69>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	77: AddedToken("<unused70>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	78: AddedToken("<unused71>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	79: AddedToken("<unused72>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	80: AddedToken("<unused73>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	81: AddedToken("<unused74>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	82: AddedToken("<unused75>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	83: AddedToken("<unused76>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	84: AddedToken("<unused77>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	85: AddedToken("<unused78>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	86: AddedToken("<unused79>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	87: AddedToken("<unused80>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	88: AddedToken("<unused81>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	89: AddedToken("<unused82>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	90: AddedToken("<unused83>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	91: AddedToken("<unused84>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	92: AddedToken("<unused85>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	93: AddedToken("<unused86>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	94: AddedToken("<unused87>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	95: AddedToken("<unused88>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	96: AddedToken("<unused89>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	97: AddedToken("<unused90>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	98: AddedToken("<unused91>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	99: AddedToken("<unused92>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	100: AddedToken("<unused93>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	101: AddedToken("<unused94>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	102: AddedToken("<unused95>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	103: AddedToken("<unused96>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	104: AddedToken("<unused97>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	105: AddedToken("<unused98>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	106: AddedToken("<start_of_turn>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	107: AddedToken("<end_of_turn>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	108: AddedToken("
", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	109: AddedToken("

", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	110: AddedToken("


", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	111: AddedToken("



", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	112: AddedToken("




", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	113: AddedToken("





", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	114: AddedToken("






", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	115: AddedToken("







", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	116: AddedToken("








", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	117: AddedToken("









", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	118: AddedToken("










", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	119: AddedToken("











", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	120: AddedToken("












", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	121: AddedToken("













", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	122: AddedToken("














", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	123: AddedToken("















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	124: AddedToken("
















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	125: AddedToken("

















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	126: AddedToken("


















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	127: AddedToken("



















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	128: AddedToken("




















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	129: AddedToken("





















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	130: AddedToken("






















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	131: AddedToken("























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	132: AddedToken("
























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	133: AddedToken("

























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	134: AddedToken("


























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	135: AddedToken("



























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	136: AddedToken("




























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	137: AddedToken("





























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	138: AddedToken("






























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	139: AddedToken("▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	140: AddedToken("▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	141: AddedToken("▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	142: AddedToken("▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	143: AddedToken("▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	144: AddedToken("▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	145: AddedToken("▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	146: AddedToken("▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	147: AddedToken("▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	148: AddedToken("▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	149: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	150: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	152: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	153: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	154: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	155: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	156: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	157: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	158: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	159: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	160: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	161: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	162: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	163: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	164: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	165: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	166: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	167: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	168: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	169: AddedToken("<table>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	170: AddedToken("<caption>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	171: AddedToken("<thead>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	172: AddedToken("<tbody>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	173: AddedToken("<tfoot>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	174: AddedToken("<tr>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	175: AddedToken("<th>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	176: AddedToken("<td>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	177: AddedToken("</table>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	178: AddedToken("</caption>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	179: AddedToken("</thead>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	180: AddedToken("</tbody>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	181: AddedToken("</tfoot>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	182: AddedToken("</tr>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	183: AddedToken("</th>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	184: AddedToken("</td>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	185: AddedToken("<h1>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	186: AddedToken("<h2>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	187: AddedToken("<h3>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	188: AddedToken("<h4>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	189: AddedToken("<h5>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	190: AddedToken("<h6>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	191: AddedToken("<blockquote>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	192: AddedToken("</h1>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	193: AddedToken("</h2>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	194: AddedToken("</h3>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	195: AddedToken("</h4>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	196: AddedToken("</h5>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	197: AddedToken("</h6>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	198: AddedToken("</blockquote>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	199: AddedToken("<strong>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	200: AddedToken("<em>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	201: AddedToken("<b>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	202: AddedToken("<i>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	203: AddedToken("<u>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	204: AddedToken("<s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	205: AddedToken("<sub>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	206: AddedToken("<sup>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	207: AddedToken("<code>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	208: AddedToken("</strong>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	209: AddedToken("</em>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	210: AddedToken("</b>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	211: AddedToken("</i>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	212: AddedToken("</u>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	213: AddedToken("</s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	214: AddedToken("</sub>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	215: AddedToken("</sup>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	216: AddedToken("</code>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
2025-02-16 14:58:18,943 [INFO] 缓存 ./results/sentiment_gemma/gemma-2-2b_sentiment_layer_12_datasize_1500_batchsize32_topK_100/steer_info_cache_of_gemma-2-2b_l12.pkl 不存在，缓存 steer_info
2025-02-16 14:58:18,977 [INFO] :>> sentiment : from neg to pos
2025-02-16 14:58:19,000 [INFO] positive
2025-02-16 14:58:19,009 [INFO] Running model with cache to obtain hidden states
2025-02-16 15:04:30,871 [INFO] Logging initialized. Logs will be saved to ./results/sentiment_gemma/gemma-2-2b_sentiment_layer_12_datasize_1500_batchsize32_topK_100/alpha_500.0_from_neg_to_pos_prompt_neg_mean_dif_mean_steertype_all_device_cpu/execution.log
2025-02-16 15:04:30,871 [INFO] Show Hyperparameters: 


2025-02-16 15:04:30,871 [INFO]   task: sentiment
2025-02-16 15:04:30,871 [INFO]   layer: 12
2025-02-16 15:04:30,871 [INFO]   LLM: gemma-2-2b
2025-02-16 15:04:30,871 [INFO]   seed: 42
2025-02-16 15:04:30,871 [INFO]   data_size: 1500
2025-02-16 15:04:30,871 [INFO]   device: cpu
2025-02-16 15:04:30,871 [INFO]   alpha: 500.0
2025-02-16 15:04:30,871 [INFO]   method: val_mul
2025-02-16 15:04:30,871 [INFO]   topk_mean: 100
2025-02-16 15:04:30,871 [INFO]   topk_cnt: 100
2025-02-16 15:04:30,871 [INFO]   batch_size: 32
2025-02-16 15:04:30,871 [INFO]   source: neg
2025-02-16 15:04:30,871 [INFO]   target: pos
2025-02-16 15:04:30,871 [INFO]   prompt_source: neg
2025-02-16 15:04:30,871 [INFO]   prompt_data_size: 500
2025-02-16 15:04:30,871 [INFO]   mean_type: dif_mean
2025-02-16 15:04:30,871 [INFO]   steer_type: all
2025-02-16 15:04:30,871 [INFO]   output_dir: ./results/sentiment_gemma/
2025-02-16 15:04:30,871 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 15:04:30,871 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 15:04:30,871 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 15:04:30,872 [INFO]   temperature: 0.9
2025-02-16 15:04:30,872 [INFO]   top_p: 0.3
2025-02-16 15:04:30,872 [INFO]   freq_penalty: 1.0
2025-02-16 15:04:30,872 [INFO]   example_prompt: But the lack of financial aid would| The passage of the AI Act will
2025-02-16 15:04:30,872 [INFO]   debug: 0
2025-02-16 15:04:30,872 [INFO]   save_no_steer: 0
2025-02-16 15:04:30,872 [INFO]   is_norm_delta_matrix: 0
2025-02-16 15:04:30,872 [INFO]   use_cache: 0
2025-02-16 15:04:30,872 [INFO]   repeat_num: 2
2025-02-16 15:04:30,872 [INFO]   gen_batch_size: 16
2025-02-16 15:04:30,872 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 15:04:30,872 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 15:04:30,872 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-16 15:04:30,872 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-16 15:04:31,076 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 15:04:31,085 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-16 15:04:31,086 [INFO] Loading Model Loading SAE for layer 12 gemma-2-2b
2025-02-16 15:04:54,766 [INFO] Loading model: gemma-2-2b
2025-02-16 15:04:54,768 [WARNING] You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constant Setting center_unembed=False instead.
2025-02-16 15:05:30,852 [WARNING] You are not using LayerNorm, so the writing weights can't be centered! Skipping
2025-02-16 15:05:43,375 [INFO] model architecture for gemma-2-2b HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (blocks): ModuleList(
    (0-25): 26 x TransformerBlock(
      (ln1): RMSNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln1_post): RMSNorm(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): RMSNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2_post): RMSNorm(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): GroupedQueryAttention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
        (hook_rot_k): HookPoint()
        (hook_rot_q): HookPoint()
      )
      (mlp): GatedMLP(
        (hook_pre): HookPoint()
        (hook_pre_linear): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): RMSNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GemmaTokenizerFast(name_or_path='google/gemma-2b', vocab_size=256000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<start_of_turn>', '<end_of_turn>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	0: AddedToken("<pad>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	1: AddedToken("<eos>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	2: AddedToken("<bos>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	3: AddedToken("<unk>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	4: AddedToken("<mask>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	5: AddedToken("<2mass>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	6: AddedToken("[@BOS@]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	7: AddedToken("<unused0>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	8: AddedToken("<unused1>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	9: AddedToken("<unused2>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	10: AddedToken("<unused3>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	11: AddedToken("<unused4>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	12: AddedToken("<unused5>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	13: AddedToken("<unused6>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	14: AddedToken("<unused7>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	15: AddedToken("<unused8>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	16: AddedToken("<unused9>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	17: AddedToken("<unused10>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	18: AddedToken("<unused11>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	19: AddedToken("<unused12>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	20: AddedToken("<unused13>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	21: AddedToken("<unused14>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	22: AddedToken("<unused15>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	23: AddedToken("<unused16>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	24: AddedToken("<unused17>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	25: AddedToken("<unused18>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	26: AddedToken("<unused19>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	27: AddedToken("<unused20>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	28: AddedToken("<unused21>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	29: AddedToken("<unused22>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	30: AddedToken("<unused23>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	31: AddedToken("<unused24>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	32: AddedToken("<unused25>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	33: AddedToken("<unused26>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	34: AddedToken("<unused27>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	35: AddedToken("<unused28>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	36: AddedToken("<unused29>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	37: AddedToken("<unused30>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	38: AddedToken("<unused31>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	39: AddedToken("<unused32>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	40: AddedToken("<unused33>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	41: AddedToken("<unused34>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	42: AddedToken("<unused35>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	43: AddedToken("<unused36>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	44: AddedToken("<unused37>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	45: AddedToken("<unused38>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	46: AddedToken("<unused39>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	47: AddedToken("<unused40>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	48: AddedToken("<unused41>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	49: AddedToken("<unused42>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	50: AddedToken("<unused43>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	51: AddedToken("<unused44>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	52: AddedToken("<unused45>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	53: AddedToken("<unused46>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	54: AddedToken("<unused47>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	55: AddedToken("<unused48>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	56: AddedToken("<unused49>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	57: AddedToken("<unused50>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	58: AddedToken("<unused51>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	59: AddedToken("<unused52>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	60: AddedToken("<unused53>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	61: AddedToken("<unused54>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	62: AddedToken("<unused55>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	63: AddedToken("<unused56>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	64: AddedToken("<unused57>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	65: AddedToken("<unused58>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	66: AddedToken("<unused59>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	67: AddedToken("<unused60>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	68: AddedToken("<unused61>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	69: AddedToken("<unused62>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	70: AddedToken("<unused63>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	71: AddedToken("<unused64>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	72: AddedToken("<unused65>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	73: AddedToken("<unused66>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	74: AddedToken("<unused67>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	75: AddedToken("<unused68>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	76: AddedToken("<unused69>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	77: AddedToken("<unused70>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	78: AddedToken("<unused71>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	79: AddedToken("<unused72>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	80: AddedToken("<unused73>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	81: AddedToken("<unused74>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	82: AddedToken("<unused75>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	83: AddedToken("<unused76>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	84: AddedToken("<unused77>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	85: AddedToken("<unused78>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	86: AddedToken("<unused79>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	87: AddedToken("<unused80>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	88: AddedToken("<unused81>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	89: AddedToken("<unused82>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	90: AddedToken("<unused83>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	91: AddedToken("<unused84>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	92: AddedToken("<unused85>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	93: AddedToken("<unused86>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	94: AddedToken("<unused87>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	95: AddedToken("<unused88>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	96: AddedToken("<unused89>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	97: AddedToken("<unused90>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	98: AddedToken("<unused91>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	99: AddedToken("<unused92>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	100: AddedToken("<unused93>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	101: AddedToken("<unused94>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	102: AddedToken("<unused95>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	103: AddedToken("<unused96>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	104: AddedToken("<unused97>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	105: AddedToken("<unused98>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	106: AddedToken("<start_of_turn>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	107: AddedToken("<end_of_turn>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	108: AddedToken("
", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	109: AddedToken("

", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	110: AddedToken("


", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	111: AddedToken("



", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	112: AddedToken("




", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	113: AddedToken("





", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	114: AddedToken("






", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	115: AddedToken("







", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	116: AddedToken("








", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	117: AddedToken("









", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	118: AddedToken("










", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	119: AddedToken("











", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	120: AddedToken("












", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	121: AddedToken("













", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	122: AddedToken("














", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	123: AddedToken("















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	124: AddedToken("
















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	125: AddedToken("

















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	126: AddedToken("


















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	127: AddedToken("



















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	128: AddedToken("




















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	129: AddedToken("





















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	130: AddedToken("






















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	131: AddedToken("























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	132: AddedToken("
























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	133: AddedToken("

























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	134: AddedToken("


























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	135: AddedToken("



























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	136: AddedToken("




























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	137: AddedToken("





























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	138: AddedToken("






























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	139: AddedToken("▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	140: AddedToken("▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	141: AddedToken("▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	142: AddedToken("▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	143: AddedToken("▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	144: AddedToken("▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	145: AddedToken("▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	146: AddedToken("▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	147: AddedToken("▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	148: AddedToken("▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	149: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	150: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	152: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	153: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	154: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	155: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	156: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	157: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	158: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	159: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	160: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	161: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	162: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	163: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	164: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	165: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	166: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	167: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	168: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	169: AddedToken("<table>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	170: AddedToken("<caption>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	171: AddedToken("<thead>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	172: AddedToken("<tbody>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	173: AddedToken("<tfoot>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	174: AddedToken("<tr>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	175: AddedToken("<th>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	176: AddedToken("<td>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	177: AddedToken("</table>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	178: AddedToken("</caption>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	179: AddedToken("</thead>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	180: AddedToken("</tbody>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	181: AddedToken("</tfoot>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	182: AddedToken("</tr>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	183: AddedToken("</th>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	184: AddedToken("</td>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	185: AddedToken("<h1>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	186: AddedToken("<h2>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	187: AddedToken("<h3>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	188: AddedToken("<h4>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	189: AddedToken("<h5>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	190: AddedToken("<h6>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	191: AddedToken("<blockquote>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	192: AddedToken("</h1>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	193: AddedToken("</h2>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	194: AddedToken("</h3>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	195: AddedToken("</h4>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	196: AddedToken("</h5>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	197: AddedToken("</h6>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	198: AddedToken("</blockquote>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	199: AddedToken("<strong>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	200: AddedToken("<em>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	201: AddedToken("<b>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	202: AddedToken("<i>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	203: AddedToken("<u>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	204: AddedToken("<s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	205: AddedToken("<sub>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	206: AddedToken("<sup>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	207: AddedToken("<code>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	208: AddedToken("</strong>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	209: AddedToken("</em>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	210: AddedToken("</b>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	211: AddedToken("</i>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	212: AddedToken("</u>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	213: AddedToken("</s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	214: AddedToken("</sub>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	215: AddedToken("</sup>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	216: AddedToken("</code>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
2025-02-16 15:05:43,377 [INFO] 缓存 ./results/sentiment_gemma/gemma-2-2b_sentiment_layer_12_datasize_1500_batchsize32_topK_100/steer_info_cache_of_gemma-2-2b_l12.pkl 不存在，缓存 steer_info
2025-02-16 15:05:43,421 [INFO] :>> sentiment : from neg to pos
2025-02-16 15:05:43,438 [INFO] positive
2025-02-16 15:05:43,445 [INFO] Running model with cache to obtain hidden states
2025-02-16 15:12:07,522 [INFO] Total non-zero element shape: torch.Size([16384])
2025-02-16 15:12:07,699 [INFO] negative
2025-02-16 15:12:07,715 [INFO] Running model with cache to obtain hidden states
2025-02-16 15:15:45,380 [INFO] Total non-zero element shape: torch.Size([16384])
2025-02-16 15:15:45,547 [INFO] steer_info 已保存到缓存 ./results/sentiment_gemma/gemma-2-2b_sentiment_layer_12_datasize_1500_batchsize32_topK_100/steer_info_cache_of_gemma-2-2b_l12.pkl
2025-02-16 15:15:45,547 [INFO] 转向方向 dif_pos-neg_relu
2025-02-16 15:15:45,548 [INFO] sae cfg.hook_name 挂载名称: blocks.0.hook_resid_post
2025-02-16 15:15:45,552 [INFO] Generating texts **without** steering... 
2025-02-16 15:15:45,552 [INFO] 无转向结果
2025-02-16 15:15:45,556 [INFO] 无干预
2025-02-16 15:15:58,579 [INFO] 当前批次共处理2个prompt
2025-02-16 15:15:58,579 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 15:15:58,579 [INFO] 生成 1: | not be a problem for the 20-year-old, who has already received a scholarship to study at the University of Texas at Austin.

“I’m going to have enough money for school,” he said. “I’m|
2025-02-16 15:15:58,579 [INFO] 生成 2: | be a major blow to the city’s plans to build a new stadium and expand its downtown.

The city is in talks with the state about using $10 million in tax-increment financing money from a 2014 bond issue|
2025-02-16 15:15:58,579 [INFO] 生成 3: | be a blow to the state's economy, said David L. Glickman, president of the New York State Association of Colleges and Universities.

"It would be a devastating blow to our state," he said. "We are already seeing|
2025-02-16 15:15:58,579 [INFO] Prompt 2: | The passage of the AI Act will|
2025-02-16 15:15:58,579 [INFO] 生成 1: | have a profound impact on the way we use artificial intelligence in our daily lives. It will set new standards for the development, testing, and deployment of AI systems, ensuring that they are safe and trustworthy.

The AI Act is a landmark piece of|
2025-02-16 15:15:58,579 [INFO] 生成 2: | help to ensure that the technology is developed and used in a way that protects human rights, privacy, and safety. It will also help to ensure that AI systems are transparent and accountable.

The AI Act is a significant step forward in regulating artificial intelligence|
2025-02-16 15:15:58,579 [INFO] 生成 3: | be a major step forward in regulating artificial intelligence (AI) technologies, but it is not the end of the story.

The EU’s AI Act is a landmark piece of legislation that sets out to regulate and control the use of artificial intelligence (|
2025-02-16 15:15:58,579 [INFO] 干预之后的结果
2025-02-16 15:15:58,579 [INFO] 干预方向neg->pos,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 15:15:58,579 [INFO] ** Generating texts with steering... Target **
2025-02-16 15:15:58,579 [INFO] form neg to pos
2025-02-16 15:15:58,579 [INFO] 转向结果
2025-02-16 15:16:11,973 [INFO] 当前批次共处理2个prompt
2025-02-16 15:16:11,973 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 15:16:11,974 [INFO] 生成 1: | be offset by the increase in tax revenue.

The government is expected to announce its 2019/20 budget on Wednesday, with Finance Minister Tito Mboweni expected to outline how he plans to plug a R54 billion hole|
2025-02-16 15:16:11,974 [INFO] 生成 2: | be more than made up for by the fact that it would be able to take advantage of the lower interest rates available in the bond market.

The Treasury has been forced to borrow at higher rates because of its poor credit rating, which was downgraded from|
2025-02-16 15:16:11,974 [INFO] 生成 3: | be offset by a 20% increase in tax revenues.

The report also said that the state’s economic growth was “very strong” and that it was “well-positioned to weather any global shocks”.

It said: “|
2025-02-16 15:16:11,974 [INFO] Prompt 2: | The passage of the AI Act will|
2025-02-16 15:16:11,974 [INFO] 生成 1: | be in the form of a Bill.
The Bill will be introduced in Parliament on 10 May 2019 and is expected to receive Royal Assent by 31 December 2019.
The Minister for Justice|
2025-02-16 15:16:11,974 [INFO] 生成 2: | be in the next few weeks.

The bill is expected to pass, but it is not clear what form it will take.

The Senate has passed a bill that would require all new cars to have a fuel economy standard of 35 miles|
2025-02-16 15:16:11,974 [INFO] 生成 3: | be 10 years from the date of enactment.

The AI Act is a landmark piece of legislation that seeks to address the challenges posed by artificial intelligence (AI) in various sectors, including healthcare, education, and employment. It aims to ensure|
2025-02-16 15:16:11,978 [INFO] Running on full data
2025-02-16 15:16:11,978 [INFO] Out of Domain: Calculate at A dataset, Evaluate at B dataset
2025-02-16 15:16:11,978 [INFO] Loading prompt_path from /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 15:16:11,990 [INFO] prompt的极性是neg
2025-02-16 15:16:11,990 [INFO] Running with alpha: 500.0
2025-02-16 15:16:11,990 [INFO] Running with prompt_type: from neg to pos
2025-02-16 15:16:11,991 [WARNING] 截取prompt_datasize500
2025-02-16 15:16:31,399 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:16:31,400 [INFO] {'md5_hash': '06daa8998220e9f416c42b8f9c45fda8', 'prompt': {'text': 'It made my hair feel flat and uncooperative'}, 'continuation': {'text': ', though my skin felt soft and relaxed.'}, 'num_positive': 0, 'generations': [{'text': "It made my hair feel flat and uncooperative.\n\nI have been using this product for a few years now and I love it! It's great for my hair, keeps it smooth and shiny.\n\nThis is the best shampoo I have ever used. My hair is very fine, so"}, {'text': "It made my hair feel flat and uncooperative.\n\nI've been using this product for a few years now and I love it! It keeps my hair in place all day long, even when I'm working out. The only downside is that it can be a bit pricey, but"}]}
2025-02-16 15:16:50,407 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:16:50,407 [INFO] {'md5_hash': '684d089dd2539bcb726b7960c35e96f2', 'prompt': {'text': 'Protesters have also long said that they would not accept'}, 'continuation': {'text': 'immunity for Saleh and his family in exchange his resignation.'}, 'num_positive': 0, 'generations': [{'text': 'Protesters have also long said that they would not accept the results of the elections, which were won by President-elect Jair Bolsonaro.\n\nThe Brazilian president-elect has been in office since January 1, 2019. He was elected with a majority of votes in the first round of'}, {'text': 'Protesters have also long said that they would not accept the results of the elections.\n\nThe protesters, who are mostly young people, have been calling for a new election and for the resignation of President Michel Aoun.\n\nThe protesters say that Aoun has failed to deliver on his promises and has been'}]}
2025-02-16 15:17:09,789 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:17:09,789 [INFO] {'md5_hash': 'cc4129826978407883aacad181a6f185', 'prompt': {'text': 'but a overclock-failure would not'}, 'continuation': {'text': 'result in black screens.'}, 'num_positive': 0, 'generations': [{'text': "but a overclock-failure would not.\nthe same as the original.\nand the other one is a little bit bigger than the original one.\nand it's very easy to install and use, so you can enjoy your life with it!\nor 100"}, {'text': 'but a overclock-failure would not.\nI\'m not sure what you mean by "a 2014 model" but I think it\'s a 2013 model.\nI don\'t know if this is the same as your problem, but'}]}
2025-02-16 15:17:28,881 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:17:28,881 [INFO] {'md5_hash': '16e85a1055720694e25c0af2b0249f5a', 'prompt': {'text': 'Whatever the truth of it, handwriting is now consigned'}, 'continuation': {'text': ', like hand-carried post, to the realm of snails.'}, 'num_positive': 0, 'generations': [{'text': 'Whatever the truth of it, handwriting is now consigned is a very important work. The book has been written by a very well known person and the author has done an excellent job in writing this book.\n\nThe book has been written by a very well known person and the author has done an excellent job'}, {'text': 'Whatever the truth of it, handwriting is now consigned.\n\nThe 2016 election was a referendum on Donald Trump. The question was whether the country would continue to be governed by an authoritarian leader or whether it would return to its constitutional roots.\n\nTrump’s victory was a repudiation'}]}
2025-02-16 15:18:08,335 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:18:08,336 [INFO] {'md5_hash': '25c4f661f5ccbbe5f43c46f20befe52a', 'prompt': {'text': 'What’s more laughable is the'}, 'continuation': {'text': 'affirmative defenses Rightscorp threw at the wall.'}, 'num_positive': 0, 'generations': [{'text': 'What’s more laughable is the.\n\nThe 2019-20 season of the Metropolitan Opera will be a special one, with the company celebrating its 135th anniversary.\n\nAnd what better way to celebrate than by presenting a new production of Puccini'}, {'text': 'What’s more laughable is the.\n\nI don’t know if you can tell from my face, but I am very excited about this week’s episode of <em>The Flash</em>. I have been waiting for this episode since it was announced and I think it will be'}]}
2025-02-16 15:18:28,150 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:18:28,150 [INFO] {'md5_hash': '5b904b341b6cb4d85bdf60ec06b2539e', 'prompt': {'text': 'But could it be'}, 'continuation': {'text': 'more insidious than that?'}, 'num_positive': 0, 'generations': [{'text': "But could it be?\n\nI'm not sure. I don't know what the deal is with this new guy. He seems to be a nice guy, but he's got some baggage.\n\nI think he was a little too quick to jump on"}, {'text': 'But could it be?\n\nI’m a bit of a sucker for a good story. I love the way people can take something that is mundane and turn it into something magical. I love the way people can take an idea and make it come to life in front'}]}
2025-02-16 15:18:46,936 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:18:46,936 [INFO] {'md5_hash': 'a40fbb2060aeac07d3c4ffe4caa544e6', 'prompt': {'text': 'Another exception is the sale of cigarettes,'}, 'continuation': {'text': 'which is covered by the Jenkins Act.'}, 'num_positive': 0, 'generations': [{'text': 'Another exception is the sale of cigarettes,. In this case, the tax was not a tax on income but a tax on the price of cigarettes. The government could have chosen to impose a sales tax on cigarettes instead of an excise tax.\n\nThe cigarette industry would have been able to pass'}, {'text': 'Another exception is the sale of cigarettes,. The following are some examples of the different types of research and development.\n\nThe 10 Best Ways To Get A Job In Marketing Marketing job marketing jobs marketing\n\n<h3>I have been working in the industry for over 20 years and i'}]}
2025-02-16 15:19:06,389 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:19:06,390 [INFO] {'md5_hash': 'a6231a5805f4f6868cdbe322ed6d9250', 'prompt': {'text': 'Disappointed: Apprentice chef Alex Martin will'}, 'continuation': {'text': 'miss out on her last two instalments.'}, 'num_positive': 0, 'generations': [{'text': 'Disappointed: Apprentice chef Alex Martin will has been given a second chance to prove himself.\n\nThe 32-year-old, who was fired from the hit Channel Seven show after he was caught on camera using racial slurs, has been offered a job as head chef at the'}, {'text': 'Disappointed: Apprentice chef Alex Martin will has a new home in the heart of the city.\n\nThe 30-year-old chef, who was forced to leave his position as head chef at The Glasshouse restaurant in 2016 after being charged with assault, has'}]}
2025-02-16 15:19:46,984 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:19:46,984 [INFO] {'md5_hash': 'b2507e3a0dc9c39b21595cc8df98e1f6', 'prompt': {'text': 'The actual reactor is typically enclosed in a cement building'}, 'continuation': {'text': 'that is built to withstand natural disasters and other threats.'}, 'num_positive': 0, 'generations': [{'text': 'The actual reactor is typically enclosed in a cement building. The concrete walls are 12 inches thick and the floor is 18 inches thick. The building has a steel frame and the roof is supported by trusses. The roof has a total area of 40,000 square'}, {'text': 'The actual reactor is typically enclosed in a cement building, and the heat is transferred to the water in a heat exchanger. The water then flows through a series of pipes to the cooling tower, where it is cooled by air. The air passes through an evaporative cooler and then through a fan that blows'}]}
2025-02-16 15:20:06,280 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:20:06,280 [INFO] {'md5_hash': 'afe25a529b2c2f59fe7a9746f912cfd0', 'prompt': {'text': 'Some, thinking disorder is simply the absence'}, 'continuation': {'text': 'of any system, confuse it with anarchy.'}, 'num_positive': 0, 'generations': [{'text': 'Some, thinking disorder is simply the absence, or a lack of, the ability to think rationally.\n\nThe most common form of this disorder is called schizophrenia.\n\nSchizophrenia is a serious mental illness that affects how you think and behave. It can cause you to have hallucinations (hearing voices'}, {'text': 'Some, thinking disorder is simply the absence, or the lack of, a specific trait.\n\nIt is not a mental illness in itself.\n\nHowever, some people with ASD may have difficulties with social interaction and communication skills.\n\nThey may also have repetitive behaviours or interests that are unusual for'}]}
2025-02-16 15:20:24,394 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:20:24,394 [INFO] {'md5_hash': '7f5156895e0d24711cc3e3d90ccbf9a1', 'prompt': {'text': 'No group claimed responsibility, but Egyptian reports pointed'}, 'continuation': {'text': 'blame at Hamas and other Gaza terror groups.'}, 'num_positive': 0, 'generations': [{'text': 'No group claimed responsibility, but Egyptian reports pointed that the attack was carried out by a group of jihadists from the Sinai Peninsula.\n\nThe Sinai is a hotbed of Islamist militancy and has been plagued by violence in recent years.\n\nIn 2014, more than '}, {'text': 'No group claimed responsibility, but Egyptian reports pointed that the Islamic State was behind the attack.\n\nThe explosion took place at a bus stop in front of a mosque in central Cairo, where worshippers were leaving after Friday prayers.\n\nA security official said 15 people were killed and 24'}]}
2025-02-16 15:20:42,791 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:20:42,791 [INFO] {'md5_hash': '7f19f058a5960ad706e86718c61f4e07', 'prompt': {'text': 'It is also easy to override'}, 'continuation': {'text': ', extend and customize the Configuration.'}, 'num_positive': 0, 'generations': [{'text': 'It is also easy to override a class in the inheritance hierarchy.\n\n<code>class A {\n    public void method() {\n        System.out.println("A");\n    }\n}\n\nclass B extends A {\n    public void method() {\n        System'}, {'text': 'It is also easy to override. It is not a problem for the new version of the code to use the old version of the code.\n\nI have been working on this project for about 10 years and I am very happy with it. I am also very happy with'}]}
2025-02-16 15:21:19,466 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:21:19,467 [INFO] {'md5_hash': '6ceb57c038afdfcf9b1f8196b0f2f3c3', 'prompt': {'text': 'getNumberProperties ( field )'}, 'continuation': {'text': ', calcInfo = this .'}, 'num_positive': 0, 'generations': [{'text': 'getNumberProperties ( field ) );\n    }\n\n    /**\n     * @param $field\n     * @return mixed|null\n     */\n    public function getNumberOfProperties($field) {\n        $this->validateField($field);\n\n        if ($'}, {'text': 'getNumberProperties ( field ) );\n    }\n\n    /**\n     * @param $field\n     * @return mixed|null\n     */\n    public function get_field($field) {\n\n        if (is_array($this->properties)) {\n\n'}]}
2025-02-16 15:22:04,033 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:22:04,033 [INFO] {'md5_hash': '99a53d41506e0837001dc9fda47a0f89', 'prompt': {'text': 'The draft ordinance would require dispensaries to receive a special'}, 'continuation': {'text': 'permit from the city in order to begin operations.'}, 'num_positive': 0, 'generations': [{'text': 'The draft ordinance would require dispensaries to receive a special of 10% of their gross income from the sale of liquor, and to use the money for community projects.\n\nThe City Council has already approved a resolution calling on the state Legislature to pass legislation that would allow cities and counties to impose such'}, {'text': 'The draft ordinance would require dispensaries to receive a special of 10% of their gross income from the sale of alcohol, and would also impose a tax on the sale of alcohol.\n\nThe council is also considering a proposal to introduce a 25% levy on the sale of alcoholic drinks in'}]}
2025-02-16 15:22:27,941 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:22:27,941 [INFO] {'md5_hash': '0c2cbc733309885571e7ebdb69b05ab0', 'prompt': {'text': 'The White House did not respond to'}, 'continuation': {'text': 'a CNBC request for further comment.'}, 'num_positive': 0, 'generations': [{'text': 'The White House did not respond to\'s request for comment.\n\nThe Trump administration has been working to expand the number of immigrants who can enter the country legally, and it has also been working to reduce the number of immigrants who are allowed into the country illegally.\n\n"We\''}, {'text': 'The White House did not respond to’s question.\n\nThe White House did not respond to a request for comment.\n\nThe report comes as the Biden administration is facing criticism from Democrats and Republicans alike over its handling of the crisis at the southern border, which has seen record numbers of'}]}
2025-02-16 15:22:46,063 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:22:46,063 [INFO] {'md5_hash': 'ffc5bbd188bbcb96c34b82a1cb9cf139', 'prompt': {'text': 'For example, Lighting Universe could save some money by'}, 'continuation': {'text': 'setting “piano” bench as a negative keyword.'}, 'num_positive': 0, 'generations': [{'text': 'For example, Lighting Universe could save some money by.\n\nIn the case of the United States, it is a very expensive country to live in. It is also one of the most expensive countries in the world to live in. The average cost of living for a family of four is $10'}, {'text': 'For example, Lighting Universe could save some money by, for example, not having to buy a new light bulb every time it burns out.\n\nThe only thing that is certain is that the cost of energy will continue to rise.\n\nIn the past few years we have seen an increase in electricity prices'}]}
2025-02-16 15:23:21,687 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:23:21,687 [INFO] {'md5_hash': 'f84597942cad62482c256a7d23c95f40', 'prompt': {'text': 'Further medication was classified into'}, 'continuation': {'text': 'groups defined by their indication.'}, 'num_positive': 0, 'generations': [{'text': 'Further medication was classified into and then a more detailed analysis of the. 1986, the journal of educational research. The first example is that you can use to support your points with evidence from the teacher s role in curriculum development, and implementation. 20'}, {'text': 'Further medication was classified into and the treatment of the patients with depression.\n\nThe study included 100 patients with depression, who were divided into two groups: group A (n = 50) received a combination of sertraline and fluoxetine, while'}]}
2025-02-16 15:23:41,971 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:23:41,971 [INFO] {'md5_hash': '4a33b5c0f5b5419c1d2b7be1288cac01', 'prompt': {'text': 'So in the absence of such skills they use the'}, 'continuation': {'text': '“carrot and stick’ technique without the carrot.'}, 'num_positive': 0, 'generations': [{'text': 'So in the absence of such skills they use the. 1986, p. 207). The second is a key aspect of your dissertation or thesis chair and committee members, you may have to be more effective than if it were an extension of this study examined the relationship between'}, {'text': 'So in the absence of such skills they use the, 2014.\n\n<h2>The essay on a person who has had a great impact on my life</h2>\n\nIn this case, we will be able to write your paper for you. We are here to help you with your academic writing'}]}
2025-02-16 15:24:00,558 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:24:00,558 [INFO] {'md5_hash': '12457dc59ff895a0112a622c8060c2c0', 'prompt': {'text': 'The process has become mired in UN bureaucracy after the'}, 'continuation': {'text': 'security council set up a subcommittee to examine the application.'}, 'num_positive': 0, 'generations': [{'text': 'The process has become mired in UN bureaucracy after the and the of 1980s. The process is a form of state intervention in which a country takes over the management of an economy, usually by nationalizing key industries or imposing economic controls.\n\nIn recent years, there has been a'}, {'text': 'The process has become mired in UN bureaucracy after the and the 2015 Paris Agreement. The process is a global agreement to keep global warming below 2 degrees Celsius above pre-industrial levels, and pursue efforts to limit it even further to 1.5 degrees Celsius.\n\nIn this'}]}
2025-02-16 15:24:18,811 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:24:18,811 [INFO] {'md5_hash': '1467fd6a27ba129d7542cb7dc66f9c1d', 'prompt': {'text': 'Earlier this month the ONS said the unemployment rate had'}, 'continuation': {'text': 'fallen to 7.4%, the lowest level since 2009.'}, 'num_positive': 0, 'generations': [{'text': 'Earlier this month the ONS said the unemployment rate had to be 4.5% and that was a very low number.\n\nThe latest figures show that it is 6.2%.\n\nThat is not a good number, but it is still lower than the OECD average of 7.1'}, {'text': 'Earlier this month the ONS said the unemployment rate had increased to 4.5 per cent, up from 3.9 per cent in January and February.\n\nThe ONS said that the increase was due to a rise in the number of people who were unemployed for more than a year, which rose'}]}
2025-02-16 15:24:55,365 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:24:55,365 [INFO] {'md5_hash': '41bc9ecd131d1d1f8b608196e1118bf1', 'prompt': {'text': "The suspect in Tuesday's downtown terror attack"}, 'continuation': {'text': 'arrives with police escort to Bellevue Hospital.'}, 'num_positive': 0, 'generations': [{'text': "The suspect in Tuesday's downtown terror attack was a 29-year-old man who had been on the run for several days.\n\nHe was arrested by police in a suburb of Melbourne, Victoria, after being spotted by a member of the public.\n\nThe man is expected to"}, {'text': "The suspect in Tuesday's downtown terror attack, who was arrested on Wednesday night, is a 25-year-old man from the Western Cape.\n\nThis was confirmed by police spokesperson Colonel Athlenda Mathe.\n\nMathe said the suspect will appear in court on Thursday for a"}]}
2025-02-16 15:25:13,048 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:25:13,048 [INFO] {'md5_hash': '8ba89b679c38d81dd20e8067000a1af4', 'prompt': {'text': 'It lost 14.5 percent of its value'}, 'continuation': {'text': 'in the third quarter of 2008.'}, 'num_positive': 0, 'generations': [{'text': 'It lost 14.5 percent of its value, and the other 85.5 percent is a bonus for the company.\n\nThe company has been able to keep its costs low by not having to pay taxes on its profits, and it has also been able to avoid paying interest on loans'}, {'text': 'It lost 14.5 percent of its value, and the remaining 85.5 percent is paid in cash.\n\nThe deal was announced on Tuesday, with the transaction expected to close in the first quarter of next year.\n\n“We are delighted to have reached an agreement with a leading'}]}
2025-02-16 15:25:30,625 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:25:30,625 [INFO] {'md5_hash': '4418c5d2083b4691da26049c806b4526', 'prompt': {'text': 'But it seems likely too that'}, 'continuation': {'text': 'Heleus will not be left behind.'}, 'num_positive': 0, 'generations': [{'text': 'But it seems likely too that is the most important part of the world. The first time I ever saw a picture of a black hole was in 1967, when I was working on my PhD at Cambridge University.\n\nI had been studying black holes for about two'}, {'text': "But it seems likely too that will be a lot of people who are going to be very good at this and I think that the most important thing is to make sure that you have a good understanding of what's going on in the world.\n\nThe most important thing is to"}]}
2025-02-16 15:25:48,648 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:25:48,648 [INFO] {'md5_hash': '8304662bb7869d6eb68357cf013a4430', 'prompt': {'text': 'Allegations of torture by secret intelligence agencies at Kuli camp'}, 'continuation': {'text': 'have been made by the Baloch community for several decades.'}, 'num_positive': 0, 'generations': [{'text': 'Allegations of torture by secret intelligence agencies at Kuli camp and other facilities have been reported to the United Nations.\n\nThe UN has asked for an investigation into the allegations.\n\nIn a statement, the UN said it was “deeply concerned” about reports of torture and ill-treatment in Zimbabwe’s'}, {'text': 'Allegations of torture by secret intelligence agencies at Kuli camp in South Africa have been denied by the prison authorities.\n\nThe Department of Correctional Services (DCS) has denied allegations that prisoners were tortured at the facility.\n\nThis comes after a report published on <em>News24</em> on Wednesday, which alleged'}]}
2025-02-16 15:26:25,447 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 15:26:25,447 [INFO] {'md5_hash': 'd57568ce10f19bc27be29d47c0d77374', 'prompt': {'text': 'The steepest decreases occurred among men who reported that they'}, 'continuation': {'text': 'spent time caring for and palling around with their children.'}, 'num_positive': 0, 'generations': [{'text': 'The steepest decreases occurred among men who reported that they had a higher risk of death from heart disease, stroke, and cancer.\n\nIn the United States, 1 in 4 women will be diagnosed with breast cancer during their lifetime.\n\nIt is important to note that these rates are based on data'}, {'text': 'The steepest decreases occurred among men who reported that they had been exposed to a high-risk situation, and were not necessarily related to the nature of their work.\n\nIn addition, there was no significant difference in the prevalence of severe depression between those who had been exposed to a high-risk situation and'}]}
2025-02-16 15:26:39,035 [INFO] 训练时间602.1703481674194
2025-02-16 15:26:39,035 [INFO] Show Hyperparameters: 


2025-02-16 15:26:39,035 [INFO]   task: sentiment
2025-02-16 15:26:39,035 [INFO]   layer: 12
2025-02-16 15:26:39,035 [INFO]   LLM: gemma-2-2b
2025-02-16 15:26:39,035 [INFO]   seed: 42
2025-02-16 15:26:39,035 [INFO]   data_size: 1500
2025-02-16 15:26:39,035 [INFO]   device: cpu
2025-02-16 15:26:39,035 [INFO]   alpha: 500.0
2025-02-16 15:26:39,035 [INFO]   method: val_mul
2025-02-16 15:26:39,035 [INFO]   topk_mean: 100
2025-02-16 15:26:39,035 [INFO]   topk_cnt: 100
2025-02-16 15:26:39,035 [INFO]   batch_size: 32
2025-02-16 15:26:39,035 [INFO]   source: neg
2025-02-16 15:26:39,035 [INFO]   target: pos
2025-02-16 15:26:39,035 [INFO]   prompt_source: neg
2025-02-16 15:26:39,035 [INFO]   prompt_data_size: 500
2025-02-16 15:26:39,035 [INFO]   mean_type: dif_mean
2025-02-16 15:26:39,036 [INFO]   steer_type: all
2025-02-16 15:26:39,036 [INFO]   output_dir: ./results/sentiment_gemma/
2025-02-16 15:26:39,036 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 15:26:39,036 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 15:26:39,036 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 15:26:39,036 [INFO]   temperature: 0.9
2025-02-16 15:26:39,036 [INFO]   top_p: 0.3
2025-02-16 15:26:39,036 [INFO]   freq_penalty: 1.0
2025-02-16 15:26:39,036 [INFO]   example_prompt: But the lack of financial aid would| The passage of the AI Act will
2025-02-16 15:26:39,036 [INFO]   debug: 0
2025-02-16 15:26:39,036 [INFO]   save_no_steer: 0
2025-02-16 15:26:39,036 [INFO]   is_norm_delta_matrix: 0
2025-02-16 15:26:39,036 [INFO]   use_cache: 0
2025-02-16 15:26:39,036 [INFO]   repeat_num: 2
2025-02-16 15:26:39,036 [INFO]   gen_batch_size: 16
2025-02-16 15:26:39,036 [INFO]   real_data_size_for_train: 1500
2025-02-16 15:26:39,036 [INFO] sentiment:neg->pos
