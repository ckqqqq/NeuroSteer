2025-02-16 12:39:19,859 [INFO] Logging initialized. Logs will be saved to ./results/sentiment_gemma/gemma-2-2b_sentiment_layer_6_datasize_1000_batchsize32_topK_100/alpha_700.0_from_neg_to_pos_prompt_neg_mean_dif_mean_steertype_all_device_cpu/execution.log
2025-02-16 12:39:19,859 [INFO] Show Hyperparameters: 


2025-02-16 12:39:19,859 [INFO]   task: sentiment
2025-02-16 12:39:19,859 [INFO]   layer: 6
2025-02-16 12:39:19,859 [INFO]   LLM: gemma-2-2b
2025-02-16 12:39:19,859 [INFO]   seed: 42
2025-02-16 12:39:19,859 [INFO]   data_size: 1000
2025-02-16 12:39:19,859 [INFO]   device: cpu
2025-02-16 12:39:19,859 [INFO]   alpha: 700.0
2025-02-16 12:39:19,859 [INFO]   method: val_mul
2025-02-16 12:39:19,859 [INFO]   topk_mean: 100
2025-02-16 12:39:19,859 [INFO]   topk_cnt: 100
2025-02-16 12:39:19,859 [INFO]   batch_size: 32
2025-02-16 12:39:19,859 [INFO]   source: neg
2025-02-16 12:39:19,859 [INFO]   target: pos
2025-02-16 12:39:19,859 [INFO]   prompt_source: neg
2025-02-16 12:39:19,859 [INFO]   prompt_data_size: 500
2025-02-16 12:39:19,859 [INFO]   mean_type: dif_mean
2025-02-16 12:39:19,859 [INFO]   steer_type: all
2025-02-16 12:39:19,859 [INFO]   output_dir: ./results/sentiment_gemma/
2025-02-16 12:39:19,859 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:39:19,859 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:39:19,860 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:39:19,860 [INFO]   temperature: 0.9
2025-02-16 12:39:19,860 [INFO]   top_p: 0.3
2025-02-16 12:39:19,860 [INFO]   freq_penalty: 1.0
2025-02-16 12:39:19,860 [INFO]   example_prompt: But the lack of financial aid would| The passage of the AI Act will
2025-02-16 12:39:19,860 [INFO]   debug: 1
2025-02-16 12:39:19,860 [INFO]   save_no_steer: 1
2025-02-16 12:39:19,860 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:39:19,860 [INFO]   use_cache: 0
2025-02-16 12:39:19,860 [INFO]   repeat_num: 2
2025-02-16 12:39:19,860 [INFO]   gen_batch_size: 16
2025-02-16 12:39:19,860 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 12:39:19,860 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:39:19,860 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-16 12:39:19,860 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-16 12:39:19,962 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 12:39:19,966 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-16 12:39:19,966 [INFO] Loading Model Loading SAE for layer 6 gemma-2-2b
2025-02-16 12:39:53,160 [INFO] Loading model: gemma-2-2b
2025-02-16 12:39:53,161 [WARNING] You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constant Setting center_unembed=False instead.
2025-02-16 12:40:25,992 [WARNING] You are not using LayerNorm, so the writing weights can't be centered! Skipping
2025-02-16 12:40:34,060 [INFO] model architecture for gemma-2-2b HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (blocks): ModuleList(
    (0-25): 26 x TransformerBlock(
      (ln1): RMSNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln1_post): RMSNorm(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): RMSNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2_post): RMSNorm(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): GroupedQueryAttention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
        (hook_rot_k): HookPoint()
        (hook_rot_q): HookPoint()
      )
      (mlp): GatedMLP(
        (hook_pre): HookPoint()
        (hook_pre_linear): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): RMSNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GemmaTokenizerFast(name_or_path='google/gemma-2b', vocab_size=256000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<start_of_turn>', '<end_of_turn>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	0: AddedToken("<pad>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	1: AddedToken("<eos>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	2: AddedToken("<bos>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	3: AddedToken("<unk>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	4: AddedToken("<mask>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	5: AddedToken("<2mass>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	6: AddedToken("[@BOS@]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	7: AddedToken("<unused0>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	8: AddedToken("<unused1>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	9: AddedToken("<unused2>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	10: AddedToken("<unused3>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	11: AddedToken("<unused4>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	12: AddedToken("<unused5>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	13: AddedToken("<unused6>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	14: AddedToken("<unused7>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	15: AddedToken("<unused8>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	16: AddedToken("<unused9>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	17: AddedToken("<unused10>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	18: AddedToken("<unused11>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	19: AddedToken("<unused12>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	20: AddedToken("<unused13>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	21: AddedToken("<unused14>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	22: AddedToken("<unused15>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	23: AddedToken("<unused16>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	24: AddedToken("<unused17>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	25: AddedToken("<unused18>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	26: AddedToken("<unused19>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	27: AddedToken("<unused20>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	28: AddedToken("<unused21>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	29: AddedToken("<unused22>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	30: AddedToken("<unused23>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	31: AddedToken("<unused24>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	32: AddedToken("<unused25>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	33: AddedToken("<unused26>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	34: AddedToken("<unused27>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	35: AddedToken("<unused28>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	36: AddedToken("<unused29>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	37: AddedToken("<unused30>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	38: AddedToken("<unused31>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	39: AddedToken("<unused32>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	40: AddedToken("<unused33>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	41: AddedToken("<unused34>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	42: AddedToken("<unused35>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	43: AddedToken("<unused36>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	44: AddedToken("<unused37>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	45: AddedToken("<unused38>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	46: AddedToken("<unused39>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	47: AddedToken("<unused40>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	48: AddedToken("<unused41>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	49: AddedToken("<unused42>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	50: AddedToken("<unused43>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	51: AddedToken("<unused44>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	52: AddedToken("<unused45>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	53: AddedToken("<unused46>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	54: AddedToken("<unused47>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	55: AddedToken("<unused48>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	56: AddedToken("<unused49>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	57: AddedToken("<unused50>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	58: AddedToken("<unused51>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	59: AddedToken("<unused52>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	60: AddedToken("<unused53>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	61: AddedToken("<unused54>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	62: AddedToken("<unused55>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	63: AddedToken("<unused56>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	64: AddedToken("<unused57>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	65: AddedToken("<unused58>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	66: AddedToken("<unused59>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	67: AddedToken("<unused60>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	68: AddedToken("<unused61>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	69: AddedToken("<unused62>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	70: AddedToken("<unused63>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	71: AddedToken("<unused64>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	72: AddedToken("<unused65>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	73: AddedToken("<unused66>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	74: AddedToken("<unused67>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	75: AddedToken("<unused68>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	76: AddedToken("<unused69>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	77: AddedToken("<unused70>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	78: AddedToken("<unused71>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	79: AddedToken("<unused72>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	80: AddedToken("<unused73>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	81: AddedToken("<unused74>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	82: AddedToken("<unused75>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	83: AddedToken("<unused76>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	84: AddedToken("<unused77>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	85: AddedToken("<unused78>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	86: AddedToken("<unused79>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	87: AddedToken("<unused80>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	88: AddedToken("<unused81>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	89: AddedToken("<unused82>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	90: AddedToken("<unused83>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	91: AddedToken("<unused84>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	92: AddedToken("<unused85>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	93: AddedToken("<unused86>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	94: AddedToken("<unused87>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	95: AddedToken("<unused88>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	96: AddedToken("<unused89>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	97: AddedToken("<unused90>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	98: AddedToken("<unused91>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	99: AddedToken("<unused92>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	100: AddedToken("<unused93>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	101: AddedToken("<unused94>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	102: AddedToken("<unused95>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	103: AddedToken("<unused96>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	104: AddedToken("<unused97>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	105: AddedToken("<unused98>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	106: AddedToken("<start_of_turn>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	107: AddedToken("<end_of_turn>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	108: AddedToken("
", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	109: AddedToken("

", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	110: AddedToken("


", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	111: AddedToken("



", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	112: AddedToken("




", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	113: AddedToken("





", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	114: AddedToken("






", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	115: AddedToken("







", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	116: AddedToken("








", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	117: AddedToken("









", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	118: AddedToken("










", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	119: AddedToken("











", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	120: AddedToken("












", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	121: AddedToken("













", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	122: AddedToken("














", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	123: AddedToken("















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	124: AddedToken("
















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	125: AddedToken("

















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	126: AddedToken("


















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	127: AddedToken("



















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	128: AddedToken("




















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	129: AddedToken("





















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	130: AddedToken("






















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	131: AddedToken("























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	132: AddedToken("
























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	133: AddedToken("

























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	134: AddedToken("


























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	135: AddedToken("



























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	136: AddedToken("




























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	137: AddedToken("





























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	138: AddedToken("






























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	139: AddedToken("▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	140: AddedToken("▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	141: AddedToken("▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	142: AddedToken("▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	143: AddedToken("▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	144: AddedToken("▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	145: AddedToken("▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	146: AddedToken("▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	147: AddedToken("▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	148: AddedToken("▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	149: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	150: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	152: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	153: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	154: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	155: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	156: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	157: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	158: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	159: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	160: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	161: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	162: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	163: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	164: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	165: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	166: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	167: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	168: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	169: AddedToken("<table>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	170: AddedToken("<caption>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	171: AddedToken("<thead>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	172: AddedToken("<tbody>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	173: AddedToken("<tfoot>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	174: AddedToken("<tr>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	175: AddedToken("<th>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	176: AddedToken("<td>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	177: AddedToken("</table>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	178: AddedToken("</caption>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	179: AddedToken("</thead>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	180: AddedToken("</tbody>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	181: AddedToken("</tfoot>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	182: AddedToken("</tr>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	183: AddedToken("</th>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	184: AddedToken("</td>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	185: AddedToken("<h1>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	186: AddedToken("<h2>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	187: AddedToken("<h3>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	188: AddedToken("<h4>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	189: AddedToken("<h5>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	190: AddedToken("<h6>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	191: AddedToken("<blockquote>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	192: AddedToken("</h1>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	193: AddedToken("</h2>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	194: AddedToken("</h3>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	195: AddedToken("</h4>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	196: AddedToken("</h5>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	197: AddedToken("</h6>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	198: AddedToken("</blockquote>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	199: AddedToken("<strong>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	200: AddedToken("<em>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	201: AddedToken("<b>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	202: AddedToken("<i>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	203: AddedToken("<u>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	204: AddedToken("<s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	205: AddedToken("<sub>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	206: AddedToken("<sup>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	207: AddedToken("<code>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	208: AddedToken("</strong>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	209: AddedToken("</em>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	210: AddedToken("</b>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	211: AddedToken("</i>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	212: AddedToken("</u>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	213: AddedToken("</s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	214: AddedToken("</sub>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	215: AddedToken("</sup>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	216: AddedToken("</code>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
2025-02-16 12:40:34,061 [INFO] 缓存 ./results/sentiment_gemma/gemma-2-2b_sentiment_layer_6_datasize_1000_batchsize32_topK_100/steer_info_cache_of_gemma-2-2b_l6.pkl 不存在，缓存 steer_info
2025-02-16 12:40:34,084 [INFO] :>> sentiment : from neg to pos
2025-02-16 12:40:34,098 [INFO] positive
2025-02-16 12:40:34,104 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:42:33,350 [INFO] Total non-zero element shape: torch.Size([16384])
2025-02-16 12:42:33,369 [INFO] negative
2025-02-16 12:42:33,383 [INFO] Running model with cache to obtain hidden states
2025-02-16 12:44:22,635 [INFO] Total non-zero element shape: torch.Size([16384])
2025-02-16 12:44:22,659 [INFO] steer_info 已保存到缓存 ./results/sentiment_gemma/gemma-2-2b_sentiment_layer_6_datasize_1000_batchsize32_topK_100/steer_info_cache_of_gemma-2-2b_l6.pkl
2025-02-16 12:44:22,660 [INFO] 转向方向 dif_pos-neg_relu
2025-02-16 12:44:22,660 [INFO] sae cfg.hook_name 挂载名称: blocks.0.hook_resid_post
2025-02-16 12:44:22,664 [INFO] delta_matrix: tensor([-0.0011,  0.0026,  0.0016,  0.0008, -0.0014], grad_fn=<SliceBackward0>)
2025-02-16 12:44:22,664 [INFO] Generating texts **without** steering... 
2025-02-16 12:44:22,665 [INFO] 无转向结果
2025-02-16 12:44:22,669 [INFO] 无干预
2025-02-16 12:44:35,657 [INFO] 当前批次共处理2个prompt
2025-02-16 12:44:35,657 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 12:44:35,657 [INFO] 生成 1: | be a major blow to the city's efforts to improve its finances.

The state has not yet released its final budget, but it is expected to include a $10 million cut in local aid.

The city has already been forced to|
2025-02-16 12:44:35,657 [INFO] 生成 2: | be a major blow to the state's colleges and universities, which have been struggling with declining enrollment and rising costs.

The House proposal would cut $10 million from the state's share of higher education funding, which is currently about $|
2025-02-16 12:44:35,657 [INFO] 生成 3: | not be a problem for the 20-year-old, who is a full-time student at St. Cloud State University and works part time as a waitress.

"I'm going to do it," she said. "I|
2025-02-16 12:44:35,658 [INFO] Prompt 2: | The passage of the AI Act will|
2025-02-16 12:44:35,658 [INFO] 生成 1: | be a major step forward in the regulation of artificial intelligence. It will set out clear rules for the development, deployment and use of AI systems, ensuring that they are safe and trustworthy.

The EU is committed to leading the way in regulating AI,|
2025-02-16 12:44:35,658 [INFO] 生成 2: | be a milestone in the development of artificial intelligence (AI) and machine learning (ML) technologies.

The European Union’s AI Act is a comprehensive set of rules that will govern the development, deployment, and use of AI systems in Europe.|
2025-02-16 12:44:35,658 [INFO] 生成 3: | be a major step forward in the regulation of artificial intelligence. It will help to ensure that AI is used responsibly and ethically, and that it does not pose a risk to public safety or security.

The EU has been working on this legislation for several|
2025-02-16 12:44:35,658 [INFO] 干预之后的结果
2025-02-16 12:44:35,658 [INFO] 干预方向neg->pos,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 12:44:35,658 [INFO] ** Generating texts with steering... Target **
2025-02-16 12:44:35,658 [INFO] form neg to pos
2025-02-16 12:44:35,658 [INFO] 转向结果
2025-02-16 12:44:48,769 [INFO] 当前批次共处理2个prompt
2025-02-16 12:44:48,769 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 12:44:48,769 [INFO] 生成 1: | not be a problem for the young man, who is studying at the University of California, Berkeley.

“I’m going to work and pay my way through school,” he said. “I don’t want to be a burden on anyone|
2025-02-16 12:44:48,770 [INFO] 生成 2: | not be a problem for him.

"I'm going to work," he said. "I'm going to work and I'll pay my own way."

The 18-year-old is one of 2,|
2025-02-16 12:44:48,770 [INFO] 生成 3: | not be the only thing that would be missing in this year’s edition.

The 2019 edition of the festival will also see a reduction in its number of participants, as well as a change in its format.

The festival|
2025-02-16 12:44:48,770 [INFO] Prompt 2: | The passage of the AI Act will|
2025-02-16 12:44:48,770 [INFO] 生成 1: | be a significant step in the evolution of AI and will provide a legal framework for the development and use of AI systems.

The passage of the AI Act is an important milestone in Europe’s efforts to regulate artificial intelligence (AI) technologies. The|
2025-02-16 12:44:48,770 [INFO] 生成 2: | be a significant step in the direction of an inclusive and sustainable society.

The law is expected to ensure that persons with disabilities are included in all aspects of life, including employment, education, health care and social services.

It will also help to|
2025-02-16 12:44:48,770 [INFO] 生成 3: | be a great milestone in the history of Nigeria. It is an opportunity for us to move from being a country that has been dominated by the whims and caprices of human beings to one where we have a constitution that is guided by artificial intelligence.

|
2025-02-16 12:44:48,773 [INFO] debug mode,show example, no full dataset eval
2025-02-16 12:44:48,773 [INFO] 训练时间228.59824872016907
2025-02-16 12:44:48,773 [INFO] Show Hyperparameters: 


2025-02-16 12:44:48,773 [INFO]   task: sentiment
2025-02-16 12:44:48,773 [INFO]   layer: 6
2025-02-16 12:44:48,773 [INFO]   LLM: gemma-2-2b
2025-02-16 12:44:48,773 [INFO]   seed: 42
2025-02-16 12:44:48,773 [INFO]   data_size: 1000
2025-02-16 12:44:48,773 [INFO]   device: cpu
2025-02-16 12:44:48,773 [INFO]   alpha: 700.0
2025-02-16 12:44:48,773 [INFO]   method: val_mul
2025-02-16 12:44:48,773 [INFO]   topk_mean: 100
2025-02-16 12:44:48,773 [INFO]   topk_cnt: 100
2025-02-16 12:44:48,774 [INFO]   batch_size: 32
2025-02-16 12:44:48,774 [INFO]   source: neg
2025-02-16 12:44:48,774 [INFO]   target: pos
2025-02-16 12:44:48,774 [INFO]   prompt_source: neg
2025-02-16 12:44:48,774 [INFO]   prompt_data_size: 500
2025-02-16 12:44:48,774 [INFO]   mean_type: dif_mean
2025-02-16 12:44:48,774 [INFO]   steer_type: all
2025-02-16 12:44:48,774 [INFO]   output_dir: ./results/sentiment_gemma/
2025-02-16 12:44:48,774 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 12:44:48,774 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 12:44:48,774 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 12:44:48,774 [INFO]   temperature: 0.9
2025-02-16 12:44:48,774 [INFO]   top_p: 0.3
2025-02-16 12:44:48,774 [INFO]   freq_penalty: 1.0
2025-02-16 12:44:48,774 [INFO]   example_prompt: But the lack of financial aid would| The passage of the AI Act will
2025-02-16 12:44:48,774 [INFO]   debug: 1
2025-02-16 12:44:48,774 [INFO]   save_no_steer: 1
2025-02-16 12:44:48,774 [INFO]   is_norm_delta_matrix: 0
2025-02-16 12:44:48,774 [INFO]   use_cache: 0
2025-02-16 12:44:48,774 [INFO]   repeat_num: 2
2025-02-16 12:44:48,774 [INFO]   gen_batch_size: 16
2025-02-16 12:44:48,774 [INFO]   real_data_size_for_train: 1000
2025-02-16 12:44:48,774 [INFO] sentiment:neg->pos
2025-02-16 13:49:47,093 [INFO] Logging initialized. Logs will be saved to ./results/sentiment_gemma/gemma-2-2b_sentiment_layer_6_datasize_1000_batchsize32_topK_100/alpha_700.0_from_neg_to_pos_prompt_neg_mean_dif_mean_steertype_all_device_cpu/execution.log
2025-02-16 13:49:47,093 [INFO] Show Hyperparameters: 


2025-02-16 13:49:47,093 [INFO]   task: sentiment
2025-02-16 13:49:47,093 [INFO]   layer: 6
2025-02-16 13:49:47,093 [INFO]   LLM: gemma-2-2b
2025-02-16 13:49:47,093 [INFO]   seed: 42
2025-02-16 13:49:47,093 [INFO]   data_size: 1000
2025-02-16 13:49:47,093 [INFO]   device: cpu
2025-02-16 13:49:47,093 [INFO]   alpha: 700.0
2025-02-16 13:49:47,093 [INFO]   method: val_mul
2025-02-16 13:49:47,093 [INFO]   topk_mean: 100
2025-02-16 13:49:47,093 [INFO]   topk_cnt: 100
2025-02-16 13:49:47,094 [INFO]   batch_size: 32
2025-02-16 13:49:47,094 [INFO]   source: neg
2025-02-16 13:49:47,094 [INFO]   target: pos
2025-02-16 13:49:47,094 [INFO]   prompt_source: neg
2025-02-16 13:49:47,094 [INFO]   prompt_data_size: 500
2025-02-16 13:49:47,094 [INFO]   mean_type: dif_mean
2025-02-16 13:49:47,094 [INFO]   steer_type: all
2025-02-16 13:49:47,094 [INFO]   output_dir: ./results/sentiment_gemma/
2025-02-16 13:49:47,094 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 13:49:47,094 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 13:49:47,094 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 13:49:47,094 [INFO]   temperature: 0.9
2025-02-16 13:49:47,094 [INFO]   top_p: 0.3
2025-02-16 13:49:47,094 [INFO]   freq_penalty: 1.0
2025-02-16 13:49:47,094 [INFO]   example_prompt: But the lack of financial aid would| The passage of the AI Act will
2025-02-16 13:49:47,094 [INFO]   debug: 0
2025-02-16 13:49:47,094 [INFO]   save_no_steer: 1
2025-02-16 13:49:47,094 [INFO]   is_norm_delta_matrix: 0
2025-02-16 13:49:47,094 [INFO]   use_cache: 0
2025-02-16 13:49:47,094 [INFO]   repeat_num: 2
2025-02-16 13:49:47,094 [INFO]   gen_batch_size: 16
2025-02-16 13:49:47,094 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 13:49:47,095 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 13:49:47,095 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5***
2025-02-16 13:49:47,095 [WARNING] Repo card metadata block was not found. Setting CardData to empty.
2025-02-16 13:49:47,204 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 13:49:47,209 [INFO] 检查数据量 Selected 3310 negative, 1624 positive, and 3610 neutral samples
2025-02-16 13:49:47,209 [INFO] Loading Model Loading SAE for layer 6 gemma-2-2b
2025-02-16 13:50:26,514 [INFO] Loading model: gemma-2-2b
2025-02-16 13:50:26,515 [WARNING] You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constant Setting center_unembed=False instead.
2025-02-16 13:51:01,710 [WARNING] You are not using LayerNorm, so the writing weights can't be centered! Skipping
2025-02-16 13:51:11,248 [INFO] model architecture for gemma-2-2b HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (blocks): ModuleList(
    (0-25): 26 x TransformerBlock(
      (ln1): RMSNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln1_post): RMSNorm(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): RMSNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2_post): RMSNorm(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): GroupedQueryAttention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
        (hook_rot_k): HookPoint()
        (hook_rot_q): HookPoint()
      )
      (mlp): GatedMLP(
        (hook_pre): HookPoint()
        (hook_pre_linear): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): RMSNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GemmaTokenizerFast(name_or_path='google/gemma-2b', vocab_size=256000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<start_of_turn>', '<end_of_turn>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	0: AddedToken("<pad>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	1: AddedToken("<eos>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	2: AddedToken("<bos>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	3: AddedToken("<unk>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	4: AddedToken("<mask>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	5: AddedToken("<2mass>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	6: AddedToken("[@BOS@]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	7: AddedToken("<unused0>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	8: AddedToken("<unused1>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	9: AddedToken("<unused2>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	10: AddedToken("<unused3>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	11: AddedToken("<unused4>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	12: AddedToken("<unused5>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	13: AddedToken("<unused6>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	14: AddedToken("<unused7>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	15: AddedToken("<unused8>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	16: AddedToken("<unused9>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	17: AddedToken("<unused10>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	18: AddedToken("<unused11>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	19: AddedToken("<unused12>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	20: AddedToken("<unused13>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	21: AddedToken("<unused14>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	22: AddedToken("<unused15>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	23: AddedToken("<unused16>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	24: AddedToken("<unused17>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	25: AddedToken("<unused18>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	26: AddedToken("<unused19>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	27: AddedToken("<unused20>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	28: AddedToken("<unused21>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	29: AddedToken("<unused22>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	30: AddedToken("<unused23>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	31: AddedToken("<unused24>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	32: AddedToken("<unused25>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	33: AddedToken("<unused26>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	34: AddedToken("<unused27>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	35: AddedToken("<unused28>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	36: AddedToken("<unused29>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	37: AddedToken("<unused30>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	38: AddedToken("<unused31>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	39: AddedToken("<unused32>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	40: AddedToken("<unused33>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	41: AddedToken("<unused34>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	42: AddedToken("<unused35>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	43: AddedToken("<unused36>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	44: AddedToken("<unused37>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	45: AddedToken("<unused38>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	46: AddedToken("<unused39>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	47: AddedToken("<unused40>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	48: AddedToken("<unused41>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	49: AddedToken("<unused42>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	50: AddedToken("<unused43>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	51: AddedToken("<unused44>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	52: AddedToken("<unused45>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	53: AddedToken("<unused46>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	54: AddedToken("<unused47>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	55: AddedToken("<unused48>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	56: AddedToken("<unused49>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	57: AddedToken("<unused50>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	58: AddedToken("<unused51>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	59: AddedToken("<unused52>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	60: AddedToken("<unused53>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	61: AddedToken("<unused54>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	62: AddedToken("<unused55>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	63: AddedToken("<unused56>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	64: AddedToken("<unused57>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	65: AddedToken("<unused58>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	66: AddedToken("<unused59>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	67: AddedToken("<unused60>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	68: AddedToken("<unused61>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	69: AddedToken("<unused62>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	70: AddedToken("<unused63>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	71: AddedToken("<unused64>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	72: AddedToken("<unused65>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	73: AddedToken("<unused66>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	74: AddedToken("<unused67>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	75: AddedToken("<unused68>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	76: AddedToken("<unused69>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	77: AddedToken("<unused70>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	78: AddedToken("<unused71>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	79: AddedToken("<unused72>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	80: AddedToken("<unused73>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	81: AddedToken("<unused74>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	82: AddedToken("<unused75>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	83: AddedToken("<unused76>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	84: AddedToken("<unused77>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	85: AddedToken("<unused78>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	86: AddedToken("<unused79>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	87: AddedToken("<unused80>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	88: AddedToken("<unused81>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	89: AddedToken("<unused82>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	90: AddedToken("<unused83>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	91: AddedToken("<unused84>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	92: AddedToken("<unused85>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	93: AddedToken("<unused86>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	94: AddedToken("<unused87>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	95: AddedToken("<unused88>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	96: AddedToken("<unused89>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	97: AddedToken("<unused90>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	98: AddedToken("<unused91>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	99: AddedToken("<unused92>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	100: AddedToken("<unused93>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	101: AddedToken("<unused94>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	102: AddedToken("<unused95>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	103: AddedToken("<unused96>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	104: AddedToken("<unused97>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	105: AddedToken("<unused98>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	106: AddedToken("<start_of_turn>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	107: AddedToken("<end_of_turn>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	108: AddedToken("
", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	109: AddedToken("

", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	110: AddedToken("


", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	111: AddedToken("



", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	112: AddedToken("




", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	113: AddedToken("





", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	114: AddedToken("






", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	115: AddedToken("







", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	116: AddedToken("








", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	117: AddedToken("









", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	118: AddedToken("










", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	119: AddedToken("











", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	120: AddedToken("












", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	121: AddedToken("













", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	122: AddedToken("














", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	123: AddedToken("















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	124: AddedToken("
















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	125: AddedToken("

















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	126: AddedToken("


















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	127: AddedToken("



















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	128: AddedToken("




















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	129: AddedToken("





















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	130: AddedToken("






















", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	131: AddedToken("























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	132: AddedToken("
























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	133: AddedToken("

























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	134: AddedToken("


























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	135: AddedToken("



























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	136: AddedToken("




























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	137: AddedToken("





























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	138: AddedToken("






























", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	139: AddedToken("▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	140: AddedToken("▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	141: AddedToken("▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	142: AddedToken("▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	143: AddedToken("▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	144: AddedToken("▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	145: AddedToken("▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	146: AddedToken("▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	147: AddedToken("▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	148: AddedToken("▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	149: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	150: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	152: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	153: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	154: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	155: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	156: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	157: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	158: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	159: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	160: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	161: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	162: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	163: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	164: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	165: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	166: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	167: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	168: AddedToken("▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	169: AddedToken("<table>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	170: AddedToken("<caption>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	171: AddedToken("<thead>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	172: AddedToken("<tbody>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	173: AddedToken("<tfoot>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	174: AddedToken("<tr>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	175: AddedToken("<th>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	176: AddedToken("<td>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	177: AddedToken("</table>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	178: AddedToken("</caption>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	179: AddedToken("</thead>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	180: AddedToken("</tbody>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	181: AddedToken("</tfoot>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	182: AddedToken("</tr>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	183: AddedToken("</th>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	184: AddedToken("</td>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	185: AddedToken("<h1>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	186: AddedToken("<h2>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	187: AddedToken("<h3>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	188: AddedToken("<h4>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	189: AddedToken("<h5>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	190: AddedToken("<h6>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	191: AddedToken("<blockquote>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	192: AddedToken("</h1>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	193: AddedToken("</h2>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	194: AddedToken("</h3>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	195: AddedToken("</h4>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	196: AddedToken("</h5>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	197: AddedToken("</h6>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	198: AddedToken("</blockquote>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	199: AddedToken("<strong>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	200: AddedToken("<em>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	201: AddedToken("<b>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	202: AddedToken("<i>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	203: AddedToken("<u>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	204: AddedToken("<s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	205: AddedToken("<sub>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	206: AddedToken("<sup>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	207: AddedToken("<code>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	208: AddedToken("</strong>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	209: AddedToken("</em>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	210: AddedToken("</b>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	211: AddedToken("</i>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	212: AddedToken("</u>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	213: AddedToken("</s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	214: AddedToken("</sub>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	215: AddedToken("</sup>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	216: AddedToken("</code>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
2025-02-16 13:51:11,249 [INFO] 缓存 ./results/sentiment_gemma/gemma-2-2b_sentiment_layer_6_datasize_1000_batchsize32_topK_100/steer_info_cache_of_gemma-2-2b_l6.pkl 不存在，缓存 steer_info
2025-02-16 13:51:11,272 [INFO] :>> sentiment : from neg to pos
2025-02-16 13:51:11,289 [INFO] positive
2025-02-16 13:51:11,296 [INFO] Running model with cache to obtain hidden states
2025-02-16 13:55:06,139 [INFO] Total non-zero element shape: torch.Size([16384])
2025-02-16 13:55:06,179 [INFO] negative
2025-02-16 13:55:06,192 [INFO] Running model with cache to obtain hidden states
2025-02-16 13:58:46,795 [INFO] Total non-zero element shape: torch.Size([16384])
2025-02-16 13:58:46,828 [INFO] steer_info 已保存到缓存 ./results/sentiment_gemma/gemma-2-2b_sentiment_layer_6_datasize_1000_batchsize32_topK_100/steer_info_cache_of_gemma-2-2b_l6.pkl
2025-02-16 13:58:46,829 [INFO] 转向方向 dif_pos-neg_relu
2025-02-16 13:58:46,829 [INFO] sae cfg.hook_name 挂载名称: blocks.0.hook_resid_post
2025-02-16 13:58:46,832 [INFO] Generating texts **without** steering... 
2025-02-16 13:58:46,832 [INFO] 无转向结果
2025-02-16 13:58:46,837 [INFO] 无干预
2025-02-16 13:59:20,665 [INFO] 当前批次共处理2个prompt
2025-02-16 13:59:20,665 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 13:59:20,665 [INFO] 生成 1: | be a major blow to the state's economy, said David M. Jones, president of the Connecticut Business and Industry Association.

"The impact on our economy would be devastating," he said. "We are already seeing a decline in business activity|
2025-02-16 13:59:20,665 [INFO] 生成 2: | be a blow to the university, which has been hit hard by declining enrollment and state budget cuts.

The university is asking for $1.5 million in state funding for its proposed $30 million renovation of the former St. John’s|
2025-02-16 13:59:20,665 [INFO] 生成 3: | be a blow to the 10,000 students who attend the university each year.

The state’s budget crisis has forced lawmakers to cut funding for higher education.

“We are in a very difficult situation,” said John B|
2025-02-16 13:59:20,665 [INFO] Prompt 2: | The passage of the AI Act will|
2025-02-16 13:59:20,665 [INFO] 生成 1: | help to protect people from harm caused by AI systems, and to ensure that AI is developed in a way that is safe and ethical.

The EU’s new Artificial Intelligence Act (AI Act) will be one of the most comprehensive pieces of legislation|
2025-02-16 13:59:20,665 [INFO] 生成 2: | be a significant step forward in ensuring that artificial intelligence (AI) is developed and used responsibly, with the aim of preventing harm to people and society.

The AI Act is a European Union (EU) regulation that sets out requirements for the development,|
2025-02-16 13:59:20,665 [INFO] 生成 3: | be a significant step forward in regulating artificial intelligence (AI) technologies, which are becoming increasingly prevalent in our daily lives. The act aims to ensure that AI systems are safe, secure, and transparent.

The AI Act is expected to have a positive|
2025-02-16 13:59:20,665 [INFO] 干预之后的结果
2025-02-16 13:59:20,665 [INFO] 干预方向neg->pos,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 13:59:20,665 [INFO] ** Generating texts with steering... Target **
2025-02-16 13:59:20,665 [INFO] form neg to pos
2025-02-16 13:59:20,665 [INFO] 转向结果
2025-02-16 13:59:52,973 [INFO] 当前批次共处理2个prompt
2025-02-16 13:59:52,973 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 13:59:52,974 [INFO] 生成 1: | be a problem for the 10,000 people who have been waiting for their turn to get their documents.

The Immigration Department has been under fire over its handling of applications and processing times.

The department is currently working on a|
2025-02-16 13:59:52,974 [INFO] 生成 2: | be a problem for many students.

“It’s going to be a big problem,” said 18-year-old student, Yassine El Bouchachi. “I’m not sure I can afford it.”

The|
2025-02-16 13:59:52,974 [INFO] 生成 3: | be a major blow to the program, which has been a lifeline for many students.

“It’s not just about the money,” said David Glickman, director of the Student Financial Aid Office at Northeastern University. “It’s about|
2025-02-16 13:59:52,974 [INFO] Prompt 2: | The passage of the AI Act will|
2025-02-16 13:59:52,974 [INFO] 生成 1: | be an important milestone in the history of Artificial Intelligence. It is a historic moment for all those who have been working on this issue for years, and it is also a moment of great responsibility.

The AI Act will set out the rules that govern|
2025-02-16 13:59:52,974 [INFO] 生成 2: | be a turning point in the history of artificial intelligence.

The European Parliament has approved the Artificial Intelligence Act, which is expected to become law in 2024.

The text, which was adopted by 516 votes to |
2025-02-16 13:59:52,974 [INFO] 生成 3: | be an important step in the development of artificial intelligence, which is already present in our daily lives. It will also allow us to have a more effective and efficient regulation of this technology, which is growing exponentially.

The European Parliament has approved the AI|
2025-02-16 13:59:52,978 [INFO] Provide No Steer Result 提供无干预对照样本
2025-02-16 13:59:52,978 [INFO] Running on full data
2025-02-16 13:59:52,978 [INFO] Out of Domain: Calculate at A dataset, Evaluate at B dataset
2025-02-16 13:59:52,978 [INFO] Loading prompt_path from /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 13:59:52,990 [INFO] prompt的极性是neg
2025-02-16 13:59:52,990 [INFO] Running with alpha: 700.0
2025-02-16 13:59:52,991 [INFO] Running with prompt_type: from neg to pos
2025-02-16 13:59:52,992 [WARNING] 截取prompt_datasize500
2025-02-16 13:59:52,999 [INFO] 无干预
2025-02-16 14:01:07,142 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:01:07,143 [INFO] {'md5_hash': '06daa8998220e9f416c42b8f9c45fda8', 'prompt': {'text': 'It made my hair feel flat and uncooperative'}, 'continuation': {'text': ', though my skin felt soft and relaxed.'}, 'num_positive': 0, 'generations': [{'text': 'It made my hair feel flat and uncooperative\n\nI have a very thick, coarse, curly hair. I was looking for a shampoo that would help tame the frizz and give me some volume. This shampoo did not do that at all. It left my hair feeling greasy and weighed down. I'}, {'text': 'It made my hair feel flat and uncooperative. I have a lot of hair and it was not easy to get it all in the bun. It is also very difficult to remove from your head. I had to use a lot of water and soap to get it out of my hair.\n\n'}]}
2025-02-16 14:01:07,150 [INFO] 无干预
2025-02-16 14:02:21,127 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:02:21,127 [INFO] {'md5_hash': '684d089dd2539bcb726b7960c35e96f2', 'prompt': {'text': 'Protesters have also long said that they would not accept'}, 'continuation': {'text': 'immunity for Saleh and his family in exchange his resignation.'}, 'num_positive': 0, 'generations': [{'text': 'Protesters have also long said that they would not accept.\n\n“We are not going to accept the result of the election,” said one protester, who gave his name as “Aminu.”\n\n“The people who voted for Buhari should go and vote for him again,” he added.\n\nThe protesters'}, {'text': 'Protesters have also long said that they would not accept\n\nthe new constitution.\n\nThe government has been trying to reach a compromise with the protesters, but it has so far failed.\n\nIt is now trying to find a way to end the protests and get back on track with its plans for the country'}]}
2025-02-16 14:02:21,135 [INFO] 无干预
2025-02-16 14:03:27,243 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:03:27,243 [INFO] {'md5_hash': 'cc4129826978407883aacad181a6f185', 'prompt': {'text': 'but a overclock-failure would not'}, 'continuation': {'text': 'result in black screens.'}, 'num_positive': 0, 'generations': [{'text': "but a overclock-failure would not, I think.\n\nI'm running a 3200mhz kit with an X58 board and the stock voltage is 1.65v for the CPU and 1.4v for the RAM.\n\nThe CPU"}, {'text': 'but a overclock-failure would not\n\nbe the same as a normal failure.\n\nI think it\'s just the way you say it. I don\'t think that "overclocking" is an inherently bad thing, but I do think that "overclocking" is'}]}
2025-02-16 14:03:27,249 [INFO] 无干预
2025-02-16 14:04:05,490 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:04:05,490 [INFO] {'md5_hash': '16e85a1055720694e25c0af2b0249f5a', 'prompt': {'text': 'Whatever the truth of it, handwriting is now consigned'}, 'continuation': {'text': ', like hand-carried post, to the realm of snails.'}, 'num_positive': 0, 'generations': [{'text': 'Whatever the truth of it, handwriting is now consigned.\n\nIn the past, we used to write with a pen and paper. We wrote our letters, notes and messages on paper using a pen. We wrote in cursive or block letters depending on what was required of us.\n\nWe also used to'}, {'text': 'Whatever the truth of it, handwriting is now consigned.\n\nIn a world where we are all connected to the internet and can type out our thoughts in seconds, it’s no surprise that we have moved away from writing by hand.\n\nBut what about those who love the feel of a pen on'}]}
2025-02-16 14:04:05,496 [INFO] 无干预
2025-02-16 14:04:44,007 [INFO] 无干预
2025-02-16 14:05:21,164 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:05:21,164 [INFO] {'md5_hash': '25c4f661f5ccbbe5f43c46f20befe52a', 'prompt': {'text': 'What’s more laughable is the'}, 'continuation': {'text': 'affirmative defenses Rightscorp threw at the wall.'}, 'num_positive': 0, 'generations': [{'text': 'What’s more laughable is the of fact that he has a <strong>daughter</strong> with his ex-wife, <strong>Jennifer Lopez</strong>.\n\nIn the past, he was married to Jennifer Lopez and they have two children together.\n\n<h2>How many kids does Ben Affleck have?'}, {'text': 'What’s more laughable is the of the fact that he has been able to make a career out of it.\n\nHe was born in 1982 and has been making people laugh since he was 16 years old.\n\nHe has made his mark on the world'}]}
2025-02-16 14:05:21,172 [INFO] 无干预
2025-02-16 14:06:08,480 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:06:08,481 [INFO] {'md5_hash': '5b904b341b6cb4d85bdf60ec06b2539e', 'prompt': {'text': 'But could it be'}, 'continuation': {'text': 'more insidious than that?'}, 'num_positive': 0, 'generations': [{'text': "But could it be?\n\nI'm not sure if I can do this, but I'll try.\n\nFirst of all, let me say that the 2016 election was a complete disaster for the Democrats. The Republicans won both houses of Congress"}, {'text': 'But could it be\n\n[User 0001]\n\nI have a 2013 Ram 1500 Laramie with the 5.7 Hemi. I have had the truck for about a year and a half now and I am'}]}
2025-02-16 14:06:08,493 [INFO] 无干预
2025-02-16 14:07:10,117 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:07:10,118 [INFO] {'md5_hash': 'a40fbb2060aeac07d3c4ffe4caa544e6', 'prompt': {'text': 'Another exception is the sale of cigarettes,'}, 'continuation': {'text': 'which is covered by the Jenkins Act.'}, 'num_positive': 0, 'generations': [{'text': 'Another exception is the sale of cigarettes,, which is now taxed at 20% of the retail price. The tax on cigarettes was raised from 15% to 20% in April this year.\n\nThe government has also increased the tax on beer and spirits by '}, {'text': 'Another exception is the sale of cigarettes,, which has been in effect since 1970.\n\nThe law requires that all cigarettes sold in the United States be at least 95% tobacco and 5% filler. The law also prohibits the use of additives such as flavor'}]}
2025-02-16 14:07:10,132 [INFO] 无干预
2025-02-16 14:08:08,212 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:08:08,213 [INFO] {'md5_hash': 'a6231a5805f4f6868cdbe322ed6d9250', 'prompt': {'text': 'Disappointed: Apprentice chef Alex Martin will'}, 'continuation': {'text': 'miss out on her last two instalments.'}, 'num_positive': 0, 'generations': [{'text': 'Disappointed: Apprentice chef Alex Martin will, for the first time, be cooking in his own kitchen.\n\nThe 32-year-old is set to open his own restaurant in Auckland\'s CBD this month.\n\nMartin said he was "disappointed" when he left the'}, {'text': 'Disappointed: Apprentice chef Alex Martin will, in a few weeks, be back on our screens.\n\nThe 2017 series of MasterChef Australia is set to air on Channel 10 from May 28.\n\nThe show’s official Instagram account posted a photo'}]}
2025-02-16 14:08:08,225 [INFO] 无干预
2025-02-16 14:09:06,458 [INFO] 无干预
2025-02-16 14:10:03,882 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:10:03,883 [INFO] {'md5_hash': 'b2507e3a0dc9c39b21595cc8df98e1f6', 'prompt': {'text': 'The actual reactor is typically enclosed in a cement building'}, 'continuation': {'text': 'that is built to withstand natural disasters and other threats.'}, 'num_positive': 0, 'generations': [{'text': 'The actual reactor is typically enclosed in a cement building. The reactor itself is usually a cylindrical structure with a dome-shaped roof. The reactor building may be built on top of the foundation or it may be constructed separately and then placed on top of the foundation.\n\nThe nuclear power plant is located in'}, {'text': 'The actual reactor is typically enclosed in a cement building. The actual reactor is the place where the nuclear reaction takes place. The reactor is located in a special room, which is called the control room.\n\nA nuclear power plant (NPP) or nuclear power station (NPS) or nuclear power facility ('}]}
2025-02-16 14:10:03,897 [INFO] 无干预
2025-02-16 14:10:59,403 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:10:59,403 [INFO] {'md5_hash': 'afe25a529b2c2f59fe7a9746f912cfd0', 'prompt': {'text': 'Some, thinking disorder is simply the absence'}, 'continuation': {'text': 'of any system, confuse it with anarchy.'}, 'num_positive': 0, 'generations': [{'text': 'Some, thinking disorder is simply the absence of self-awareness.\n\nThis is a very common condition in our society today.\n\nThe lack of self-awareness has led to many people not knowing who they are and what they want in life.\n\nIt’s also caused by a lack'}, {'text': 'Some, thinking disorder is simply the absence.\n\nI have been in a relationship for 10 years and it has been very good until I met this guy. He is a very nice guy and he loves me so much but he has some issues with his thinking. He thinks that I'}]}
2025-02-16 14:10:59,410 [INFO] 无干预
2025-02-16 14:11:55,167 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:11:55,168 [INFO] {'md5_hash': '7f5156895e0d24711cc3e3d90ccbf9a1', 'prompt': {'text': 'No group claimed responsibility, but Egyptian reports pointed'}, 'continuation': {'text': 'blame at Hamas and other Gaza terror groups.'}, 'num_positive': 0, 'generations': [{'text': 'No group claimed responsibility, but Egyptian reports pointed\n\nto the Islamic State as the likely culprit.\n\nThe attack was the latest in a series of bombings and shootings that have rocked Egypt since 2013, when President Abdel Fattah al-Sisi led a military coup against his elected'}, {'text': 'No group claimed responsibility, but Egyptian reports pointed as the perpetrators of the attack.\n\nThe attack occurred in a busy area of the city, where there are many shops and restaurants.\n\nThe blast caused a huge explosion that shook the city and sent smoke billowing into the air.\n\nAccording to'}]}
2025-02-16 14:11:55,178 [INFO] 无干预
2025-02-16 14:12:46,593 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:12:46,593 [INFO] {'md5_hash': '7f19f058a5960ad706e86718c61f4e07', 'prompt': {'text': 'It is also easy to override'}, 'continuation': {'text': ', extend and customize the Configuration.'}, 'num_positive': 0, 'generations': [{'text': 'It is also easy to override. The first step is to find the desired object in the hierarchy.\n\nThe next step is to set the value of a property of this object.\n\nFinally, it is necessary to save the changes made by calling <code>save()</code> on the'}, {'text': 'It is also easy to override.\n\nThe <code>override</code> keyword can be used to override a method in a subclass.\n\nIn the following example, the <code>foo()</code> method in the <code>Foo</code> class is overridden by the <code>Bar</code> class:\n\n'}]}
2025-02-16 14:12:46,600 [INFO] 无干预
2025-02-16 14:13:39,337 [INFO] 无干预
2025-02-16 14:14:30,311 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:14:30,311 [INFO] {'md5_hash': '6ceb57c038afdfcf9b1f8196b0f2f3c3', 'prompt': {'text': 'getNumberProperties ( field )'}, 'continuation': {'text': ', calcInfo = this .'}, 'num_positive': 0, 'generations': [{'text': 'getNumberProperties ( field ),\n\t\t        \t\t    \t    \t    \t    \t   "get" );\n\t\t        \t\t    } else {\n\t\t\t        \t\t\t// If the field is not in the object, then we need to get it from the parent.'}, {'text': 'getNumberProperties ( field ).\n\n    @Override\n    public void setField(String name, String value) {\n        if (name.equals("field")) {\n            this.field = value;\n        } else if (name.equals("id"))'}]}
2025-02-16 14:14:30,319 [INFO] 无干预
2025-02-16 14:15:22,125 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:15:22,125 [INFO] {'md5_hash': '99a53d41506e0837001dc9fda47a0f89', 'prompt': {'text': 'The draft ordinance would require dispensaries to receive a special'}, 'continuation': {'text': 'permit from the city in order to begin operations.'}, 'num_positive': 0, 'generations': [{'text': 'The draft ordinance would require dispensaries to receive a special in-kind donation of land for the construction of their own buildings.\n\nThe ordinance was passed by the council on Tuesday, 12 May, and will be sent to the mayor for approval.\n\n“We are not going to give them money'}, {'text': 'The draft ordinance would require dispensaries to receive a special in-kind contribution from the state.\n\nThe draft ordinance was presented by the city’s Health Department at a public hearing on Wednesday, 12 June.\n\n“We are looking for ways to support our dispensaries and make sure they have'}]}
2025-02-16 14:15:22,135 [INFO] 无干预
2025-02-16 14:16:14,599 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:16:14,599 [INFO] {'md5_hash': '0c2cbc733309885571e7ebdb69b05ab0', 'prompt': {'text': 'The White House did not respond to'}, 'continuation': {'text': 'a CNBC request for further comment.'}, 'num_positive': 0, 'generations': [{'text': 'The White House did not respond to\'s question about the possibility of a meeting between President Trump and North Korean leader Kim Jong Un.\n\n"We have no comment on that," said White House press secretary Sarah Huckabee Sanders.\n\nSanders also said she was not aware of any'}, {'text': 'The White House did not respond to.\n\n“We’re not going to get into a tit-for-tat,” said White House press secretary Jen Psaki. “We’re going to focus on our own priorities.”\n\nThe president has been under pressure from Democrats and some'}]}
2025-02-16 14:16:14,609 [INFO] 无干预
2025-02-16 14:17:08,937 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:17:08,938 [INFO] {'md5_hash': 'ffc5bbd188bbcb96c34b82a1cb9cf139', 'prompt': {'text': 'For example, Lighting Universe could save some money by'}, 'continuation': {'text': 'setting “piano” bench as a negative keyword.'}, 'num_positive': 0, 'generations': [{'text': 'For example, Lighting Universe could save some money by <strong>using</strong> a smaller <strong>LED</strong> screen.\n\n<h3>What is LED?</h3>\n\nA light-emitting diode (LED) is a semiconductor device that emits light when an electric current passes through it. LEDs are widely used in various'}, {'text': 'For example, Lighting Universe could save some money by.\n\n<h2><strong>How to make a business plan for a small business</strong></h2>\n\nThe first step is to identify the type of business you want to start. There are many different types of businesses, so it is important to choose one that fits your'}]}
2025-02-16 14:17:08,945 [INFO] 无干预
2025-02-16 14:18:01,074 [INFO] 无干预
2025-02-16 14:18:56,155 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:18:56,155 [INFO] {'md5_hash': 'f84597942cad62482c256a7d23c95f40', 'prompt': {'text': 'Further medication was classified into'}, 'continuation': {'text': 'groups defined by their indication.'}, 'num_positive': 0, 'generations': [{'text': 'Further medication was classified into, and also the effects of the medication were assessed. The most common side effects were headache, nausea, vomiting and dizziness.\n\nThe results showed that the majority of patients had a significant improvement in their symptoms after taking the medication.\n\nThe study was'}, {'text': 'Further medication was classified into.\n\nThe most common types of medications are:\n\n* Antidepressants\n* Antipsychotics\n* Mood stabilizers\n* Anticonvulsants\n* Beta-blockers\n\nThese medications can be used to treat a variety of mental health'}]}
2025-02-16 14:18:56,162 [INFO] 无干预
2025-02-16 14:20:10,296 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:20:10,297 [INFO] {'md5_hash': '4a33b5c0f5b5419c1d2b7be1288cac01', 'prompt': {'text': 'So in the absence of such skills they use the'}, 'continuation': {'text': '“carrot and stick’ technique without the carrot.'}, 'num_positive': 0, 'generations': [{'text': 'So in the absence of such skills they use the to get their work done. So, this is a good example of how we can use the to get our work done.\n\n<h3>How do you use a tool?</h3>\n\n1. Use a tool for its intended purpose\n2. Don’'}, {'text': "So in the absence of such skills they use the.\n\n1. The most common way to make a profit is by buying low and selling high, but this can be difficult to do when you don't have any money.\n2. You can also make money by investing in stocks or bonds"}]}
2025-02-16 14:20:10,304 [INFO] 无干预
2025-02-16 14:21:29,031 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:21:29,032 [INFO] {'md5_hash': '12457dc59ff895a0112a622c8060c2c0', 'prompt': {'text': 'The process has become mired in UN bureaucracy after the'}, 'continuation': {'text': 'security council set up a subcommittee to examine the application.'}, 'num_positive': 0, 'generations': [{'text': 'The process has become mired in UN bureaucracy after the, as it were, "re-election" of Secretary General Ban Ki-moon. The 193 member states of the United Nations have to elect a new secretary general by consensus.\n\nThe process is not going well. It is being'}, {'text': 'The process has become mired in UN bureaucracy after the of the United Nations General Assembly. The Secretary-General, Ban Ki-moon, has been a major player in this process. He has been a strong advocate for reform and change.\n\nIn his address to the General Assembly on September 27'}]}
2025-02-16 14:21:29,039 [INFO] 无干预
2025-02-16 14:22:43,849 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:22:43,849 [INFO] {'md5_hash': '1467fd6a27ba129d7542cb7dc66f9c1d', 'prompt': {'text': 'Earlier this month the ONS said the unemployment rate had'}, 'continuation': {'text': 'fallen to 7.4%, the lowest level since 2009.'}, 'num_positive': 0, 'generations': [{'text': 'Earlier this month the ONS said the unemployment rate had in fact fallen to 5.2% in March, down from 5.4% in February and 6.1% a year earlier.\n\nThe ONS also said that the number of people claiming unemployment benefits fell by 10,'}, {'text': 'Earlier this month the ONS said the unemployment rate had in fact fallen to 10.2% in December, from 10.5% in November, and that the number of people out of work had fallen by 36,000 to 2.4 million.\n\n'}]}
2025-02-16 14:22:43,856 [INFO] 无干预
2025-02-16 14:23:58,634 [INFO] 无干预
2025-02-16 14:25:13,263 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:25:13,263 [INFO] {'md5_hash': '41bc9ecd131d1d1f8b608196e1118bf1', 'prompt': {'text': "The suspect in Tuesday's downtown terror attack"}, 'continuation': {'text': 'arrives with police escort to Bellevue Hospital.'}, 'num_positive': 0, 'generations': [{'text': "The suspect in Tuesday's downtown terror attack Kaduna, Samuel Aruwan has said that the state government is working to ensure that the victims of the attack are compensated.\n\nAruwan who is also the Commissioner for Internal Security and Home Affairs, Kaduna State said this while speaking with newsmen on"}, {'text': "The suspect in Tuesday's downtown terror attack Kaduna State, has been identified as a 20-year-old man.\n\nThe suspect was arrested by the police after he was caught with a gun and some other dangerous weapons.\n\nHe was said to have been arrested at the popular Ung"}]}
2025-02-16 14:25:13,272 [INFO] 无干预
2025-02-16 14:26:27,551 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:26:27,551 [INFO] {'md5_hash': '8ba89b679c38d81dd20e8067000a1af4', 'prompt': {'text': 'It lost 14.5 percent of its value'}, 'continuation': {'text': 'in the third quarter of 2008.'}, 'num_positive': 0, 'generations': [{'text': 'It lost 14.5 percent of its value\n\nThe Nigerian Stock Exchange (NSE) has recorded a decline in the market capitalisation of the nation’s equities market for the first time in 2017.\n\nThe market capitalisation, which was N12.3 trillion on'}, {'text': 'It lost 14.5 percent of its value, while the index of the stock market fell by 1.38 percent to close at 20,976.28 points.\n\nThe total value of shares traded on the floor was N34 billion, compared with N'}]}
2025-02-16 14:26:27,564 [INFO] 无干预
2025-02-16 14:27:41,244 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:27:41,244 [INFO] {'md5_hash': '4418c5d2083b4691da26049c806b4526', 'prompt': {'text': 'But it seems likely too that'}, 'continuation': {'text': 'Heleus will not be left behind.'}, 'num_positive': 0, 'generations': [{'text': 'But it seems likely too that is not the case.\n\nThe most recent report from the World Health Organization (WHO) on the coronavirus pandemic has shown that there are now 12,000 cases of COVID-19 in China and 3,857'}, {'text': 'But it seems likely too that will be the case in the future.\n\nThe new study, published in <em>Nature</em>, is based on a survey of 120 countries and found that more than half of people are concerned about their health and well-being.\n\n'}]}
2025-02-16 14:27:41,257 [INFO] 无干预
2025-02-16 14:28:56,537 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:28:56,538 [INFO] {'md5_hash': '8304662bb7869d6eb68357cf013a4430', 'prompt': {'text': 'Allegations of torture by secret intelligence agencies at Kuli camp'}, 'continuation': {'text': 'have been made by the Baloch community for several decades.'}, 'num_positive': 0, 'generations': [{'text': 'Allegations of torture by secret intelligence agencies at Kuli camp in Kaduna State have been denied by the Nigerian Army.\n\nThe army said it has not received any report of torture or abuse of prisoners at the facility.\n\nThe military also said that it is not aware of any case where a prisoner was killed or'}, {'text': 'Allegations of torture by secret intelligence agencies at Kuli camp in Kano, have been dismissed as false.\n\nThe director-general of the National Intelligence Agency (NIA), Ahmed Rufai Abubakar, made this known while speaking with journalists on Wednesday in Abuja.\n\nAbubakar said that the allegations were not true and'}]}
2025-02-16 14:28:56,544 [INFO] 无干预
2025-02-16 14:30:11,062 [INFO] 无干预
2025-02-16 14:31:22,867 [INFO] sentiment: from neg to pos prompt_set: neg
2025-02-16 14:31:22,867 [INFO] {'md5_hash': 'd57568ce10f19bc27be29d47c0d77374', 'prompt': {'text': 'The steepest decreases occurred among men who reported that they'}, 'continuation': {'text': 'spent time caring for and palling around with their children.'}, 'num_positive': 0, 'generations': [{'text': 'The steepest decreases occurred among men who reported that they had been married at least once, with a decrease of 10.5 percentage points in the period 2016-2017.\n\nThe same trend was observed among women who had been married at least once, with a'}, {'text': 'The steepest decreases occurred among men who reported that they had been married for 10 years or more, and among those who were divorced or separated.\n\nAmong the women, the largest decreases in satisfaction with marriage were reported by those who had been married for 10 years or more and by those'}]}
2025-02-16 14:31:22,874 [INFO] 无干预
2025-02-16 14:32:27,784 [INFO] 训练时间455.5794084072113
2025-02-16 14:32:27,785 [INFO] Show Hyperparameters: 


2025-02-16 14:32:27,785 [INFO]   task: sentiment
2025-02-16 14:32:27,785 [INFO]   layer: 6
2025-02-16 14:32:27,785 [INFO]   LLM: gemma-2-2b
2025-02-16 14:32:27,785 [INFO]   seed: 42
2025-02-16 14:32:27,785 [INFO]   data_size: 1000
2025-02-16 14:32:27,785 [INFO]   device: cpu
2025-02-16 14:32:27,785 [INFO]   alpha: 700.0
2025-02-16 14:32:27,785 [INFO]   method: val_mul
2025-02-16 14:32:27,785 [INFO]   topk_mean: 100
2025-02-16 14:32:27,785 [INFO]   topk_cnt: 100
2025-02-16 14:32:27,785 [INFO]   batch_size: 32
2025-02-16 14:32:27,785 [INFO]   source: neg
2025-02-16 14:32:27,785 [INFO]   target: pos
2025-02-16 14:32:27,785 [INFO]   prompt_source: neg
2025-02-16 14:32:27,785 [INFO]   prompt_data_size: 500
2025-02-16 14:32:27,785 [INFO]   mean_type: dif_mean
2025-02-16 14:32:27,785 [INFO]   steer_type: all
2025-02-16 14:32:27,785 [INFO]   output_dir: ./results/sentiment_gemma/
2025-02-16 14:32:27,785 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5
2025-02-16 14:32:27,785 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k
2025-02-16 14:32:27,785 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 14:32:27,786 [INFO]   temperature: 0.9
2025-02-16 14:32:27,786 [INFO]   top_p: 0.3
2025-02-16 14:32:27,786 [INFO]   freq_penalty: 1.0
2025-02-16 14:32:27,786 [INFO]   example_prompt: But the lack of financial aid would| The passage of the AI Act will
2025-02-16 14:32:27,786 [INFO]   debug: 0
2025-02-16 14:32:27,786 [INFO]   save_no_steer: 1
2025-02-16 14:32:27,786 [INFO]   is_norm_delta_matrix: 0
2025-02-16 14:32:27,786 [INFO]   use_cache: 0
2025-02-16 14:32:27,786 [INFO]   repeat_num: 2
2025-02-16 14:32:27,786 [INFO]   gen_batch_size: 16
2025-02-16 14:32:27,786 [INFO]   real_data_size_for_train: 1000
2025-02-16 14:32:27,786 [INFO] sentiment:neg->pos
