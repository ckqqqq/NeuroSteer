2025-02-16 11:03:11,639 [INFO] Logging initialized. Logs will be saved to ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_150/alpha_1.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 11:03:11,639 [INFO] Show Hyperparameters: 


2025-02-16 11:03:11,639 [INFO]   task: polite
2025-02-16 11:03:11,639 [INFO]   layer: 6
2025-02-16 11:03:11,639 [INFO]   LLM: gpt2-small
2025-02-16 11:03:11,639 [INFO]   seed: 42
2025-02-16 11:03:11,639 [INFO]   data_size: -1
2025-02-16 11:03:11,639 [INFO]   device: cuda
2025-02-16 11:03:11,639 [INFO]   alpha: 1.0
2025-02-16 11:03:11,639 [INFO]   method: val_mul
2025-02-16 11:03:11,639 [INFO]   topk_mean: 100
2025-02-16 11:03:11,639 [INFO]   topk_cnt: 150
2025-02-16 11:03:11,639 [INFO]   batch_size: 32
2025-02-16 11:03:11,639 [INFO]   source: pos
2025-02-16 11:03:11,639 [INFO]   target: neg
2025-02-16 11:03:11,639 [INFO]   prompt_source: neg
2025-02-16 11:03:11,639 [INFO]   prompt_data_size: -1
2025-02-16 11:03:11,639 [INFO]   mean_type: dif_mean
2025-02-16 11:03:11,639 [INFO]   steer_type: all
2025-02-16 11:03:11,639 [INFO]   output_dir: ./results/polite/
2025-02-16 11:03:11,639 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:03:11,639 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:03:11,639 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 11:03:11,639 [INFO]   temperature: 0.9
2025-02-16 11:03:11,639 [INFO]   top_p: 0.3
2025-02-16 11:03:11,640 [INFO]   freq_penalty: 1.0
2025-02-16 11:03:11,640 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 11:03:11,640 [INFO]   debug: 1
2025-02-16 11:03:11,640 [INFO]   save_no_steer: 1
2025-02-16 11:03:11,640 [INFO]   is_norm_delta_matrix: 0
2025-02-16 11:03:11,640 [INFO]   use_cache: 0
2025-02-16 11:03:11,640 [INFO]   repeat_num: 2
2025-02-16 11:03:11,640 [INFO]   gen_batch_size: 16
2025-02-16 11:03:11,640 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 11:03:11,640 [INFO] dataset path /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:03:11,640 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-02-16 11:03:11,640 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus***
2025-02-16 11:03:11,663 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 11:03:11,759 [INFO] 检查数据量 Selected 5476 negative, 5476 positive, and 5476 neutral samples
2025-02-16 11:03:11,759 [INFO] 数据集不兼容，没有验证数据集，但是不影响
2025-02-16 11:03:11,760 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-16 11:03:11,760 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-16 11:03:16,056 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-16 11:03:16,057 [INFO] 缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_150/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-16 11:03:16,094 [INFO] :>> {TASK} : from pos to neg
2025-02-16 11:03:16,110 [INFO] positive
2025-02-16 11:03:16,127 [INFO] Running model with cache to obtain hidden states
2025-02-16 11:03:23,808 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 11:03:23,808 [INFO] negative
2025-02-16 11:03:23,830 [INFO] Running model with cache to obtain hidden states
2025-02-16 11:03:31,544 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 11:03:31,546 [INFO] steer_info 已保存到缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_150/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-16 11:03:31,559 [INFO] 转向方向 dif_neg-pos_relu
2025-02-16 11:03:31,588 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-16 11:03:31,631 [INFO] delta_matrix: tensor([-0.2591,  0.1759, -0.0605,  0.0863,  0.1590], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-16 11:03:31,631 [INFO] Generating texts **without** steering... 
2025-02-16 11:03:31,631 [INFO] 无转向结果
2025-02-16 11:03:31,633 [INFO] 无干预
2025-02-16 11:03:32,922 [INFO] 当前批次共处理2个prompt
2025-02-16 11:03:32,923 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 11:03:32,923 [INFO] 生成 1: |

"It's not a question of if, but when," he said. "We have to look at it from the perspective of what we need to do."

The proposal would require that state and local governments provide $1 billion in|
2025-02-16 11:03:32,923 [INFO] 生成 2: | arouse suspicions among some in the administration that it is being used to support an agenda that could be unpopular with voters.

"I think it's a very important issue," said one Republican senator, who asked not to be named because he was|
2025-02-16 11:03:32,923 [INFO] 生成 3: |'s make it difficult for her to continue her education.

"I don't want to go back to school," she said. "I'm going to have to take a break from my job and get a better job."

The State|
2025-02-16 11:03:32,923 [INFO] Prompt 2: | She was so busy with her work |
2025-02-16 11:03:32,923 [INFO] 生成 1: | that she didn't even bother to ask me about it. I was too busy to ask her about it, but she did tell me that she wanted to see what my daughter had done for her.
She also told me that I would be|
2025-02-16 11:03:32,923 [INFO] 生成 2: | that she forgot to take a shower.
I'm not sure if this is a coincidence or just a bad habit, but I'm going to try and explain it in more detail later.
I have an idea for the next chapter of my|
2025-02-16 11:03:32,923 [INFO] 生成 3: | that she didn't even bother to ask for a ride home.
I'm sure she's been waiting for this one, but I'm not sure if it's because of the amount of time that she spent in the car or because she was|
2025-02-16 11:03:32,923 [INFO] 干预之后的结果
2025-02-16 11:03:32,923 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 11:03:32,923 [INFO] ** Generating texts with steering... Target **
2025-02-16 11:03:32,923 [INFO] form pos to neg
2025-02-16 11:03:32,923 [INFO] 转向结果
2025-02-16 11:03:33,833 [INFO] 当前批次共处理2个prompt
2025-02-16 11:03:33,833 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 11:03:33,833 [INFO] 生成 1: |.

The federal government has been struggling to provide a steady stream of aid to the needy since 2009, when President Barack Obama took office.

Since then, the U.S. has spent more than $1 trillion on programs for low|
2025-02-16 11:03:33,834 [INFO] 生成 2: | in turn be a problem for many Americans.

The National Association of State Boards of Education, which represents state boards, said it was "disappointed" by the recent budget proposal and that it was working with the White House to find ways to|
2025-02-16 11:03:33,834 [INFO] 生成 3: |'s be a major problem for those who are trying to get ahead.

The Department of Education has already provided $1.3 billion in grants to states that have not yet received federal funding, according to a report released by the nonprofit Center for|
2025-02-16 11:03:33,834 [INFO] Prompt 2: | She was so busy with her work |
2025-02-16 11:03:33,834 [INFO] 生成 1: | that she didn't even bother to get up.
I'm not sure if I should have done this or not, but I did it anyway.
She got up and walked over to the bathroom and put on her makeup.
"Oh|
2025-02-16 11:03:33,834 [INFO] 生成 2: | that she didn't even notice that I was in the room.
She looked at me and said, "What are you doing?"
I said, "I'm going to get a job at a restaurant."
She said, "Oh|
2025-02-16 11:03:33,834 [INFO] 生成 3: | that she had to leave the house for a few days. I think that was because she didn't want to go back home.
She went to school and did a lot of reading, but then she left for work.
I think that|
2025-02-16 11:03:33,838 [INFO] debug mode,show example, no full dataset eval
2025-02-16 11:03:33,838 [INFO] 训练时间15.490196704864502
2025-02-16 11:03:33,838 [INFO] Show Hyperparameters: 


2025-02-16 11:03:33,838 [INFO]   task: polite
2025-02-16 11:03:33,839 [INFO]   layer: 6
2025-02-16 11:03:33,839 [INFO]   LLM: gpt2-small
2025-02-16 11:03:33,839 [INFO]   seed: 42
2025-02-16 11:03:33,839 [INFO]   data_size: -1
2025-02-16 11:03:33,839 [INFO]   device: cuda
2025-02-16 11:03:33,839 [INFO]   alpha: 1.0
2025-02-16 11:03:33,839 [INFO]   method: val_mul
2025-02-16 11:03:33,839 [INFO]   topk_mean: 100
2025-02-16 11:03:33,839 [INFO]   topk_cnt: 150
2025-02-16 11:03:33,839 [INFO]   batch_size: 32
2025-02-16 11:03:33,839 [INFO]   source: pos
2025-02-16 11:03:33,839 [INFO]   target: neg
2025-02-16 11:03:33,839 [INFO]   prompt_source: neg
2025-02-16 11:03:33,839 [INFO]   prompt_data_size: -1
2025-02-16 11:03:33,839 [INFO]   mean_type: dif_mean
2025-02-16 11:03:33,839 [INFO]   steer_type: all
2025-02-16 11:03:33,839 [INFO]   output_dir: ./results/polite/
2025-02-16 11:03:33,839 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:03:33,839 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:03:33,839 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 11:03:33,839 [INFO]   temperature: 0.9
2025-02-16 11:03:33,839 [INFO]   top_p: 0.3
2025-02-16 11:03:33,839 [INFO]   freq_penalty: 1.0
2025-02-16 11:03:33,839 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 11:03:33,839 [INFO]   debug: 1
2025-02-16 11:03:33,839 [INFO]   save_no_steer: 1
2025-02-16 11:03:33,839 [INFO]   is_norm_delta_matrix: 0
2025-02-16 11:03:33,839 [INFO]   use_cache: 0
2025-02-16 11:03:33,839 [INFO]   repeat_num: 2
2025-02-16 11:03:33,839 [INFO]   gen_batch_size: 16
2025-02-16 11:03:33,839 [INFO]   real_data_size_for_train: 5476
2025-02-16 11:05:44,257 [INFO] Logging initialized. Logs will be saved to ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_150/alpha_1.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 11:05:44,257 [INFO] Show Hyperparameters: 


2025-02-16 11:05:44,257 [INFO]   task: polite
2025-02-16 11:05:44,257 [INFO]   layer: 6
2025-02-16 11:05:44,257 [INFO]   LLM: gpt2-small
2025-02-16 11:05:44,257 [INFO]   seed: 42
2025-02-16 11:05:44,257 [INFO]   data_size: -1
2025-02-16 11:05:44,257 [INFO]   device: cuda
2025-02-16 11:05:44,258 [INFO]   alpha: 1.0
2025-02-16 11:05:44,258 [INFO]   method: val_mul
2025-02-16 11:05:44,258 [INFO]   topk_mean: 100
2025-02-16 11:05:44,258 [INFO]   topk_cnt: 150
2025-02-16 11:05:44,258 [INFO]   batch_size: 32
2025-02-16 11:05:44,258 [INFO]   source: pos
2025-02-16 11:05:44,258 [INFO]   target: neg
2025-02-16 11:05:44,258 [INFO]   prompt_source: neg
2025-02-16 11:05:44,258 [INFO]   prompt_data_size: -1
2025-02-16 11:05:44,258 [INFO]   mean_type: dif_mean
2025-02-16 11:05:44,258 [INFO]   steer_type: all
2025-02-16 11:05:44,258 [INFO]   output_dir: ./results/polite/
2025-02-16 11:05:44,258 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:05:44,258 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:05:44,258 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 11:05:44,258 [INFO]   temperature: 0.9
2025-02-16 11:05:44,258 [INFO]   top_p: 0.3
2025-02-16 11:05:44,258 [INFO]   freq_penalty: 1.0
2025-02-16 11:05:44,258 [INFO]   example_prompt: But the lack of financial aid would| The passage of the AI Act wil
2025-02-16 11:05:44,258 [INFO]   debug: 1
2025-02-16 11:05:44,258 [INFO]   save_no_steer: 1
2025-02-16 11:05:44,258 [INFO]   is_norm_delta_matrix: 0
2025-02-16 11:05:44,258 [INFO]   use_cache: 0
2025-02-16 11:05:44,258 [INFO]   repeat_num: 2
2025-02-16 11:05:44,258 [INFO]   gen_batch_size: 16
2025-02-16 11:05:44,258 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 11:05:44,259 [INFO] dataset path /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:05:44,259 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-02-16 11:05:44,259 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus***
2025-02-16 11:05:44,277 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 11:05:44,282 [INFO] 检查数据量 Selected 5476 negative, 5476 positive, and 5476 neutral samples
2025-02-16 11:05:44,282 [INFO] 数据集不兼容，没有验证数据集，但是不影响
2025-02-16 11:05:44,282 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-16 11:05:44,282 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-16 11:05:48,617 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-16 11:05:48,617 [INFO] 缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_150/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-16 11:05:48,661 [INFO] :>> polite : from pos to neg
2025-02-16 11:05:48,682 [INFO] positive
2025-02-16 11:05:48,702 [INFO] Running model with cache to obtain hidden states
2025-02-16 11:05:56,577 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 11:05:56,578 [INFO] negative
2025-02-16 11:05:56,598 [INFO] Running model with cache to obtain hidden states
2025-02-16 11:06:04,220 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 11:06:04,222 [INFO] steer_info 已保存到缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_150/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-16 11:06:04,231 [INFO] 转向方向 dif_neg-pos_relu
2025-02-16 11:06:04,251 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-16 11:06:04,281 [INFO] delta_matrix: tensor([-0.2591,  0.1759, -0.0605,  0.0863,  0.1590], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-16 11:06:04,282 [INFO] Generating texts **without** steering... 
2025-02-16 11:06:04,282 [INFO] 无转向结果
2025-02-16 11:06:04,284 [INFO] 无干预
2025-02-16 11:06:05,713 [INFO] 当前批次共处理2个prompt
2025-02-16 11:06:05,713 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 11:06:05,713 [INFO] 生成 1: | have made it harder for them to get jobs.

"The reality is that if you're going to have a job, you need a lot of help," said Sarah Levenson, who works as an assistant professor at the University of California|
2025-02-16 11:06:05,713 [INFO] 生成 2: | be a huge blow to many in the region, especially those who have lost their homes and businesses.

"I think it's very important that we get help for our children," said Srinivasan. "We need to get them out|
2025-02-16 11:06:05,714 [INFO] 生成 3: | be a big problem for those who are working hard to make ends meet.

The state's unemployment rate is 5.7 percent, and its unemployment rate is 8.5 percent, according to the latest data from the Bureau of Labor Statistics.|
2025-02-16 11:06:05,714 [INFO] Prompt 2: | The passage of the AI Act wil|
2025-02-16 11:06:05,714 [INFO] 生成 1: |fully and intentionally compromises the integrity of our national security.

The act is a major step forward in this direction. It will ensure that we have a strong and robust intelligence community, which will be able to provide our nation with information that is vital|
2025-02-16 11:06:05,714 [INFO] 生成 2: |fully erodes the autonomy of India's government.

The bill, which was passed by a parliamentary committee on Wednesday, is an attempt to make it easier for AI to conduct its own research and development. It will also allow it to use AI|
2025-02-16 11:06:05,714 [INFO] 生成 3: |fully undermines the public trust in our intelligence agencies.

The government's position is that it has no right to collect and store data on anyone, including foreign nationals. It is also wrong to assume that we have any right to know who is sending|
2025-02-16 11:06:05,714 [INFO] 干预之后的结果
2025-02-16 11:06:05,714 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 11:06:05,714 [INFO] ** Generating texts with steering... Target **
2025-02-16 11:06:05,714 [INFO] form pos to neg
2025-02-16 11:06:05,714 [INFO] 转向结果
2025-02-16 11:06:06,638 [INFO] 当前批次共处理2个prompt
2025-02-16 11:06:06,638 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 11:06:06,638 [INFO] 生成 1: | be a major problem for some of the most vulnerable people in the country.

The report, which was prepared by the Department of Education's Office for Civil Rights, found that nearly half of all students who received federal aid under Title IX were denied|
2025-02-16 11:06:06,638 [INFO] 生成 2: | have been a big blow to Mr. Trump's campaign, which has spent millions of dollars on advertising and fundraising.

Mr. Trump has said he will give up his presidential bid in favor of a run for president in 2020, but that he|
2025-02-16 11:06:06,638 [INFO] 生成 3: | be a big blow to his campaign.

The former Florida governor has been under fire for his handling of Hurricane Irma, which devastated parts of the Caribbean and killed at least 10 people.

His campaign said he was "disappointed" by|
2025-02-16 11:06:06,638 [INFO] Prompt 2: | The passage of the AI Act wil|
2025-02-16 11:06:06,638 [INFO] 生成 1: |fully destroys the lives of people who have been working in the IT sector for over a decade.

The law will be passed by Parliament on Friday, and will require companies to pay an annual fee of Rs 1,000 crore to ensure that they|
2025-02-16 11:06:06,638 [INFO] 生成 2: |fully nullifies the rights of human beings to self-determination.

The new law will not only allow for arbitrary and arbitrary decisions, but also will be a violation of human rights. It is a step in the right direction towards equality, and|
2025-02-16 11:06:06,638 [INFO] 生成 3: |fully nullifies the right to freedom of speech and expression.

The Bill will also give the government a new mandate to use its powers to stop any and all internet activity that is "illegal" or "unconstitutional". This includes:

|
2025-02-16 11:06:06,643 [INFO] debug mode,show example, no full dataset eval
2025-02-16 11:06:06,643 [INFO] 训练时间15.604799032211304
2025-02-16 11:06:06,643 [INFO] Show Hyperparameters: 


2025-02-16 11:06:06,643 [INFO]   task: polite
2025-02-16 11:06:06,643 [INFO]   layer: 6
2025-02-16 11:06:06,643 [INFO]   LLM: gpt2-small
2025-02-16 11:06:06,643 [INFO]   seed: 42
2025-02-16 11:06:06,643 [INFO]   data_size: -1
2025-02-16 11:06:06,643 [INFO]   device: cuda
2025-02-16 11:06:06,643 [INFO]   alpha: 1.0
2025-02-16 11:06:06,643 [INFO]   method: val_mul
2025-02-16 11:06:06,643 [INFO]   topk_mean: 100
2025-02-16 11:06:06,643 [INFO]   topk_cnt: 150
2025-02-16 11:06:06,643 [INFO]   batch_size: 32
2025-02-16 11:06:06,643 [INFO]   source: pos
2025-02-16 11:06:06,643 [INFO]   target: neg
2025-02-16 11:06:06,643 [INFO]   prompt_source: neg
2025-02-16 11:06:06,643 [INFO]   prompt_data_size: -1
2025-02-16 11:06:06,643 [INFO]   mean_type: dif_mean
2025-02-16 11:06:06,643 [INFO]   steer_type: all
2025-02-16 11:06:06,643 [INFO]   output_dir: ./results/polite/
2025-02-16 11:06:06,643 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:06:06,643 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:06:06,644 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 11:06:06,644 [INFO]   temperature: 0.9
2025-02-16 11:06:06,644 [INFO]   top_p: 0.3
2025-02-16 11:06:06,644 [INFO]   freq_penalty: 1.0
2025-02-16 11:06:06,644 [INFO]   example_prompt: But the lack of financial aid would| The passage of the AI Act wil
2025-02-16 11:06:06,644 [INFO]   debug: 1
2025-02-16 11:06:06,644 [INFO]   save_no_steer: 1
2025-02-16 11:06:06,644 [INFO]   is_norm_delta_matrix: 0
2025-02-16 11:06:06,644 [INFO]   use_cache: 0
2025-02-16 11:06:06,644 [INFO]   repeat_num: 2
2025-02-16 11:06:06,644 [INFO]   gen_batch_size: 16
2025-02-16 11:06:06,644 [INFO]   real_data_size_for_train: 5476
