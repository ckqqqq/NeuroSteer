2025-02-16 10:50:18,315 [INFO] Logging initialized. Logs will be saved to ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/alpha_200.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 10:50:18,315 [INFO] Show Hyperparameters: 


2025-02-16 10:50:18,315 [INFO]   task: polite
2025-02-16 10:50:18,315 [INFO]   layer: 6
2025-02-16 10:50:18,315 [INFO]   LLM: gpt2-small
2025-02-16 10:50:18,315 [INFO]   seed: 42
2025-02-16 10:50:18,315 [INFO]   data_size: -1
2025-02-16 10:50:18,315 [INFO]   device: cuda
2025-02-16 10:50:18,315 [INFO]   alpha: 200.0
2025-02-16 10:50:18,315 [INFO]   method: val_mul
2025-02-16 10:50:18,315 [INFO]   topk_mean: 100
2025-02-16 10:50:18,316 [INFO]   topk_cnt: 100
2025-02-16 10:50:18,316 [INFO]   batch_size: 32
2025-02-16 10:50:18,316 [INFO]   source: pos
2025-02-16 10:50:18,316 [INFO]   target: neg
2025-02-16 10:50:18,316 [INFO]   prompt_source: neg
2025-02-16 10:50:18,316 [INFO]   prompt_data_size: -1
2025-02-16 10:50:18,316 [INFO]   mean_type: dif_mean
2025-02-16 10:50:18,316 [INFO]   steer_type: all
2025-02-16 10:50:18,316 [INFO]   output_dir: ./results/polite/
2025-02-16 10:50:18,316 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:50:18,316 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:50:18,316 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 10:50:18,316 [INFO]   temperature: 0.9
2025-02-16 10:50:18,316 [INFO]   top_p: 0.3
2025-02-16 10:50:18,316 [INFO]   freq_penalty: 1.0
2025-02-16 10:50:18,316 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 10:50:18,316 [INFO]   debug: 1
2025-02-16 10:50:18,316 [INFO]   save_no_steer: 1
2025-02-16 10:50:18,316 [INFO]   is_norm_delta_matrix: 0
2025-02-16 10:50:18,316 [INFO]   use_cache: 0
2025-02-16 10:50:18,316 [INFO]   repeat_num: 2
2025-02-16 10:50:18,316 [INFO]   gen_batch_size: 16
2025-02-16 10:50:18,316 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 10:50:18,316 [INFO] dataset path /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:50:18,316 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-02-16 10:51:17,306 [INFO] Logging initialized. Logs will be saved to ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/alpha_200.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 10:51:17,306 [INFO] Show Hyperparameters: 


2025-02-16 10:51:17,306 [INFO]   task: polite
2025-02-16 10:51:17,306 [INFO]   layer: 6
2025-02-16 10:51:17,306 [INFO]   LLM: gpt2-small
2025-02-16 10:51:17,306 [INFO]   seed: 42
2025-02-16 10:51:17,306 [INFO]   data_size: -1
2025-02-16 10:51:17,307 [INFO]   device: cuda
2025-02-16 10:51:17,307 [INFO]   alpha: 200.0
2025-02-16 10:51:17,307 [INFO]   method: val_mul
2025-02-16 10:51:17,307 [INFO]   topk_mean: 100
2025-02-16 10:51:17,307 [INFO]   topk_cnt: 100
2025-02-16 10:51:17,307 [INFO]   batch_size: 32
2025-02-16 10:51:17,307 [INFO]   source: pos
2025-02-16 10:51:17,307 [INFO]   target: neg
2025-02-16 10:51:17,307 [INFO]   prompt_source: neg
2025-02-16 10:51:17,307 [INFO]   prompt_data_size: -1
2025-02-16 10:51:17,307 [INFO]   mean_type: dif_mean
2025-02-16 10:51:17,307 [INFO]   steer_type: all
2025-02-16 10:51:17,307 [INFO]   output_dir: ./results/polite/
2025-02-16 10:51:17,307 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:51:17,307 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:51:17,307 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 10:51:17,307 [INFO]   temperature: 0.9
2025-02-16 10:51:17,307 [INFO]   top_p: 0.3
2025-02-16 10:51:17,307 [INFO]   freq_penalty: 1.0
2025-02-16 10:51:17,307 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 10:51:17,307 [INFO]   debug: 1
2025-02-16 10:51:17,307 [INFO]   save_no_steer: 1
2025-02-16 10:51:17,307 [INFO]   is_norm_delta_matrix: 0
2025-02-16 10:51:17,307 [INFO]   use_cache: 0
2025-02-16 10:51:17,307 [INFO]   repeat_num: 2
2025-02-16 10:51:17,307 [INFO]   gen_batch_size: 16
2025-02-16 10:51:17,308 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 10:51:17,308 [INFO] dataset path /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:51:17,308 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-02-16 10:51:57,781 [INFO] Logging initialized. Logs will be saved to ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/alpha_200.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 10:51:57,781 [INFO] Show Hyperparameters: 


2025-02-16 10:51:57,781 [INFO]   task: polite
2025-02-16 10:51:57,781 [INFO]   layer: 6
2025-02-16 10:51:57,781 [INFO]   LLM: gpt2-small
2025-02-16 10:51:57,781 [INFO]   seed: 42
2025-02-16 10:51:57,781 [INFO]   data_size: -1
2025-02-16 10:51:57,781 [INFO]   device: cuda
2025-02-16 10:51:57,781 [INFO]   alpha: 200.0
2025-02-16 10:51:57,781 [INFO]   method: val_mul
2025-02-16 10:51:57,781 [INFO]   topk_mean: 100
2025-02-16 10:51:57,781 [INFO]   topk_cnt: 100
2025-02-16 10:51:57,781 [INFO]   batch_size: 32
2025-02-16 10:51:57,781 [INFO]   source: pos
2025-02-16 10:51:57,781 [INFO]   target: neg
2025-02-16 10:51:57,781 [INFO]   prompt_source: neg
2025-02-16 10:51:57,781 [INFO]   prompt_data_size: -1
2025-02-16 10:51:57,781 [INFO]   mean_type: dif_mean
2025-02-16 10:51:57,781 [INFO]   steer_type: all
2025-02-16 10:51:57,781 [INFO]   output_dir: ./results/polite/
2025-02-16 10:51:57,781 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:51:57,781 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:51:57,781 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 10:51:57,782 [INFO]   temperature: 0.9
2025-02-16 10:51:57,782 [INFO]   top_p: 0.3
2025-02-16 10:51:57,782 [INFO]   freq_penalty: 1.0
2025-02-16 10:51:57,782 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 10:51:57,782 [INFO]   debug: 1
2025-02-16 10:51:57,782 [INFO]   save_no_steer: 1
2025-02-16 10:51:57,782 [INFO]   is_norm_delta_matrix: 0
2025-02-16 10:51:57,782 [INFO]   use_cache: 0
2025-02-16 10:51:57,782 [INFO]   repeat_num: 2
2025-02-16 10:51:57,782 [INFO]   gen_batch_size: 16
2025-02-16 10:51:57,782 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 10:51:57,782 [INFO] dataset path /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:51:57,782 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-02-16 10:51:57,782 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus***
2025-02-16 10:51:57,904 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 10:51:58,399 [INFO] 检查数据量 Selected 5476 negative, 5476 positive, and 5476 neutral samples
2025-02-16 10:54:00,613 [INFO] Logging initialized. Logs will be saved to ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/alpha_200.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 10:54:00,613 [INFO] Show Hyperparameters: 


2025-02-16 10:54:00,613 [INFO]   task: polite
2025-02-16 10:54:00,613 [INFO]   layer: 6
2025-02-16 10:54:00,613 [INFO]   LLM: gpt2-small
2025-02-16 10:54:00,613 [INFO]   seed: 42
2025-02-16 10:54:00,613 [INFO]   data_size: -1
2025-02-16 10:54:00,613 [INFO]   device: cuda
2025-02-16 10:54:00,614 [INFO]   alpha: 200.0
2025-02-16 10:54:00,614 [INFO]   method: val_mul
2025-02-16 10:54:00,614 [INFO]   topk_mean: 100
2025-02-16 10:54:00,614 [INFO]   topk_cnt: 100
2025-02-16 10:54:00,614 [INFO]   batch_size: 32
2025-02-16 10:54:00,614 [INFO]   source: pos
2025-02-16 10:54:00,614 [INFO]   target: neg
2025-02-16 10:54:00,614 [INFO]   prompt_source: neg
2025-02-16 10:54:00,614 [INFO]   prompt_data_size: -1
2025-02-16 10:54:00,614 [INFO]   mean_type: dif_mean
2025-02-16 10:54:00,614 [INFO]   steer_type: all
2025-02-16 10:54:00,614 [INFO]   output_dir: ./results/polite/
2025-02-16 10:54:00,614 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:54:00,614 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:54:00,614 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 10:54:00,614 [INFO]   temperature: 0.9
2025-02-16 10:54:00,614 [INFO]   top_p: 0.3
2025-02-16 10:54:00,614 [INFO]   freq_penalty: 1.0
2025-02-16 10:54:00,614 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 10:54:00,614 [INFO]   debug: 1
2025-02-16 10:54:00,614 [INFO]   save_no_steer: 1
2025-02-16 10:54:00,614 [INFO]   is_norm_delta_matrix: 0
2025-02-16 10:54:00,614 [INFO]   use_cache: 0
2025-02-16 10:54:00,614 [INFO]   repeat_num: 2
2025-02-16 10:54:00,614 [INFO]   gen_batch_size: 16
2025-02-16 10:54:00,615 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 10:54:00,615 [INFO] dataset path /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:54:00,615 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-02-16 10:54:00,615 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus***
2025-02-16 10:54:00,639 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 10:54:00,644 [INFO] 检查数据量 Selected 5476 negative, 5476 positive, and 5476 neutral samples
2025-02-16 10:54:00,644 [INFO] 数据集不兼容，没有验证数据集，但是不影响
2025-02-16 10:54:00,644 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-16 10:54:00,644 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-16 10:54:05,214 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-16 10:54:05,214 [INFO] 缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-16 10:54:05,251 [INFO] :>> Sentiment : from pos to neg
2025-02-16 10:54:05,268 [INFO] positive
2025-02-16 10:54:05,284 [INFO] Running model with cache to obtain hidden states
2025-02-16 10:54:12,891 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 10:54:12,892 [INFO] negative
2025-02-16 10:54:12,914 [INFO] Running model with cache to obtain hidden states
2025-02-16 10:54:20,601 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 10:54:20,604 [INFO] steer_info 已保存到缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-16 10:54:20,617 [INFO] 转向方向 dif_neg-pos_relu
2025-02-16 10:54:20,645 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-16 10:54:20,685 [INFO] delta_matrix: tensor([0.0956, 0.2137, 0.0332, 0.2678, 0.1838], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-16 10:54:20,685 [INFO] Generating texts **without** steering... 
2025-02-16 10:54:20,685 [INFO] 无转向结果
2025-02-16 10:54:20,687 [INFO] 无干预
2025-02-16 10:54:22,012 [INFO] 当前批次共处理2个prompt
2025-02-16 10:54:22,012 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 10:54:22,012 [INFO] 生成 1: |

make it harder for a new generation to succeed.

The United States has a population of about 1.5 billion, but its population is growing faster than that of any other developed country in the world. The United States is also one|
2025-02-16 10:54:22,013 [INFO] 生成 2: |

"certainly be a big problem for them," said Mr. McDaniel, who is also a former chief economist at the Federal Reserve Bank of New York. "It's not going to be easy."

The federal government has already|
2025-02-16 10:54:22,013 [INFO] 生成 3: | arouse suspicion among some Republicans.

"I think it's a very bad idea," said Rep. Steve King (R-Iowa), who has been pushing for the federal government to provide more money to states that have already provided Medicaid coverage,|
2025-02-16 10:54:22,013 [INFO] Prompt 2: | She was so busy with her work |
2025-02-16 10:54:22,013 [INFO] 生成 1: | that she didn't even bother to check the email.
I had no idea what to do with this information. I was already a little confused about how I could get this information out of my computer, but I decided to go ahead and do|
2025-02-16 10:54:22,013 [INFO] 生成 2: | that she had to go to the bathroom.
The next day, she went back to work and found that her hair was still wet.
She called me and told me that I had been trying to get rid of it for a while,|
2025-02-16 10:54:22,013 [INFO] 生成 3: | that she couldn't get up to leave the room.
I went to my desk and asked her if she had any more questions. She said that she had, but that it was a bit of a hassle. I asked her if she could|
2025-02-16 10:54:22,013 [INFO] 干预之后的结果
2025-02-16 10:54:22,013 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 10:54:22,013 [INFO] ** Generating texts with steering... Target **
2025-02-16 10:54:22,013 [INFO] form pos to neg
2025-02-16 10:54:22,013 [INFO] 转向结果
2025-02-16 10:54:22,930 [INFO] 当前批次共处理2个prompt
2025-02-16 10:54:22,930 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 10:54:22,930 [INFO] 生成 1: |? why why? why? when? why do you just give a more than one?" ??" Why instead of a high-use a group for this ? Why is this? Why do you have a different way to make your so many people|
2025-02-16 10:54:22,930 [INFO] 生成 2: |? Why why why?? Why why do you have a government that instead of having a single, more powerful?"
 Why do you have a team just to make an extra  why is there a different version of this?", when you instead|
2025-02-16 10:54:22,930 [INFO] 生成 3: |? why? why do you just make a show that? Why? why have you just let me get a bunch of this? Why do I instead have a different group of people who suddenly have an all-use more than one way to make your|
2025-02-16 10:54:22,930 [INFO] Prompt 2: | She was so busy with her work |
2025-02-16 10:54:22,930 [INFO] 生成 1: |?]? Why why? why why? Why??!?! ? Why is this?"? ?
Why do you have a different answer when you just let me get a random?", if I instead of having the answer for a more than just one|
2025-02-16 10:54:22,930 [INFO] 生成 2: |?]? why? why do you have a new low-use a high-class? why? ??" ??!?!  Why don't you just let me just give the player instead of getting an idiot like this?", let's get your super|
2025-02-16 10:54:22,930 [INFO] 生成 3: |?]? Why why why? Why? ? ?" ??!?"?Why are you just a girl instead of a new?", instead of why do you have a show that when?! let's get the first person for the other people? ?"|
2025-02-16 10:54:22,935 [INFO] debug mode,show example, no full dataset eval
2025-02-16 10:54:22,935 [INFO] 训练时间15.389692783355713
2025-02-16 10:54:22,935 [INFO] Show Hyperparameters: 


2025-02-16 10:54:22,935 [INFO]   task: polite
2025-02-16 10:54:22,935 [INFO]   layer: 6
2025-02-16 10:54:22,935 [INFO]   LLM: gpt2-small
2025-02-16 10:54:22,935 [INFO]   seed: 42
2025-02-16 10:54:22,935 [INFO]   data_size: -1
2025-02-16 10:54:22,935 [INFO]   device: cuda
2025-02-16 10:54:22,935 [INFO]   alpha: 200.0
2025-02-16 10:54:22,936 [INFO]   method: val_mul
2025-02-16 10:54:22,936 [INFO]   topk_mean: 100
2025-02-16 10:54:22,936 [INFO]   topk_cnt: 100
2025-02-16 10:54:22,936 [INFO]   batch_size: 32
2025-02-16 10:54:22,936 [INFO]   source: pos
2025-02-16 10:54:22,936 [INFO]   target: neg
2025-02-16 10:54:22,936 [INFO]   prompt_source: neg
2025-02-16 10:54:22,936 [INFO]   prompt_data_size: -1
2025-02-16 10:54:22,936 [INFO]   mean_type: dif_mean
2025-02-16 10:54:22,936 [INFO]   steer_type: all
2025-02-16 10:54:22,936 [INFO]   output_dir: ./results/polite/
2025-02-16 10:54:22,936 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:54:22,936 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:54:22,936 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 10:54:22,936 [INFO]   temperature: 0.9
2025-02-16 10:54:22,936 [INFO]   top_p: 0.3
2025-02-16 10:54:22,936 [INFO]   freq_penalty: 1.0
2025-02-16 10:54:22,936 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 10:54:22,936 [INFO]   debug: 1
2025-02-16 10:54:22,936 [INFO]   save_no_steer: 1
2025-02-16 10:54:22,936 [INFO]   is_norm_delta_matrix: 0
2025-02-16 10:54:22,936 [INFO]   use_cache: 0
2025-02-16 10:54:22,936 [INFO]   repeat_num: 2
2025-02-16 10:54:22,936 [INFO]   gen_batch_size: 16
2025-02-16 10:54:22,936 [INFO]   real_data_size_for_train: 5476
