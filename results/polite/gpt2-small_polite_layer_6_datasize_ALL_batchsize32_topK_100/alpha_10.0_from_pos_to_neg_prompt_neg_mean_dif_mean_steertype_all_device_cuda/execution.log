2025-02-16 10:59:14,207 [INFO] Logging initialized. Logs will be saved to ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/alpha_10.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 10:59:14,207 [INFO] Show Hyperparameters: 


2025-02-16 10:59:14,207 [INFO]   task: polite
2025-02-16 10:59:14,207 [INFO]   layer: 6
2025-02-16 10:59:14,207 [INFO]   LLM: gpt2-small
2025-02-16 10:59:14,207 [INFO]   seed: 42
2025-02-16 10:59:14,207 [INFO]   data_size: -1
2025-02-16 10:59:14,207 [INFO]   device: cuda
2025-02-16 10:59:14,208 [INFO]   alpha: 10.0
2025-02-16 10:59:14,208 [INFO]   method: val_mul
2025-02-16 10:59:14,208 [INFO]   topk_mean: 100
2025-02-16 10:59:14,208 [INFO]   topk_cnt: 100
2025-02-16 10:59:14,208 [INFO]   batch_size: 32
2025-02-16 10:59:14,208 [INFO]   source: pos
2025-02-16 10:59:14,208 [INFO]   target: neg
2025-02-16 10:59:14,208 [INFO]   prompt_source: neg
2025-02-16 10:59:14,208 [INFO]   prompt_data_size: -1
2025-02-16 10:59:14,208 [INFO]   mean_type: dif_mean
2025-02-16 10:59:14,208 [INFO]   steer_type: all
2025-02-16 10:59:14,208 [INFO]   output_dir: ./results/polite/
2025-02-16 10:59:14,208 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:59:14,208 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:59:14,208 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 10:59:14,208 [INFO]   temperature: 0.9
2025-02-16 10:59:14,208 [INFO]   top_p: 0.3
2025-02-16 10:59:14,208 [INFO]   freq_penalty: 1.0
2025-02-16 10:59:14,208 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 10:59:14,208 [INFO]   debug: 1
2025-02-16 10:59:14,208 [INFO]   save_no_steer: 1
2025-02-16 10:59:14,208 [INFO]   is_norm_delta_matrix: 0
2025-02-16 10:59:14,208 [INFO]   use_cache: 0
2025-02-16 10:59:14,208 [INFO]   repeat_num: 2
2025-02-16 10:59:14,208 [INFO]   gen_batch_size: 16
2025-02-16 10:59:14,209 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 10:59:14,209 [INFO] dataset path /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:59:14,209 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-02-16 10:59:14,209 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus***
2025-02-16 10:59:14,233 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 10:59:14,238 [INFO] 检查数据量 Selected 5476 negative, 5476 positive, and 5476 neutral samples
2025-02-16 10:59:14,238 [INFO] 数据集不兼容，没有验证数据集，但是不影响
2025-02-16 10:59:14,238 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-16 10:59:14,238 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-16 10:59:19,021 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-16 10:59:19,022 [INFO] 缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-16 10:59:19,065 [INFO] :>> {TASK} : from pos to neg
2025-02-16 10:59:19,085 [INFO] positive
2025-02-16 10:59:19,105 [INFO] Running model with cache to obtain hidden states
2025-02-16 10:59:26,952 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 10:59:26,952 [INFO] negative
2025-02-16 10:59:26,974 [INFO] Running model with cache to obtain hidden states
2025-02-16 10:59:34,773 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 10:59:34,775 [INFO] steer_info 已保存到缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-16 10:59:34,799 [INFO] 转向方向 dif_neg-pos_relu
2025-02-16 10:59:34,854 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-16 10:59:34,927 [INFO] delta_matrix: tensor([0.0956, 0.2137, 0.0332, 0.2678, 0.1838], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-16 10:59:34,928 [INFO] Generating texts **without** steering... 
2025-02-16 10:59:34,928 [INFO] 无转向结果
2025-02-16 10:59:34,930 [INFO] 无干预
2025-02-16 10:59:36,361 [INFO] 当前批次共处理2个prompt
2025-02-16 10:59:36,361 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 10:59:36,361 [INFO] 生成 1: |-be immigrants have a hard time finding jobs, according to a new report from the Center for Immigration Studies.

The study, released by the think tank, found that about one in five undocumented immigrants who arrived in the U.S. between|
2025-02-16 10:59:36,361 [INFO] 生成 2: | and should have prevented him from becoming a free agent.

"I think it's important to remember that he's been a very good player," said Scott Boras, who has coached with the Rangers since 2007. "He was one of those|
2025-02-16 10:59:36,361 [INFO] 生成 3: |, in fact, be a major problem for many African-Americans.

"I think there's a lot of money to be made," said Larry Koppel, president of the American Civil Liberties Union. "It's not just about getting|
2025-02-16 10:59:36,361 [INFO] Prompt 2: | She was so busy with her work |
2025-02-16 10:59:36,361 [INFO] 生成 1: | that she didn't even bother to get out of bed.
This is the first time I've ever seen a cat in my life. It's a very cute little kitten, but it's not like it has any real purpose other than to|
2025-02-16 10:59:36,361 [INFO] 生成 2: | that she didn't even notice that the entire place was filled with people.
I thought about it for a while, and then I remembered that this place is really important to me. It's where I'm going to go for a walk or|
2025-02-16 10:59:36,361 [INFO] 生成 3: | that she couldn't get up to go to bed. I don't know if it was because of the cold or because she didn't want to wake me up, but I'm sure that if she had been awake at the time, she would|
2025-02-16 10:59:36,361 [INFO] 干预之后的结果
2025-02-16 10:59:36,361 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 10:59:36,361 [INFO] ** Generating texts with steering... Target **
2025-02-16 10:59:36,361 [INFO] form pos to neg
2025-02-16 10:59:36,361 [INFO] 转向结果
2025-02-16 10:59:37,298 [INFO] 当前批次共处理2个prompt
2025-02-16 10:59:37,298 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 10:59:37,298 [INFO] 生成 1: | "be a big problem," says economist David W. Hartman, who is a professor at the University of Chicago's School of Public Policy?

The answer is that they don't have to pay for it. The only way to get help|
2025-02-16 10:59:37,298 [INFO] 生成 2: | it?

In this case, it's not just a matter of money. The federal government is giving more money to the states than to the states themselves? Why should we give them more money if they don't have access to basic services like|
2025-02-16 10:59:37,298 [INFO] 生成 3: |

The U.S. government is willing to give $10 billion to states that have a large number of students?

"We're not going to let them get into the game," said Michael S. Smith, president and CEO of|
2025-02-16 10:59:37,299 [INFO] Prompt 2: | She was so busy with her work |
2025-02-16 10:59:37,299 [INFO] 生成 1: | ? Why is she doing this?
I'm going to give you a chance to make your own web design project. I want to create a new page that will be used for my own website. I want to create a new page that will|
2025-02-16 10:59:37,299 [INFO] 生成 2: | when she was a teenager?
I am a very smart girl. I have always been interested in learning more about myself and my own life. I am the first person to tell you that I have no idea what you are talking about! You|
2025-02-16 10:59:37,299 [INFO] 生成 3: | ?
I'm not going to write about this blog. I've been doing a lot of research on how to make the best of your life. I'm not going to write about this blog. I've been doing a lot of research on|
2025-02-16 10:59:37,303 [INFO] debug mode,show example, no full dataset eval
2025-02-16 10:59:37,303 [INFO] 训练时间15.753889799118042
2025-02-16 10:59:37,303 [INFO] Show Hyperparameters: 


2025-02-16 10:59:37,303 [INFO]   task: polite
2025-02-16 10:59:37,303 [INFO]   layer: 6
2025-02-16 10:59:37,303 [INFO]   LLM: gpt2-small
2025-02-16 10:59:37,303 [INFO]   seed: 42
2025-02-16 10:59:37,303 [INFO]   data_size: -1
2025-02-16 10:59:37,303 [INFO]   device: cuda
2025-02-16 10:59:37,304 [INFO]   alpha: 10.0
2025-02-16 10:59:37,304 [INFO]   method: val_mul
2025-02-16 10:59:37,304 [INFO]   topk_mean: 100
2025-02-16 10:59:37,304 [INFO]   topk_cnt: 100
2025-02-16 10:59:37,304 [INFO]   batch_size: 32
2025-02-16 10:59:37,304 [INFO]   source: pos
2025-02-16 10:59:37,304 [INFO]   target: neg
2025-02-16 10:59:37,304 [INFO]   prompt_source: neg
2025-02-16 10:59:37,304 [INFO]   prompt_data_size: -1
2025-02-16 10:59:37,304 [INFO]   mean_type: dif_mean
2025-02-16 10:59:37,304 [INFO]   steer_type: all
2025-02-16 10:59:37,304 [INFO]   output_dir: ./results/polite/
2025-02-16 10:59:37,304 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:59:37,304 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:59:37,304 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 10:59:37,304 [INFO]   temperature: 0.9
2025-02-16 10:59:37,304 [INFO]   top_p: 0.3
2025-02-16 10:59:37,304 [INFO]   freq_penalty: 1.0
2025-02-16 10:59:37,304 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 10:59:37,304 [INFO]   debug: 1
2025-02-16 10:59:37,304 [INFO]   save_no_steer: 1
2025-02-16 10:59:37,304 [INFO]   is_norm_delta_matrix: 0
2025-02-16 10:59:37,304 [INFO]   use_cache: 0
2025-02-16 10:59:37,304 [INFO]   repeat_num: 2
2025-02-16 10:59:37,304 [INFO]   gen_batch_size: 16
2025-02-16 10:59:37,304 [INFO]   real_data_size_for_train: 5476
2025-02-16 11:02:04,341 [INFO] Logging initialized. Logs will be saved to ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/alpha_10.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 11:02:04,341 [INFO] Show Hyperparameters: 


2025-02-16 11:02:04,341 [INFO]   task: polite
2025-02-16 11:02:04,341 [INFO]   layer: 6
2025-02-16 11:02:04,341 [INFO]   LLM: gpt2-small
2025-02-16 11:02:04,341 [INFO]   seed: 42
2025-02-16 11:02:04,341 [INFO]   data_size: -1
2025-02-16 11:02:04,341 [INFO]   device: cuda
2025-02-16 11:02:04,341 [INFO]   alpha: 10.0
2025-02-16 11:02:04,341 [INFO]   method: val_mul
2025-02-16 11:02:04,341 [INFO]   topk_mean: 100
2025-02-16 11:02:04,341 [INFO]   topk_cnt: 100
2025-02-16 11:02:04,341 [INFO]   batch_size: 32
2025-02-16 11:02:04,341 [INFO]   source: pos
2025-02-16 11:02:04,341 [INFO]   target: neg
2025-02-16 11:02:04,341 [INFO]   prompt_source: neg
2025-02-16 11:02:04,341 [INFO]   prompt_data_size: -1
2025-02-16 11:02:04,341 [INFO]   mean_type: dif_mean
2025-02-16 11:02:04,341 [INFO]   steer_type: all
2025-02-16 11:02:04,341 [INFO]   output_dir: ./results/polite/
2025-02-16 11:02:04,341 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:02:04,342 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:02:04,342 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 11:02:04,342 [INFO]   temperature: 0.9
2025-02-16 11:02:04,342 [INFO]   top_p: 0.3
2025-02-16 11:02:04,342 [INFO]   freq_penalty: 1.0
2025-02-16 11:02:04,342 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 11:02:04,342 [INFO]   debug: 1
2025-02-16 11:02:04,342 [INFO]   save_no_steer: 1
2025-02-16 11:02:04,342 [INFO]   is_norm_delta_matrix: 0
2025-02-16 11:02:04,342 [INFO]   use_cache: 0
2025-02-16 11:02:04,342 [INFO]   repeat_num: 2
2025-02-16 11:02:04,342 [INFO]   gen_batch_size: 16
2025-02-16 11:02:04,342 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 11:02:04,342 [INFO] dataset path /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:02:04,342 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-02-16 11:02:04,343 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus***
2025-02-16 11:02:04,376 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 11:02:04,381 [INFO] 检查数据量 Selected 5476 negative, 5476 positive, and 5476 neutral samples
2025-02-16 11:02:04,381 [INFO] 数据集不兼容，没有验证数据集，但是不影响
2025-02-16 11:02:04,381 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-16 11:02:04,381 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-16 11:02:08,719 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-16 11:02:08,719 [INFO] 缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-16 11:02:08,763 [INFO] :>> {TASK} : from pos to neg
2025-02-16 11:02:08,783 [INFO] positive
2025-02-16 11:02:08,803 [INFO] Running model with cache to obtain hidden states
2025-02-16 11:02:16,436 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 11:02:16,437 [INFO] negative
2025-02-16 11:02:16,458 [INFO] Running model with cache to obtain hidden states
2025-02-16 11:02:24,155 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 11:02:24,157 [INFO] steer_info 已保存到缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-16 11:02:24,171 [INFO] 转向方向 dif_neg-pos_relu
2025-02-16 11:02:24,204 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-16 11:02:24,250 [INFO] delta_matrix: tensor([0.0956, 0.2137, 0.0332, 0.2678, 0.1838], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-16 11:02:24,251 [INFO] Generating texts **without** steering... 
2025-02-16 11:02:24,251 [INFO] 无转向结果
2025-02-16 11:02:24,253 [INFO] 无干预
2025-02-16 11:02:25,604 [INFO] 当前批次共处理2个prompt
2025-02-16 11:02:25,604 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 11:02:25,604 [INFO] 生成 1: |.

"The reality is that if you're going to have a job, you need to have a job," said Mark Kornacki, president of the American Federation of State, County and Municipal Employees. "If you're going to|
2025-02-16 11:02:25,604 [INFO] 生成 2: |-be students have to pay for their tuition.

"It's not a big deal," said Tom Smith, a sophomore at the University of California, Berkeley. "It's just not going to happen."

The $5,000|
2025-02-16 11:02:25,604 [INFO] 生成 3: |

Make sure you're getting the best deal possible. If you're not, we'll help you get your money back.

Our team is committed to helping you get the best deal possible. We offer free shipping on orders over $50|
2025-02-16 11:02:25,604 [INFO] Prompt 2: | She was so busy with her work |
2025-02-16 11:02:25,604 [INFO] 生成 1: | that she didn't even notice that the dog had been sitting on her lap.
I have to admit, I was a little surprised when I saw this photo of the dog. It looked like it had been taken by a cat, but it|
2025-02-16 11:02:25,604 [INFO] 生成 2: | that she couldn't even get a good look at the whole thing.
The next day, I got a call from my boss. He told me that he had been called to the office and that he wanted to meet with me for lunch.|
2025-02-16 11:02:25,604 [INFO] 生成 3: | that she had to leave the house.
The next day, I found out that she had been arrested for DUI.
I was so excited to get my hands on this case that I started looking around and found a lot of things wrong with|
2025-02-16 11:02:25,604 [INFO] 干预之后的结果
2025-02-16 11:02:25,604 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 11:02:25,605 [INFO] ** Generating texts with steering... Target **
2025-02-16 11:02:25,605 [INFO] form pos to neg
2025-02-16 11:02:25,605 [INFO] 转向结果
2025-02-16 11:02:26,555 [INFO] 当前批次共处理2个prompt
2025-02-16 11:02:26,556 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 11:02:26,556 [INFO] 生成 1: | "help to make sure that the government doesn't have to do more?"

The United States has a lot of money. It's not just people who need help. It's also people who are poor, and those poor people need help.|
2025-02-16 11:02:26,556 [INFO] 生成 2: | it be so easy to get a job?

The federal government is trying to provide more funding for the university system. The University of California at Berkeley has already offered $2 billion in grants to students, faculty and staff. Why would you give|
2025-02-16 11:02:26,556 [INFO] 生成 3: |I have to take a look at the federal government's priorities?

The U.S. government is not only failing to provide adequate education for all Americans, but also many other countries? Why would you want to do something about it?
|
2025-02-16 11:02:26,556 [INFO] Prompt 2: | She was so busy with her work |
2025-02-16 11:02:26,556 [INFO] 生成 1: | when she had to leave?
I'm not sure what I'm doing right now. I can't do anything for you, but if you don't want to help me, then please let me know.
I have a feeling that the|
2025-02-16 11:02:26,556 [INFO] 生成 2: | ?
This is the first time I've ever been asked to write a blog post about me?
I'm sure you're thinking, "Why do I have to write a blog post about me?" Well, because it's not like I|
2025-02-16 11:02:26,556 [INFO] 生成 3: | when she got a job?
I am not sure if I should just go to school and study for my degree?
I have been working on this project for over a year now. I want to learn more about how to make your own|
2025-02-16 11:02:26,561 [INFO] debug mode,show example, no full dataset eval
2025-02-16 11:02:26,561 [INFO] 训练时间15.437967777252197
2025-02-16 11:02:26,561 [INFO] Show Hyperparameters: 


2025-02-16 11:02:26,561 [INFO]   task: polite
2025-02-16 11:02:26,561 [INFO]   layer: 6
2025-02-16 11:02:26,561 [INFO]   LLM: gpt2-small
2025-02-16 11:02:26,561 [INFO]   seed: 42
2025-02-16 11:02:26,561 [INFO]   data_size: -1
2025-02-16 11:02:26,561 [INFO]   device: cuda
2025-02-16 11:02:26,561 [INFO]   alpha: 10.0
2025-02-16 11:02:26,561 [INFO]   method: val_mul
2025-02-16 11:02:26,561 [INFO]   topk_mean: 100
2025-02-16 11:02:26,561 [INFO]   topk_cnt: 100
2025-02-16 11:02:26,561 [INFO]   batch_size: 32
2025-02-16 11:02:26,561 [INFO]   source: pos
2025-02-16 11:02:26,561 [INFO]   target: neg
2025-02-16 11:02:26,561 [INFO]   prompt_source: neg
2025-02-16 11:02:26,561 [INFO]   prompt_data_size: -1
2025-02-16 11:02:26,561 [INFO]   mean_type: dif_mean
2025-02-16 11:02:26,561 [INFO]   steer_type: all
2025-02-16 11:02:26,561 [INFO]   output_dir: ./results/polite/
2025-02-16 11:02:26,561 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:02:26,561 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 11:02:26,561 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 11:02:26,561 [INFO]   temperature: 0.9
2025-02-16 11:02:26,561 [INFO]   top_p: 0.3
2025-02-16 11:02:26,562 [INFO]   freq_penalty: 1.0
2025-02-16 11:02:26,562 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 11:02:26,562 [INFO]   debug: 1
2025-02-16 11:02:26,562 [INFO]   save_no_steer: 1
2025-02-16 11:02:26,562 [INFO]   is_norm_delta_matrix: 0
2025-02-16 11:02:26,562 [INFO]   use_cache: 0
2025-02-16 11:02:26,562 [INFO]   repeat_num: 2
2025-02-16 11:02:26,562 [INFO]   gen_batch_size: 16
2025-02-16 11:02:26,562 [INFO]   real_data_size_for_train: 5476
2025-02-19 18:26:09,447 [INFO] Logging initialized. Logs will be saved to ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/alpha_10.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-19 18:26:09,447 [INFO] Show Hyperparameters: 


2025-02-19 18:26:09,447 [INFO]   task: polite
2025-02-19 18:26:09,447 [INFO]   layer: 6
2025-02-19 18:26:09,447 [INFO]   LLM: gpt2-small
2025-02-19 18:26:09,447 [INFO]   seed: 42
2025-02-19 18:26:09,447 [INFO]   data_size: -1
2025-02-19 18:26:09,447 [INFO]   device: cuda
2025-02-19 18:26:09,447 [INFO]   alpha: 10.0
2025-02-19 18:26:09,447 [INFO]   method: val_mul
2025-02-19 18:26:09,447 [INFO]   topk_mean: 100
2025-02-19 18:26:09,447 [INFO]   topk_cnt: 100
2025-02-19 18:26:09,447 [INFO]   batch_size: 32
2025-02-19 18:26:09,447 [INFO]   source: pos
2025-02-19 18:26:09,447 [INFO]   target: neg
2025-02-19 18:26:09,447 [INFO]   prompt_source: neg
2025-02-19 18:26:09,447 [INFO]   prompt_data_size: -1
2025-02-19 18:26:09,447 [INFO]   mean_type: dif_mean
2025-02-19 18:26:09,447 [INFO]   steer_type: all
2025-02-19 18:26:09,447 [INFO]   output_dir: ./results/polite/
2025-02-19 18:26:09,447 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-19 18:26:09,448 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-19 18:26:09,448 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-19 18:26:09,448 [INFO]   temperature: 0.9
2025-02-19 18:26:09,448 [INFO]   top_p: 0.3
2025-02-19 18:26:09,448 [INFO]   freq_penalty: 1.0
2025-02-19 18:26:09,448 [INFO]   example_prompt: But the lack of financial aid would| The passage of the AI Act wil
2025-02-19 18:26:09,448 [INFO]   debug: 1
2025-02-19 18:26:09,448 [INFO]   save_no_steer: 1
2025-02-19 18:26:09,448 [INFO]   is_norm_delta_matrix: 0
2025-02-19 18:26:09,448 [INFO]   use_cache: 0
2025-02-19 18:26:09,448 [INFO]   repeat_num: 2
2025-02-19 18:26:09,448 [INFO]   gen_batch_size: 16
2025-02-19 18:26:09,448 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-19 18:26:09,448 [INFO] dataset path /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-19 18:26:09,448 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-02-19 18:26:09,448 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-19 18:26:09,474 [INFO] Filtering dataset for polite and nonpolite samples
2025-02-19 18:26:09,478 [INFO] Selected 4136 polite and 4098 nonpolite samples
2025-02-19 18:26:09,479 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-19 18:26:09,479 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-19 18:35:34,521 [INFO] Logging initialized. Logs will be saved to ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/alpha_10.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-19 18:35:34,521 [INFO] Show Hyperparameters: 


2025-02-19 18:35:34,521 [INFO]   task: polite
2025-02-19 18:35:34,521 [INFO]   layer: 6
2025-02-19 18:35:34,521 [INFO]   LLM: gpt2-small
2025-02-19 18:35:34,521 [INFO]   seed: 42
2025-02-19 18:35:34,521 [INFO]   data_size: -1
2025-02-19 18:35:34,521 [INFO]   device: cuda
2025-02-19 18:35:34,521 [INFO]   alpha: 10.0
2025-02-19 18:35:34,521 [INFO]   method: val_mul
2025-02-19 18:35:34,521 [INFO]   topk_mean: 100
2025-02-19 18:35:34,521 [INFO]   topk_cnt: 100
2025-02-19 18:35:34,522 [INFO]   batch_size: 32
2025-02-19 18:35:34,522 [INFO]   source: pos
2025-02-19 18:35:34,522 [INFO]   target: neg
2025-02-19 18:35:34,522 [INFO]   prompt_source: neg
2025-02-19 18:35:34,522 [INFO]   prompt_data_size: 100
2025-02-19 18:35:34,522 [INFO]   mean_type: dif_mean
2025-02-19 18:35:34,522 [INFO]   steer_type: all
2025-02-19 18:35:34,522 [INFO]   output_dir: ./results/polite/
2025-02-19 18:35:34,522 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-19 18:35:34,522 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-19 18:35:34,522 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-19 18:35:34,522 [INFO]   temperature: 0.9
2025-02-19 18:35:34,522 [INFO]   top_p: 0.3
2025-02-19 18:35:34,522 [INFO]   freq_penalty: 1.0
2025-02-19 18:35:34,522 [INFO]   example_prompt: But the lack of financial aid would| The passage of the AI Act wil
2025-02-19 18:35:34,522 [INFO]   debug: 1
2025-02-19 18:35:34,522 [INFO]   save_no_steer: 1
2025-02-19 18:35:34,522 [INFO]   is_norm_delta_matrix: 0
2025-02-19 18:35:34,522 [INFO]   use_cache: 0
2025-02-19 18:35:34,522 [INFO]   repeat_num: 2
2025-02-19 18:35:34,522 [INFO]   gen_batch_size: 16
2025-02-19 18:35:34,522 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-19 18:35:34,522 [INFO] dataset path /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-19 18:35:34,522 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-02-19 18:35:34,522 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-19 18:35:34,543 [INFO] Filtering dataset for polite and nonpolite samples
2025-02-19 18:35:34,547 [INFO] Selected 4136 polite and 4098 nonpolite samples
2025-02-19 18:35:34,547 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-19 18:35:34,547 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-19 18:35:36,674 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-19 18:35:36,675 [INFO] 缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-19 18:35:36,709 [INFO] :>> polite : from pos to neg
2025-02-19 18:35:36,725 [INFO] positive
2025-02-19 18:35:36,740 [INFO] Running model with cache to obtain hidden states
2025-02-19 18:35:42,435 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-19 18:35:42,436 [INFO] negative
2025-02-19 18:35:42,451 [INFO] Running model with cache to obtain hidden states
2025-02-19 18:35:48,516 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-19 18:35:48,518 [INFO] steer_info 已保存到缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-19 18:35:48,531 [INFO] 转向方向 dif_neg-pos_relu
2025-02-19 18:35:48,568 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-19 18:35:48,608 [INFO] delta_matrix: tensor([ 0.0829,  0.3953, -0.1047,  0.2565,  0.1550], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-19 18:35:48,609 [INFO] Generating texts **without** steering... 
2025-02-19 18:35:48,609 [INFO] 无转向结果
2025-02-19 18:35:48,611 [INFO] 无干预
2025-02-19 18:35:49,982 [INFO] 当前批次共处理2个prompt
2025-02-19 18:35:49,982 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-19 18:35:49,982 [INFO] 生成 1: | be a big blow to the program, which has been in operation since 2011.

"It's a real blow to our program," said Jeff Chiu, president of the California-based Center for Economic and Policy Research. "We're going|
2025-02-19 18:35:49,982 [INFO] 生成 2: | be a big problem for those who have been struggling to make ends meet.

The federal government has said it will not accept more than $2 billion in grants from states that have given their residents the money, but only if they are able to|
2025-02-19 18:35:49,982 [INFO] 生成 3: | be a major blow to the struggling economy.

The federal government has been under pressure from Congress to help low-income Americans find work, and some states have been able to offer job training programs. But that's not always easy for low-|
2025-02-19 18:35:49,982 [INFO] Prompt 2: | The passage of the AI Act wil|
2025-02-19 18:35:49,982 [INFO] 生成 1: |fully and recklessly undermines the very principles that underpin our democracy.

The AI Act is a dangerous step towards a future where the most powerful institutions are being eroded by technology. It will lead to an era of increased surveillance, in which all information|
2025-02-19 18:35:49,982 [INFO] 生成 2: |fully stifles innovation and innovation in the industry.

The bill, which was introduced by a coalition of businesses including Apple, Google, Microsoft and Facebook, is designed to help companies like Apple's Siri and Google's Assistant get better at building apps|
2025-02-19 18:35:49,982 [INFO] 生成 3: |fully ignores the fundamental principle that any change in technology is a process.

In fact, it's not even clear what that means. In an interview with Wired, the Australian director of research at Stanford University, Robert Wahlberg said: "|
2025-02-19 18:35:49,982 [INFO] 干预之后的结果
2025-02-19 18:35:49,982 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-19 18:35:49,983 [INFO] ** Generating texts with steering... Target **
2025-02-19 18:35:49,983 [INFO] form pos to neg
2025-02-19 18:35:49,983 [INFO] 转向结果
2025-02-19 18:35:50,903 [INFO] 当前批次共处理2个prompt
2025-02-19 18:35:50,903 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-19 18:35:50,904 [INFO] 生成 1: | the U.S. government take on more responsibility for protecting its citizens?

The first reason is that there are no federal agencies that can do anything about it. The second reason is that it's not clear how to do this without a significant|
2025-02-19 18:35:50,904 [INFO] 生成 2: | you rather have a better education?"

"Why is it that we have no choice but to pay for education?"

"Why does it matter if you are poor or rich? Why is it that the government doesn't provide any funding to|
2025-02-19 18:35:50,904 [INFO] 生成 3: | so many people feel they have no choice but to leave?

"The answer is that there are many reasons why you don't want to stay in this country," says David Lipscomb, a professor at the University of Toronto's School of|
2025-02-19 18:35:50,904 [INFO] Prompt 2: | The passage of the AI Act wil|
2025-02-19 18:35:50,904 [INFO] 生成 1: | you? Why is it that I am a man who is a woman?

I am not a man. I am not an individual. I am not an individual with any other rights than those granted to me by law. It is my duty|
2025-02-19 18:35:50,904 [INFO] 生成 2: | anyone be surprised by a series of events that have been happening for the last two years?

It is obvious that the government has no interest in protecting its citizens from what it calls "the most serious threat to our security" – namely, terrorism|
2025-02-19 18:35:50,904 [INFO] 生成 3: | we not know what it is?"

"The reason why I am here is because I want to see the future. If you don't like me, then you can leave. You can leave now."

"I'm not a fan|
2025-02-19 18:35:50,909 [INFO] debug mode,show example, no full dataset eval
2025-02-19 18:35:50,909 [INFO] 训练时间11.843604803085327
2025-02-19 18:35:50,909 [INFO] Show Hyperparameters: 


2025-02-19 18:35:50,909 [INFO]   task: polite
2025-02-19 18:35:50,909 [INFO]   layer: 6
2025-02-19 18:35:50,909 [INFO]   LLM: gpt2-small
2025-02-19 18:35:50,909 [INFO]   seed: 42
2025-02-19 18:35:50,909 [INFO]   data_size: -1
2025-02-19 18:35:50,909 [INFO]   device: cuda
2025-02-19 18:35:50,909 [INFO]   alpha: 10.0
2025-02-19 18:35:50,910 [INFO]   method: val_mul
2025-02-19 18:35:50,910 [INFO]   topk_mean: 100
2025-02-19 18:35:50,910 [INFO]   topk_cnt: 100
2025-02-19 18:35:50,910 [INFO]   batch_size: 32
2025-02-19 18:35:50,910 [INFO]   source: pos
2025-02-19 18:35:50,910 [INFO]   target: neg
2025-02-19 18:35:50,910 [INFO]   prompt_source: neg
2025-02-19 18:35:50,910 [INFO]   prompt_data_size: 100
2025-02-19 18:35:50,910 [INFO]   mean_type: dif_mean
2025-02-19 18:35:50,910 [INFO]   steer_type: all
2025-02-19 18:35:50,910 [INFO]   output_dir: ./results/polite/
2025-02-19 18:35:50,910 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-19 18:35:50,910 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-19 18:35:50,910 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-19 18:35:50,910 [INFO]   temperature: 0.9
2025-02-19 18:35:50,910 [INFO]   top_p: 0.3
2025-02-19 18:35:50,910 [INFO]   freq_penalty: 1.0
2025-02-19 18:35:50,910 [INFO]   example_prompt: But the lack of financial aid would| The passage of the AI Act wil
2025-02-19 18:35:50,910 [INFO]   debug: 1
2025-02-19 18:35:50,910 [INFO]   save_no_steer: 1
2025-02-19 18:35:50,910 [INFO]   is_norm_delta_matrix: 0
2025-02-19 18:35:50,910 [INFO]   use_cache: 0
2025-02-19 18:35:50,910 [INFO]   repeat_num: 2
2025-02-19 18:35:50,910 [INFO]   gen_batch_size: 16
2025-02-19 18:35:50,910 [INFO]   real_data_size_for_train: 4098
2025-02-19 18:35:50,910 [INFO] polite:pos->neg
