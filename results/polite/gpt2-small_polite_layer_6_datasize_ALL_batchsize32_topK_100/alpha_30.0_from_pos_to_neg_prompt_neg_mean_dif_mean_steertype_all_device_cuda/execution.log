2025-02-16 10:58:18,784 [INFO] Logging initialized. Logs will be saved to ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/alpha_30.0_from_pos_to_neg_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-16 10:58:18,784 [INFO] Show Hyperparameters: 


2025-02-16 10:58:18,784 [INFO]   task: polite
2025-02-16 10:58:18,784 [INFO]   layer: 6
2025-02-16 10:58:18,784 [INFO]   LLM: gpt2-small
2025-02-16 10:58:18,784 [INFO]   seed: 42
2025-02-16 10:58:18,784 [INFO]   data_size: -1
2025-02-16 10:58:18,784 [INFO]   device: cuda
2025-02-16 10:58:18,784 [INFO]   alpha: 30.0
2025-02-16 10:58:18,784 [INFO]   method: val_mul
2025-02-16 10:58:18,784 [INFO]   topk_mean: 100
2025-02-16 10:58:18,785 [INFO]   topk_cnt: 100
2025-02-16 10:58:18,785 [INFO]   batch_size: 32
2025-02-16 10:58:18,785 [INFO]   source: pos
2025-02-16 10:58:18,785 [INFO]   target: neg
2025-02-16 10:58:18,785 [INFO]   prompt_source: neg
2025-02-16 10:58:18,785 [INFO]   prompt_data_size: -1
2025-02-16 10:58:18,785 [INFO]   mean_type: dif_mean
2025-02-16 10:58:18,785 [INFO]   steer_type: all
2025-02-16 10:58:18,785 [INFO]   output_dir: ./results/polite/
2025-02-16 10:58:18,785 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:58:18,785 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:58:18,785 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 10:58:18,785 [INFO]   temperature: 0.9
2025-02-16 10:58:18,785 [INFO]   top_p: 0.3
2025-02-16 10:58:18,785 [INFO]   freq_penalty: 1.0
2025-02-16 10:58:18,785 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 10:58:18,785 [INFO]   debug: 1
2025-02-16 10:58:18,785 [INFO]   save_no_steer: 1
2025-02-16 10:58:18,785 [INFO]   is_norm_delta_matrix: 0
2025-02-16 10:58:18,785 [INFO]   use_cache: 0
2025-02-16 10:58:18,785 [INFO]   repeat_num: 2
2025-02-16 10:58:18,785 [INFO]   gen_batch_size: 16
2025-02-16 10:58:18,785 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-16 10:58:18,785 [INFO] dataset path /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:58:18,786 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-02-16 10:58:18,786 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus***
2025-02-16 10:58:18,805 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-02-16 10:58:18,809 [INFO] 检查数据量 Selected 5476 negative, 5476 positive, and 5476 neutral samples
2025-02-16 10:58:18,809 [INFO] 数据集不兼容，没有验证数据集，但是不影响
2025-02-16 10:58:18,809 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-16 10:58:18,809 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-16 10:58:22,953 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-16 10:58:22,954 [INFO] 缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-16 10:58:22,997 [INFO] :>> {TASK} : from pos to neg
2025-02-16 10:58:23,018 [INFO] positive
2025-02-16 10:58:23,038 [INFO] Running model with cache to obtain hidden states
2025-02-16 10:58:30,695 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 10:58:30,696 [INFO] negative
2025-02-16 10:58:30,717 [INFO] Running model with cache to obtain hidden states
2025-02-16 10:58:38,346 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-16 10:58:38,348 [INFO] steer_info 已保存到缓存 ./results/polite/gpt2-small_polite_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-16 10:58:38,361 [INFO] 转向方向 dif_neg-pos_relu
2025-02-16 10:58:38,389 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-16 10:58:38,427 [INFO] delta_matrix: tensor([0.0956, 0.2137, 0.0332, 0.2678, 0.1838], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-16 10:58:38,427 [INFO] Generating texts **without** steering... 
2025-02-16 10:58:38,427 [INFO] 无转向结果
2025-02-16 10:58:38,429 [INFO] 无干预
2025-02-16 10:58:39,755 [INFO] 当前批次共处理2个prompt
2025-02-16 10:58:39,755 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 10:58:39,755 [INFO] 生成 1: |

"be a major problem for the United States," said Michael W. Vladeck, an economist at the University of California, Berkeley. "The U.S. has not had a single federal program to help low-income people|
2025-02-16 10:58:39,755 [INFO] 生成 2: |, in fact, have been a big problem for Mr. Obama's first term.

The president has been unable to secure enough money to pay his bills since taking office, and he has struggled to raise enough money for his family's health care|
2025-02-16 10:58:39,756 [INFO] 生成 3: | in turn be a major blow to his campaign.

"I'm not going to get into the specifics of what I'm going to do," he said. "I'm not going to go into how much money I'll spend on my campaign|
2025-02-16 10:58:39,756 [INFO] Prompt 2: | She was so busy with her work |
2025-02-16 10:58:39,756 [INFO] 生成 1: | that she forgot to finish her homework.
She had a bad day, and it wasn't because of the bad grades she received. It was because of the fact that she didn't have time to read or write, and she didn't have|
2025-02-16 10:58:39,756 [INFO] 生成 2: | that she didn't even notice that the boy was wearing a pair of shoes.
She had to stop and look at him, then go back to her desk. She couldn't help but think about how she'd been working on this for so|
2025-02-16 10:58:39,756 [INFO] 生成 3: | that she didn't even bother to take a shower.
She's also been using a bathtub as a base for the rest of her life.
The only thing that really bothered me about this picture is how it looks on the wall.|
2025-02-16 10:58:39,756 [INFO] 干预之后的结果
2025-02-16 10:58:39,756 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-16 10:58:39,756 [INFO] ** Generating texts with steering... Target **
2025-02-16 10:58:39,756 [INFO] form pos to neg
2025-02-16 10:58:39,756 [INFO] 转向结果
2025-02-16 10:58:40,660 [INFO] 当前批次共处理2个prompt
2025-02-16 10:58:40,660 [INFO] Prompt 1: |But the lack of financial aid would|
2025-02-16 10:58:40,660 [INFO] 生成 1: |?

The same people who are doing this? Why do you have a government that is going to make the people involved in the project?"

If you just get a few more people who want to use this data when we just give them|
2025-02-16 10:58:40,660 [INFO] 生成 2: |? I'm not going to give a bunch of people a piece of shit? Why are you so low-level developers just using some other way to make something that makes it easier for them to use this information when we just make them have an open|
2025-02-16 10:58:40,660 [INFO] 生成 3: |?

The "New Orleans Saints?" Why do you have a high-powered group of people that has the power to make it so that they can use your own resources instead of other methods? Why are we doing this? It's so simple|
2025-02-16 10:58:40,660 [INFO] Prompt 2: | She was so busy with her work |
2025-02-16 10:58:40,660 [INFO] 生成 1: | I have a good reason? Why do you have a little girl like me? I'm just going to make it easier for me to use my powers?

I want to get the same thing that she has this thing so much of the world|
2025-02-16 10:58:40,660 [INFO] 生成 2: | I'm just going to give you a quick update? Why do you have a way to make this so easy? I'm not doing something that is really useful for the players? Why are you trying to make it so simple for me when we just|
2025-02-16 10:58:40,660 [INFO] 生成 3: | I just want to see the game? Why is it so easy? Why are you making a game that makes a new character like me have an awesome mod that makes something different? I'm just going to make something that has this guy so important?|
2025-02-16 10:58:40,665 [INFO] debug mode,show example, no full dataset eval
2025-02-16 10:58:40,665 [INFO] 训练时间15.39485478401184
2025-02-16 10:58:40,665 [INFO] Show Hyperparameters: 


2025-02-16 10:58:40,665 [INFO]   task: polite
2025-02-16 10:58:40,665 [INFO]   layer: 6
2025-02-16 10:58:40,665 [INFO]   LLM: gpt2-small
2025-02-16 10:58:40,665 [INFO]   seed: 42
2025-02-16 10:58:40,665 [INFO]   data_size: -1
2025-02-16 10:58:40,665 [INFO]   device: cuda
2025-02-16 10:58:40,665 [INFO]   alpha: 30.0
2025-02-16 10:58:40,665 [INFO]   method: val_mul
2025-02-16 10:58:40,665 [INFO]   topk_mean: 100
2025-02-16 10:58:40,665 [INFO]   topk_cnt: 100
2025-02-16 10:58:40,665 [INFO]   batch_size: 32
2025-02-16 10:58:40,665 [INFO]   source: pos
2025-02-16 10:58:40,665 [INFO]   target: neg
2025-02-16 10:58:40,665 [INFO]   prompt_source: neg
2025-02-16 10:58:40,665 [INFO]   prompt_data_size: -1
2025-02-16 10:58:40,666 [INFO]   mean_type: dif_mean
2025-02-16 10:58:40,666 [INFO]   steer_type: all
2025-02-16 10:58:40,666 [INFO]   output_dir: ./results/polite/
2025-02-16 10:58:40,666 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:58:40,666 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-02-16 10:58:40,666 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-16 10:58:40,666 [INFO]   temperature: 0.9
2025-02-16 10:58:40,666 [INFO]   top_p: 0.3
2025-02-16 10:58:40,666 [INFO]   freq_penalty: 1.0
2025-02-16 10:58:40,666 [INFO]   example_prompt: But the lack of financial aid would| She was so busy with her work 
2025-02-16 10:58:40,666 [INFO]   debug: 1
2025-02-16 10:58:40,666 [INFO]   save_no_steer: 1
2025-02-16 10:58:40,666 [INFO]   is_norm_delta_matrix: 0
2025-02-16 10:58:40,666 [INFO]   use_cache: 0
2025-02-16 10:58:40,666 [INFO]   repeat_num: 2
2025-02-16 10:58:40,666 [INFO]   gen_batch_size: 16
2025-02-16 10:58:40,666 [INFO]   real_data_size_for_train: 5476
