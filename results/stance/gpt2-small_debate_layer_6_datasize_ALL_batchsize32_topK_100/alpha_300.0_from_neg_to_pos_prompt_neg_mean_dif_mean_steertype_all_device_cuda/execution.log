2025-02-09 23:30:24,839 [INFO] Logging initialized. Logs will be saved to ./results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/alpha_300.0_from_neg_to_pos_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-09 23:30:24,839 [INFO] Show Hyperparameters: 


2025-02-09 23:30:24,839 [INFO]   task: debate
2025-02-09 23:30:24,839 [INFO]   layer: 6
2025-02-09 23:30:24,840 [INFO]   LLM: gpt2-small
2025-02-09 23:30:24,840 [INFO]   seed: 42
2025-02-09 23:30:24,840 [INFO]   data_size: -1
2025-02-09 23:30:24,840 [INFO]   device: cuda
2025-02-09 23:30:24,840 [INFO]   alpha: 300.0
2025-02-09 23:30:24,840 [INFO]   method: val_mul
2025-02-09 23:30:24,840 [INFO]   topk_mean: 100
2025-02-09 23:30:24,840 [INFO]   topk_cnt: 100
2025-02-09 23:30:24,840 [INFO]   batch_size: 32
2025-02-09 23:30:24,840 [INFO]   source: neg
2025-02-09 23:30:24,840 [INFO]   target: pos
2025-02-09 23:30:24,840 [INFO]   prompt_source: neg
2025-02-09 23:30:24,840 [INFO]   prompt_data_size: -1
2025-02-09 23:30:24,840 [INFO]   mean_type: dif_mean
2025-02-09 23:30:24,840 [INFO]   steer_type: all
2025-02-09 23:30:24,840 [INFO]   output_dir: ./results/stance
2025-02-09 23:30:24,840 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:30:24,840 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/ibm_debate
2025-02-09 23:30:24,840 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-09 23:30:24,840 [INFO]   temperature: 0.9
2025-02-09 23:30:24,840 [INFO]   top_p: 0.3
2025-02-09 23:30:24,840 [INFO]   freq_penalty: 1.0
2025-02-09 23:30:24,840 [INFO]   example_prompt: But the lack of financial aid would| I feel 
2025-02-09 23:30:24,840 [INFO]   debug: 1
2025-02-09 23:30:24,840 [INFO]   save_no_steer: 0
2025-02-09 23:30:24,840 [INFO]   is_norm_delta_matrix: 0
2025-02-09 23:30:24,840 [INFO]   use_cache: 0
2025-02-09 23:30:24,840 [INFO]   repeat_num: 2
2025-02-09 23:30:24,840 [INFO]   gen_batch_size: 16
2025-02-09 23:30:24,841 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-09 23:30:24,841 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:30:24,841 [INFO] debatedebatedebatedebatedebatedebatedebatedebatedebatedebate
2025-02-09 23:30:24,841 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:30:24,974 [INFO] Filtering dataset for support and oppose samples
2025-02-09 23:30:24,977 [INFO] Selected 486 support and 486 oppose samples
2025-02-09 23:30:24,977 [INFO] suppoert==positive opposite==negative
2025-02-09 23:30:24,977 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-09 23:30:24,977 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-09 23:30:35,211 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-09 23:30:35,212 [INFO] 缓存 ./results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-09 23:30:35,216 [INFO] :> Debate :fromnegtopos
2025-02-09 23:30:35,216 [INFO] support
2025-02-09 23:30:35,219 [INFO] Running model with cache to obtain hidden states
2025-02-09 23:30:35,936 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-09 23:30:35,937 [INFO] oppose
2025-02-09 23:30:35,939 [INFO] Running model with cache to obtain hidden states
2025-02-09 23:30:36,476 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-09 23:30:36,478 [INFO] steer_info 已保存到缓存 ./results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-09 23:30:36,488 [INFO] 转向方向 dif_pos-neg_relu
2025-02-09 23:30:36,509 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-09 23:30:36,536 [INFO] delta_matrix: tensor([-0.0284,  0.2685,  0.0067,  0.0359,  0.1836], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-09 23:30:36,536 [INFO] Example prompt: ['But the lack of financial aid would', ' I feel ']
2025-02-09 23:30:36,536 [INFO] Generating texts **without** steering... 
2025-02-09 23:30:36,538 [INFO] 无干预
2025-02-09 23:30:37,825 [INFO] 当前批次共处理2个prompt
2025-02-09 23:30:37,826 [INFO] Prompt 1: But the lack of financial aid would...
2025-02-09 23:30:37,826 [INFO] 生成 1:  be a huge blow to the state's ability to attract and retain...
2025-02-09 23:30:37,826 [INFO] 生成 2:  be a big blow to the American economy.

The president's bud...
2025-02-09 23:30:37,826 [INFO] 生成 3:  have been even worse if it had been available to those who ...
2025-02-09 23:30:37,826 [INFO] Prompt 2:  I feel ...
2025-02-09 23:30:37,826 [INFO] 生成 1:  the need to explain this, but I am not a fan of your "manif...
2025-02-09 23:30:37,826 [INFO] 生成 2: 

It's a bit like having a baby. You have to give it your al...
2025-02-09 23:30:37,826 [INFO] 生成 3:  and that's why I'm here.

The following is a list of things...
2025-02-09 23:30:37,826 [INFO] 干预之后的结果
2025-02-09 23:30:37,826 [INFO] 干预方向neg->pos,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-09 23:30:37,826 [INFO] ** Generating texts with steering... Target **
2025-02-09 23:30:37,826 [INFO] form neg to pos
2025-02-09 23:30:38,706 [INFO] 当前批次共处理2个prompt
2025-02-09 23:30:38,706 [INFO] Prompt 1: But the lack of financial aid would...
2025-02-09 23:30:38,707 [INFO] 生成 1:  education and encourage investment in the budget deficit.

...
2025-02-09 23:30:38,707 [INFO] 生成 2:  education and encourage investment in the economy.

The bud...
2025-02-09 23:30:38,707 [INFO] 生成 3:  education and encourage support to the bottom-income famili...
2025-02-09 23:30:38,707 [INFO] Prompt 2:  I feel ...
2025-02-09 23:30:38,707 [INFO] 生成 1:  education and investment in the budget deficit - deficit sp...
2025-02-09 23:30:38,707 [INFO] 生成 2:  education is set out to encourage the deficit and encourage...
2025-02-09 23:30:38,707 [INFO] 生成 3:  education and investment in the budget deficit drive down s...
2025-02-09 23:30:38,711 [INFO] debug mode,show example, no full dataset eval
2025-02-09 23:30:38,711 [INFO] 训练时间1.2666184902191162
2025-02-09 23:30:38,711 [INFO] Show Hyperparameters: 


2025-02-09 23:30:38,711 [INFO]   task: debate
2025-02-09 23:30:38,711 [INFO]   layer: 6
2025-02-09 23:30:38,711 [INFO]   LLM: gpt2-small
2025-02-09 23:30:38,711 [INFO]   seed: 42
2025-02-09 23:30:38,711 [INFO]   data_size: -1
2025-02-09 23:30:38,711 [INFO]   device: cuda
2025-02-09 23:30:38,711 [INFO]   alpha: 300.0
2025-02-09 23:30:38,711 [INFO]   method: val_mul
2025-02-09 23:30:38,711 [INFO]   topk_mean: 100
2025-02-09 23:30:38,711 [INFO]   topk_cnt: 100
2025-02-09 23:30:38,711 [INFO]   batch_size: 32
2025-02-09 23:30:38,711 [INFO]   source: neg
2025-02-09 23:30:38,711 [INFO]   target: pos
2025-02-09 23:30:38,711 [INFO]   prompt_source: neg
2025-02-09 23:30:38,711 [INFO]   prompt_data_size: -1
2025-02-09 23:30:38,711 [INFO]   mean_type: dif_mean
2025-02-09 23:30:38,712 [INFO]   steer_type: all
2025-02-09 23:30:38,712 [INFO]   output_dir: ./results/stance
2025-02-09 23:30:38,712 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:30:38,712 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/ibm_debate
2025-02-09 23:30:38,712 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-09 23:30:38,712 [INFO]   temperature: 0.9
2025-02-09 23:30:38,712 [INFO]   top_p: 0.3
2025-02-09 23:30:38,712 [INFO]   freq_penalty: 1.0
2025-02-09 23:30:38,712 [INFO]   example_prompt: But the lack of financial aid would| I feel 
2025-02-09 23:30:38,712 [INFO]   debug: 1
2025-02-09 23:30:38,712 [INFO]   save_no_steer: 0
2025-02-09 23:30:38,712 [INFO]   is_norm_delta_matrix: 0
2025-02-09 23:30:38,712 [INFO]   use_cache: 0
2025-02-09 23:30:38,712 [INFO]   repeat_num: 2
2025-02-09 23:30:38,712 [INFO]   gen_batch_size: 16
2025-02-09 23:30:38,712 [INFO]   real_data_size_for_train: 486
2025-02-09 23:31:27,221 [INFO] Logging initialized. Logs will be saved to ./results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/alpha_300.0_from_neg_to_pos_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-09 23:31:27,221 [INFO] Show Hyperparameters: 


2025-02-09 23:31:27,221 [INFO]   task: debate
2025-02-09 23:31:27,221 [INFO]   layer: 6
2025-02-09 23:31:27,221 [INFO]   LLM: gpt2-small
2025-02-09 23:31:27,221 [INFO]   seed: 42
2025-02-09 23:31:27,221 [INFO]   data_size: -1
2025-02-09 23:31:27,221 [INFO]   device: cuda
2025-02-09 23:31:27,221 [INFO]   alpha: 300.0
2025-02-09 23:31:27,221 [INFO]   method: val_mul
2025-02-09 23:31:27,222 [INFO]   topk_mean: 100
2025-02-09 23:31:27,222 [INFO]   topk_cnt: 100
2025-02-09 23:31:27,222 [INFO]   batch_size: 32
2025-02-09 23:31:27,222 [INFO]   source: neg
2025-02-09 23:31:27,222 [INFO]   target: pos
2025-02-09 23:31:27,222 [INFO]   prompt_source: neg
2025-02-09 23:31:27,222 [INFO]   prompt_data_size: -1
2025-02-09 23:31:27,222 [INFO]   mean_type: dif_mean
2025-02-09 23:31:27,222 [INFO]   steer_type: all
2025-02-09 23:31:27,222 [INFO]   output_dir: ./results/stance
2025-02-09 23:31:27,222 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:31:27,222 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/ibm_debate
2025-02-09 23:31:27,222 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-09 23:31:27,222 [INFO]   temperature: 0.9
2025-02-09 23:31:27,222 [INFO]   top_p: 0.3
2025-02-09 23:31:27,222 [INFO]   freq_penalty: 1.0
2025-02-09 23:31:27,222 [INFO]   example_prompt: But the lack of financial aid would| The pass of the AI Act will
2025-02-09 23:31:27,222 [INFO]   debug: 1
2025-02-09 23:31:27,222 [INFO]   save_no_steer: 0
2025-02-09 23:31:27,222 [INFO]   is_norm_delta_matrix: 0
2025-02-09 23:31:27,222 [INFO]   use_cache: 0
2025-02-09 23:31:27,222 [INFO]   repeat_num: 2
2025-02-09 23:31:27,222 [INFO]   gen_batch_size: 16
2025-02-09 23:31:27,223 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-09 23:31:27,223 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:31:27,223 [INFO] debatedebatedebatedebatedebatedebatedebatedebatedebatedebate
2025-02-09 23:31:27,223 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:31:27,387 [INFO] Filtering dataset for support and oppose samples
2025-02-09 23:31:27,391 [INFO] Selected 486 support and 486 oppose samples
2025-02-09 23:31:27,391 [INFO] suppoert==positive opposite==negative
2025-02-09 23:31:27,391 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-09 23:31:27,391 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-09 23:31:32,456 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-09 23:31:32,456 [INFO] 缓存 ./results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-09 23:31:32,461 [INFO] :> Debate :fromnegtopos
2025-02-09 23:31:32,461 [INFO] support
2025-02-09 23:31:32,463 [INFO] Running model with cache to obtain hidden states
2025-02-09 23:31:33,176 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-09 23:31:33,176 [INFO] oppose
2025-02-09 23:31:33,179 [INFO] Running model with cache to obtain hidden states
2025-02-09 23:31:33,731 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-09 23:31:33,740 [INFO] steer_info 已保存到缓存 ./results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-09 23:31:33,749 [INFO] 转向方向 dif_pos-neg_relu
2025-02-09 23:31:33,769 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-09 23:31:33,798 [INFO] delta_matrix: tensor([-0.0284,  0.2685,  0.0067,  0.0359,  0.1836], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-09 23:31:33,798 [INFO] Example prompt: ['But the lack of financial aid would', ' The pass of the AI Act will']
2025-02-09 23:31:33,798 [INFO] Generating texts **without** steering... 
2025-02-09 23:31:33,800 [INFO] 无干预
2025-02-09 23:31:35,046 [INFO] 当前批次共处理2个prompt
2025-02-09 23:31:35,046 [INFO] Prompt 1: But the lack of financial aid would...
2025-02-09 23:31:35,046 [INFO] 生成 1:  have been devastating for many people.

"It's a huge burden...
2025-02-09 23:31:35,046 [INFO] 生成 2:  be a huge blow to the United States' ability to meet its ob...
2025-02-09 23:31:35,046 [INFO] 生成 3:  have made it difficult for him to continue.

"I don't think...
2025-02-09 23:31:35,046 [INFO] Prompt 2:  The pass of the AI Act will...
2025-02-09 23:31:35,046 [INFO] 生成 1:  be implemented in 2018.

The AI Act is a set of laws that w...
2025-02-09 23:31:35,046 [INFO] 生成 2:  be passed by the Lok Sabha on Tuesday.

The bill, which was...
2025-02-09 23:31:35,046 [INFO] 生成 3:  have a huge impact on the Indian economy. It is not just th...
2025-02-09 23:31:35,046 [INFO] 干预之后的结果
2025-02-09 23:31:35,046 [INFO] 干预方向neg->pos,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-09 23:31:35,047 [INFO] ** Generating texts with steering... Target **
2025-02-09 23:31:35,047 [INFO] form neg to pos
2025-02-09 23:31:35,939 [INFO] 当前批次共处理2个prompt
2025-02-09 23:31:35,939 [INFO] Prompt 1: But the lack of financial aid would...
2025-02-09 23:31:35,939 [INFO] 生成 1:  education and encourage support to get into the classroom.
...
2025-02-09 23:31:35,939 [INFO] 生成 2:  education and encourage investment in the economy.

"We wan...
2025-02-09 23:31:35,939 [INFO] 生成 3:  education and encourage investment in the economy.

The min...
2025-02-09 23:31:35,939 [INFO] Prompt 2:  The pass of the AI Act will...
2025-02-09 23:31:35,939 [INFO] 生成 1:  education and encourage investment in the budget deficit.

...
2025-02-09 23:31:35,939 [INFO] 生成 2:  education and encourage investment in the deficit.

Economi...
2025-02-09 23:31:35,939 [INFO] 生成 3:  education and encourage investment in investment.

F4D5E0D3...
2025-02-09 23:31:35,945 [INFO] debug mode,show example, no full dataset eval
2025-02-09 23:31:35,945 [INFO] 训练时间1.2840325832366943
2025-02-09 23:31:35,945 [INFO] Show Hyperparameters: 


2025-02-09 23:31:35,945 [INFO]   task: debate
2025-02-09 23:31:35,945 [INFO]   layer: 6
2025-02-09 23:31:35,945 [INFO]   LLM: gpt2-small
2025-02-09 23:31:35,945 [INFO]   seed: 42
2025-02-09 23:31:35,945 [INFO]   data_size: -1
2025-02-09 23:31:35,945 [INFO]   device: cuda
2025-02-09 23:31:35,945 [INFO]   alpha: 300.0
2025-02-09 23:31:35,945 [INFO]   method: val_mul
2025-02-09 23:31:35,945 [INFO]   topk_mean: 100
2025-02-09 23:31:35,945 [INFO]   topk_cnt: 100
2025-02-09 23:31:35,945 [INFO]   batch_size: 32
2025-02-09 23:31:35,945 [INFO]   source: neg
2025-02-09 23:31:35,945 [INFO]   target: pos
2025-02-09 23:31:35,945 [INFO]   prompt_source: neg
2025-02-09 23:31:35,945 [INFO]   prompt_data_size: -1
2025-02-09 23:31:35,945 [INFO]   mean_type: dif_mean
2025-02-09 23:31:35,945 [INFO]   steer_type: all
2025-02-09 23:31:35,945 [INFO]   output_dir: ./results/stance
2025-02-09 23:31:35,945 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:31:35,945 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/ibm_debate
2025-02-09 23:31:35,945 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-09 23:31:35,945 [INFO]   temperature: 0.9
2025-02-09 23:31:35,945 [INFO]   top_p: 0.3
2025-02-09 23:31:35,946 [INFO]   freq_penalty: 1.0
2025-02-09 23:31:35,946 [INFO]   example_prompt: But the lack of financial aid would| The pass of the AI Act will
2025-02-09 23:31:35,946 [INFO]   debug: 1
2025-02-09 23:31:35,946 [INFO]   save_no_steer: 0
2025-02-09 23:31:35,946 [INFO]   is_norm_delta_matrix: 0
2025-02-09 23:31:35,946 [INFO]   use_cache: 0
2025-02-09 23:31:35,946 [INFO]   repeat_num: 2
2025-02-09 23:31:35,946 [INFO]   gen_batch_size: 16
2025-02-09 23:31:35,946 [INFO]   real_data_size_for_train: 486
