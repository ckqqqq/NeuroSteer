2025-02-09 23:29:52,834 [INFO] Logging initialized. Logs will be saved to ./results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/alpha_100.0_from_neg_to_pos_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-09 23:29:52,834 [INFO] Show Hyperparameters: 


2025-02-09 23:29:52,834 [INFO]   task: debate
2025-02-09 23:29:52,834 [INFO]   layer: 6
2025-02-09 23:29:52,834 [INFO]   LLM: gpt2-small
2025-02-09 23:29:52,834 [INFO]   seed: 42
2025-02-09 23:29:52,834 [INFO]   data_size: -1
2025-02-09 23:29:52,834 [INFO]   device: cuda
2025-02-09 23:29:52,834 [INFO]   alpha: 100.0
2025-02-09 23:29:52,834 [INFO]   method: val_mul
2025-02-09 23:29:52,834 [INFO]   topk_mean: 100
2025-02-09 23:29:52,834 [INFO]   topk_cnt: 100
2025-02-09 23:29:52,834 [INFO]   batch_size: 32
2025-02-09 23:29:52,834 [INFO]   source: neg
2025-02-09 23:29:52,834 [INFO]   target: pos
2025-02-09 23:29:52,834 [INFO]   prompt_source: neg
2025-02-09 23:29:52,834 [INFO]   prompt_data_size: -1
2025-02-09 23:29:52,834 [INFO]   mean_type: dif_mean
2025-02-09 23:29:52,834 [INFO]   steer_type: all
2025-02-09 23:29:52,834 [INFO]   output_dir: ./results/stance
2025-02-09 23:29:52,834 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:29:52,834 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/ibm_debate
2025-02-09 23:29:52,834 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-09 23:29:52,835 [INFO]   temperature: 0.9
2025-02-09 23:29:52,835 [INFO]   top_p: 0.3
2025-02-09 23:29:52,835 [INFO]   freq_penalty: 1.0
2025-02-09 23:29:52,835 [INFO]   example_prompt: But the lack of financial aid would| I feel 
2025-02-09 23:29:52,835 [INFO]   debug: 1
2025-02-09 23:29:52,835 [INFO]   save_no_steer: 0
2025-02-09 23:29:52,835 [INFO]   is_norm_delta_matrix: 0
2025-02-09 23:29:52,835 [INFO]   use_cache: 0
2025-02-09 23:29:52,835 [INFO]   repeat_num: 2
2025-02-09 23:29:52,835 [INFO]   gen_batch_size: 16
2025-02-09 23:29:52,835 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-09 23:29:52,835 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:29:52,835 [INFO] debatedebatedebatedebatedebatedebatedebatedebatedebatedebate
2025-02-09 23:29:52,835 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:29:53,001 [INFO] Filtering dataset for support and oppose samples
2025-02-09 23:29:53,004 [INFO] Selected 486 support and 486 oppose samples
2025-02-09 23:29:53,005 [INFO] suppoert==positive opposite==negative
2025-02-09 23:29:53,005 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-09 23:29:53,005 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-09 23:29:57,876 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-09 23:29:57,876 [INFO] 缓存 ./results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-09 23:29:57,881 [INFO] :> Debate :fromnegtopos
2025-02-09 23:29:57,881 [INFO] support
2025-02-09 23:29:57,883 [INFO] Running model with cache to obtain hidden states
2025-02-09 23:29:58,581 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-09 23:29:58,581 [INFO] oppose
2025-02-09 23:29:58,584 [INFO] Running model with cache to obtain hidden states
2025-02-09 23:29:59,136 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-09 23:29:59,138 [INFO] steer_info 已保存到缓存 ./results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-09 23:29:59,147 [INFO] 转向方向 dif_pos-neg_relu
2025-02-09 23:29:59,168 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-09 23:29:59,195 [INFO] delta_matrix: tensor([-0.0284,  0.2685,  0.0067,  0.0359,  0.1836], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-09 23:29:59,195 [INFO] Example prompt: ['But the lack of financial aid would', ' I feel ']
2025-02-09 23:29:59,195 [INFO] Generating texts **without** steering... 
2025-02-09 23:29:59,197 [INFO] 无干预
2025-02-09 23:30:00,586 [INFO] 当前批次共处理2个prompt
2025-02-09 23:30:00,587 [INFO] Prompt 1: But the lack of financial aid would...
2025-02-09 23:30:00,587 [INFO] 生成 1:  have made it difficult for a man to buy a home in Los Angel...
2025-02-09 23:30:00,587 [INFO] 生成 2:  be even more significant if it meant that some people would...
2025-02-09 23:30:00,587 [INFO] 生成 3:  be a major blow to President Trump's efforts to build a wal...
2025-02-09 23:30:00,587 [INFO] Prompt 2:  I feel ...
2025-02-09 23:30:00,587 [INFO] 生成 1: 

I feel the

I feel the


I felt it, I felt it, I felt it, ...
2025-02-09 23:30:00,587 [INFO] 生成 2:  a bit like a connoisseur of "good food" and "good wine". I'...
2025-02-09 23:30:00,587 [INFO] 生成 3: 

I feel like I'm going to be stuck in a room with a bunch o...
2025-02-09 23:30:00,587 [INFO] 干预之后的结果
2025-02-09 23:30:00,587 [INFO] 干预方向neg->pos,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-09 23:30:00,587 [INFO] ** Generating texts with steering... Target **
2025-02-09 23:30:00,587 [INFO] form neg to pos
2025-02-09 23:30:01,427 [INFO] 当前批次共处理2个prompt
2025-02-09 23:30:01,427 [INFO] Prompt 1: But the lack of financial aid would...
2025-02-09 23:30:01,427 [INFO] 生成 1:  economic growth and job creation?

The government supports ...
2025-02-09 23:30:01,427 [INFO] 生成 2:  economic growth and job creation?

"The number of people wo...
2025-02-09 23:30:01,427 [INFO] 生成 3:  economic growth and support the economy.

"The fiscal stimu...
2025-02-09 23:30:01,427 [INFO] Prompt 2:  I feel ...
2025-02-09 23:30:01,427 [INFO] 生成 1:  and we need to keep our voices heard.

• A focus on educati...
2025-02-09 23:30:01,427 [INFO] 生成 2:  and the future of the United States.

The United States is ...
2025-02-09 23:30:01,427 [INFO] 生成 3: 

The federal government is committed to supporting the grow...
2025-02-09 23:30:01,431 [INFO] debug mode,show example, no full dataset eval
2025-02-09 23:30:01,431 [INFO] 训练时间1.261610507965088
2025-02-09 23:30:01,431 [INFO] Show Hyperparameters: 


2025-02-09 23:30:01,431 [INFO]   task: debate
2025-02-09 23:30:01,431 [INFO]   layer: 6
2025-02-09 23:30:01,431 [INFO]   LLM: gpt2-small
2025-02-09 23:30:01,431 [INFO]   seed: 42
2025-02-09 23:30:01,431 [INFO]   data_size: -1
2025-02-09 23:30:01,431 [INFO]   device: cuda
2025-02-09 23:30:01,432 [INFO]   alpha: 100.0
2025-02-09 23:30:01,432 [INFO]   method: val_mul
2025-02-09 23:30:01,432 [INFO]   topk_mean: 100
2025-02-09 23:30:01,432 [INFO]   topk_cnt: 100
2025-02-09 23:30:01,432 [INFO]   batch_size: 32
2025-02-09 23:30:01,432 [INFO]   source: neg
2025-02-09 23:30:01,432 [INFO]   target: pos
2025-02-09 23:30:01,432 [INFO]   prompt_source: neg
2025-02-09 23:30:01,432 [INFO]   prompt_data_size: -1
2025-02-09 23:30:01,432 [INFO]   mean_type: dif_mean
2025-02-09 23:30:01,432 [INFO]   steer_type: all
2025-02-09 23:30:01,432 [INFO]   output_dir: ./results/stance
2025-02-09 23:30:01,432 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:30:01,432 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/ibm_debate
2025-02-09 23:30:01,432 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-09 23:30:01,432 [INFO]   temperature: 0.9
2025-02-09 23:30:01,432 [INFO]   top_p: 0.3
2025-02-09 23:30:01,432 [INFO]   freq_penalty: 1.0
2025-02-09 23:30:01,432 [INFO]   example_prompt: But the lack of financial aid would| I feel 
2025-02-09 23:30:01,432 [INFO]   debug: 1
2025-02-09 23:30:01,432 [INFO]   save_no_steer: 0
2025-02-09 23:30:01,432 [INFO]   is_norm_delta_matrix: 0
2025-02-09 23:30:01,432 [INFO]   use_cache: 0
2025-02-09 23:30:01,432 [INFO]   repeat_num: 2
2025-02-09 23:30:01,432 [INFO]   gen_batch_size: 16
2025-02-09 23:30:01,432 [INFO]   real_data_size_for_train: 486
