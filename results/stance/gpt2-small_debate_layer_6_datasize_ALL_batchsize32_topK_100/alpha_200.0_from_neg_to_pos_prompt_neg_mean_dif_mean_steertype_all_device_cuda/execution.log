2025-02-09 23:32:02,733 [INFO] Logging initialized. Logs will be saved to ./results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/alpha_200.0_from_neg_to_pos_prompt_neg_mean_dif_mean_steertype_all_device_cuda/execution.log
2025-02-09 23:32:02,733 [INFO] Show Hyperparameters: 


2025-02-09 23:32:02,733 [INFO]   task: debate
2025-02-09 23:32:02,733 [INFO]   layer: 6
2025-02-09 23:32:02,733 [INFO]   LLM: gpt2-small
2025-02-09 23:32:02,733 [INFO]   seed: 42
2025-02-09 23:32:02,733 [INFO]   data_size: -1
2025-02-09 23:32:02,733 [INFO]   device: cuda
2025-02-09 23:32:02,733 [INFO]   alpha: 200.0
2025-02-09 23:32:02,733 [INFO]   method: val_mul
2025-02-09 23:32:02,733 [INFO]   topk_mean: 100
2025-02-09 23:32:02,733 [INFO]   topk_cnt: 100
2025-02-09 23:32:02,733 [INFO]   batch_size: 32
2025-02-09 23:32:02,733 [INFO]   source: neg
2025-02-09 23:32:02,733 [INFO]   target: pos
2025-02-09 23:32:02,733 [INFO]   prompt_source: neg
2025-02-09 23:32:02,733 [INFO]   prompt_data_size: -1
2025-02-09 23:32:02,733 [INFO]   mean_type: dif_mean
2025-02-09 23:32:02,733 [INFO]   steer_type: all
2025-02-09 23:32:02,733 [INFO]   output_dir: ./results/stance
2025-02-09 23:32:02,733 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:32:02,733 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/ibm_debate
2025-02-09 23:32:02,733 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-09 23:32:02,733 [INFO]   temperature: 0.9
2025-02-09 23:32:02,733 [INFO]   top_p: 0.3
2025-02-09 23:32:02,733 [INFO]   freq_penalty: 1.0
2025-02-09 23:32:02,733 [INFO]   example_prompt: But the lack of financial aid would| The pass of the AI Act will
2025-02-09 23:32:02,734 [INFO]   debug: 1
2025-02-09 23:32:02,734 [INFO]   save_no_steer: 0
2025-02-09 23:32:02,734 [INFO]   is_norm_delta_matrix: 0
2025-02-09 23:32:02,734 [INFO]   use_cache: 0
2025-02-09 23:32:02,734 [INFO]   repeat_num: 2
2025-02-09 23:32:02,734 [INFO]   gen_batch_size: 16
2025-02-09 23:32:02,734 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-02-09 23:32:02,734 [INFO] dataset path /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:32:02,734 [INFO] debatedebatedebatedebatedebatedebatedebatedebatedebatedebate
2025-02-09 23:32:02,734 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:32:02,897 [INFO] Filtering dataset for support and oppose samples
2025-02-09 23:32:02,900 [INFO] Selected 486 support and 486 oppose samples
2025-02-09 23:32:02,900 [INFO] suppoert==positive opposite==negative
2025-02-09 23:32:02,900 [INFO] Loading Model Loading SAE for layer 6 gpt2-small
2025-02-09 23:32:02,900 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb
2025-02-09 23:32:07,438 [INFO] model architecture for gpt2-small HookedTransformer(
  (embed): Embed()
  (hook_embed): HookPoint()
  (pos_embed): PosEmbed()
  (hook_pos_embed): HookPoint()
  (blocks): ModuleList(
    (0-11): 12 x TransformerBlock(
      (ln1): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (ln2): LayerNormPre(
        (hook_scale): HookPoint()
        (hook_normalized): HookPoint()
      )
      (attn): Attention(
        (hook_k): HookPoint()
        (hook_q): HookPoint()
        (hook_v): HookPoint()
        (hook_z): HookPoint()
        (hook_attn_scores): HookPoint()
        (hook_pattern): HookPoint()
        (hook_result): HookPoint()
      )
      (mlp): MLP(
        (hook_pre): HookPoint()
        (hook_post): HookPoint()
      )
      (hook_attn_in): HookPoint()
      (hook_q_input): HookPoint()
      (hook_k_input): HookPoint()
      (hook_v_input): HookPoint()
      (hook_mlp_in): HookPoint()
      (hook_attn_out): HookPoint()
      (hook_mlp_out): HookPoint()
      (hook_resid_pre): HookPoint()
      (hook_resid_mid): HookPoint()
      (hook_resid_post): HookPoint()
    )
  )
  (ln_final): LayerNormPre(
    (hook_scale): HookPoint()
    (hook_normalized): HookPoint()
  )
  (unembed): Unembed()
) GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	50256: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
}
)
2025-02-09 23:32:07,439 [INFO] 缓存 ./results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 不存在，缓存 steer_info
2025-02-09 23:32:07,443 [INFO] :> Debate :fromnegtopos
2025-02-09 23:32:07,443 [INFO] support
2025-02-09 23:32:07,445 [INFO] Running model with cache to obtain hidden states
2025-02-09 23:32:08,148 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-09 23:32:08,149 [INFO] oppose
2025-02-09 23:32:08,151 [INFO] Running model with cache to obtain hidden states
2025-02-09 23:32:08,737 [INFO] Total non-zero element shape: torch.Size([24576])
2025-02-09 23:32:08,740 [INFO] steer_info 已保存到缓存 ./results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl
2025-02-09 23:32:08,749 [INFO] 转向方向 dif_pos-neg_relu
2025-02-09 23:32:08,770 [INFO] sae cfg.hook_name 挂载名称: blocks.6.hook_resid_pre
2025-02-09 23:32:08,797 [INFO] delta_matrix: tensor([-0.0284,  0.2685,  0.0067,  0.0359,  0.1836], device='cuda:0',
       grad_fn=<SliceBackward0>)
2025-02-09 23:32:08,797 [INFO] Example prompt: ['But the lack of financial aid would', ' The pass of the AI Act will']
2025-02-09 23:32:08,797 [INFO] Generating texts **without** steering... 
2025-02-09 23:32:08,799 [INFO] 无干预
2025-02-09 23:32:10,092 [INFO] 当前批次共处理2个prompt
2025-02-09 23:32:10,093 [INFO] Prompt 1: But the lack of financial aid would...
2025-02-09 23:32:10,093 [INFO] 生成 1:  mean that those who have earned it could not be counted on ...
2025-02-09 23:32:10,093 [INFO] 生成 2:  have been a huge blow to the US economy.

The National Inst...
2025-02-09 23:32:10,093 [INFO] 生成 3:  have been even worse if it had been offered to the students...
2025-02-09 23:32:10,093 [INFO] Prompt 2:  The pass of the AI Act will...
2025-02-09 23:32:10,093 [INFO] 生成 1:  be implemented in the coming weeks.

The AI Act is a bill t...
2025-02-09 23:32:10,093 [INFO] 生成 2:  have a significant impact on the ability of governments to ...
2025-02-09 23:32:10,093 [INFO] 生成 3:  not be allowed to proceed until a decision is taken by the ...
2025-02-09 23:32:10,093 [INFO] 干预之后的结果
2025-02-09 23:32:10,093 [INFO] 干预方向neg->pos,礼貌任务下，neg=impolite，情感任务下 pos=积极情感
2025-02-09 23:32:10,093 [INFO] ** Generating texts with steering... Target **
2025-02-09 23:32:10,093 [INFO] form neg to pos
2025-02-09 23:32:11,004 [INFO] 当前批次共处理2个prompt
2025-02-09 23:32:11,004 [INFO] Prompt 1: But the lack of financial aid would...
2025-02-09 23:32:11,004 [INFO] 生成 1:  education and encourage participation in the private sector...
2025-02-09 23:32:11,004 [INFO] 生成 2:  education and encourage investment in the private sector.

...
2025-02-09 23:32:11,004 [INFO] 生成 3:  education and encourage investment in the economy.

"The go...
2025-02-09 23:32:11,004 [INFO] Prompt 2:  The pass of the AI Act will...
2025-02-09 23:32:11,004 [INFO] 生成 1:  education and encourage support to promote a number of sect...
2025-02-09 23:32:11,004 [INFO] 生成 2:  education and encourage investment in the private sector.

...
2025-02-09 23:32:11,004 [INFO] 生成 3:  education and encourage investment in the private sector.

...
2025-02-09 23:32:11,009 [INFO] debug mode,show example, no full dataset eval
2025-02-09 23:32:11,009 [INFO] 训练时间1.3010492324829102
2025-02-09 23:32:11,010 [INFO] Show Hyperparameters: 


2025-02-09 23:32:11,010 [INFO]   task: debate
2025-02-09 23:32:11,010 [INFO]   layer: 6
2025-02-09 23:32:11,010 [INFO]   LLM: gpt2-small
2025-02-09 23:32:11,010 [INFO]   seed: 42
2025-02-09 23:32:11,010 [INFO]   data_size: -1
2025-02-09 23:32:11,010 [INFO]   device: cuda
2025-02-09 23:32:11,010 [INFO]   alpha: 200.0
2025-02-09 23:32:11,010 [INFO]   method: val_mul
2025-02-09 23:32:11,010 [INFO]   topk_mean: 100
2025-02-09 23:32:11,010 [INFO]   topk_cnt: 100
2025-02-09 23:32:11,010 [INFO]   batch_size: 32
2025-02-09 23:32:11,010 [INFO]   source: neg
2025-02-09 23:32:11,010 [INFO]   target: pos
2025-02-09 23:32:11,010 [INFO]   prompt_source: neg
2025-02-09 23:32:11,010 [INFO]   prompt_data_size: -1
2025-02-09 23:32:11,010 [INFO]   mean_type: dif_mean
2025-02-09 23:32:11,010 [INFO]   steer_type: all
2025-02-09 23:32:11,010 [INFO]   output_dir: ./results/stance
2025-02-09 23:32:11,010 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences
2025-02-09 23:32:11,010 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/ibm_debate
2025-02-09 23:32:11,010 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-02-09 23:32:11,010 [INFO]   temperature: 0.9
2025-02-09 23:32:11,010 [INFO]   top_p: 0.3
2025-02-09 23:32:11,010 [INFO]   freq_penalty: 1.0
2025-02-09 23:32:11,010 [INFO]   example_prompt: But the lack of financial aid would| The pass of the AI Act will
2025-02-09 23:32:11,010 [INFO]   debug: 1
2025-02-09 23:32:11,010 [INFO]   save_no_steer: 0
2025-02-09 23:32:11,010 [INFO]   is_norm_delta_matrix: 0
2025-02-09 23:32:11,010 [INFO]   use_cache: 0
2025-02-09 23:32:11,010 [INFO]   repeat_num: 2
2025-02-09 23:32:11,010 [INFO]   gen_batch_size: 16
2025-02-09 23:32:11,010 [INFO]   real_data_size_for_train: 486
