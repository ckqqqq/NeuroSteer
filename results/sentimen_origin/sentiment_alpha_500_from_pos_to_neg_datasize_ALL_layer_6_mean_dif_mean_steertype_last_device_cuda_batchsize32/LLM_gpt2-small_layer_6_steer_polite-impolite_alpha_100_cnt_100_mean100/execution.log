2025-01-10 23:20:51,299 [INFO] Logging initialized. Logs will be saved to ./results/LLM_gpt2-small_layer_6_steer_polite-impolite_alpha_100_cnt_100_mean100/execution.log
2025-01-10 23:20:51,302 [INFO] Hyperparameters:
2025-01-10 23:20:51,305 [INFO]   layer: 6
2025-01-10 23:20:51,307 [INFO]   LLM: gpt2-small
2025-01-10 23:20:51,308 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-10 23:20:51,310 [INFO]   output_dir: ./results
2025-01-10 23:20:51,312 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-10 23:20:51,313 [INFO]   seed: 42
2025-01-10 23:20:51,315 [INFO]   data_size: 1000
2025-01-10 23:20:51,316 [INFO]   device: cpu
2025-01-10 23:20:51,318 [INFO]   alpha: 100
2025-01-10 23:20:51,319 [INFO]   steer: polite-impolite
2025-01-10 23:20:51,320 [INFO]   method: val_mul
2025-01-10 23:20:51,321 [INFO]   topk_mean: 100
2025-01-10 23:20:51,323 [INFO]   topk_cnt: 100
2025-01-10 23:20:51,324 [INFO]   batch_size: 32
2025-01-10 23:21:09,292 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-10 23:44:19,265 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-01-10 23:44:19,269 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-10 23:44:19,418 [INFO] Filtering dataset for impolite, polite, and neutral samples
2025-01-10 23:44:19,975 [INFO] Selected 1000 negative, 1000 positive, and 1000 neutral samples
2025-01-10 23:44:48,326 [INFO] non cache: ./results/LLM_gpt2-small_layer_6_steer_polite-impolite_alpha_100_cnt_100_mean100/hyperparameters.json
2025-01-10 23:44:51,049 [INFO] Hyperparameters:
2025-01-10 23:44:51,051 [INFO]   layer: 6
2025-01-10 23:44:51,071 [INFO]   LLM: gpt2-small
2025-01-10 23:44:51,074 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-10 23:44:51,075 [INFO]   output_dir: ./results
2025-01-10 23:44:51,076 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-10 23:44:51,078 [INFO]   seed: 42
2025-01-10 23:44:51,080 [INFO]   data_size: 1000
2025-01-10 23:44:51,081 [INFO]   device: cpu
2025-01-10 23:44:51,083 [INFO]   alpha: 100
2025-01-10 23:44:51,085 [INFO]   steer: polite-impolite
2025-01-10 23:44:51,085 [INFO]   method: val_mul
2025-01-10 23:44:51,087 [INFO]   topk_mean: 100
2025-01-10 23:44:51,088 [INFO]   topk_cnt: 100
2025-01-10 23:44:51,088 [INFO]   batch_size: 32
2025-01-10 23:44:51,091 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-10 23:44:51,092 [INFO] Loading model: gpt2-small
2025-01-10 23:44:52,896 [INFO] Loading SAE for layer 6
2025-01-10 23:45:16,971 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-10 23:45:17,001 [INFO] Filtering dataset for impolite, polite, and neutral samples
2025-01-10 23:45:17,033 [INFO] Selected 1000 negative, 1000 positive, and 1000 neutral samples
2025-01-10 23:48:00,601 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-01-10 23:48:00,604 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-10 23:48:00,765 [INFO] Filtering dataset for impolite, polite, and neutral samples
2025-01-10 23:48:00,791 [INFO] Selected 1000 negative, 1000 positive, and 1000 neutral samples
2025-01-10 23:54:05,706 [INFO] Running model with cache to obtain hidden states
2025-01-10 23:54:06,187 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-10 23:54:06,187 [INFO] Encoding hidden states for batch 1
2025-01-10 23:54:07,422 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:54:07,424 [INFO] Encoding hidden states for batch 2
2025-01-10 23:54:07,914 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-10 23:54:07,916 [INFO] Encoding hidden states for batch 3
2025-01-10 23:54:08,270 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-10 23:54:08,272 [INFO] Encoding hidden states for batch 4
2025-01-10 23:54:08,687 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-10 23:54:08,689 [INFO] Encoding hidden states for batch 5
2025-01-10 23:54:09,271 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-10 23:54:09,272 [INFO] Encoding hidden states for batch 6
2025-01-10 23:54:09,714 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-10 23:54:09,716 [INFO] Encoding hidden states for batch 7
2025-01-10 23:54:10,137 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:54:10,138 [INFO] Encoding hidden states for batch 8
2025-01-10 23:54:10,569 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-10 23:54:10,571 [INFO] Encoding hidden states for batch 9
2025-01-10 23:54:10,936 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-10 23:54:10,937 [INFO] Encoding hidden states for batch 10
2025-01-10 23:54:11,294 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-10 23:54:11,295 [INFO] Encoding hidden states for batch 11
2025-01-10 23:54:12,232 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-10 23:54:12,233 [INFO] Encoding hidden states for batch 12
2025-01-10 23:54:12,807 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-10 23:54:12,810 [INFO] Encoding hidden states for batch 13
2025-01-10 23:54:13,296 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-10 23:54:13,298 [INFO] Encoding hidden states for batch 14
2025-01-10 23:54:13,708 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-10 23:54:13,710 [INFO] Encoding hidden states for batch 15
2025-01-10 23:54:14,106 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:54:14,107 [INFO] Encoding hidden states for batch 16
2025-01-10 23:54:14,516 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-10 23:54:14,517 [INFO] Encoding hidden states for batch 17
2025-01-10 23:54:15,305 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-10 23:54:15,307 [INFO] Encoding hidden states for batch 18
2025-01-10 23:54:16,160 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-10 23:54:16,161 [INFO] Encoding hidden states for batch 19
2025-01-10 23:54:16,746 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-10 23:54:16,748 [INFO] Encoding hidden states for batch 20
2025-01-10 23:54:17,177 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-10 23:54:17,178 [INFO] Encoding hidden states for batch 21
2025-01-10 23:54:17,577 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-10 23:54:17,579 [INFO] Encoding hidden states for batch 22
2025-01-10 23:54:18,054 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:54:18,056 [INFO] Encoding hidden states for batch 23
2025-01-10 23:54:18,508 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-10 23:54:18,510 [INFO] Encoding hidden states for batch 24
2025-01-10 23:54:18,853 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-10 23:54:18,855 [INFO] Encoding hidden states for batch 25
2025-01-10 23:54:19,258 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-10 23:54:19,260 [INFO] Encoding hidden states for batch 26
2025-01-10 23:54:20,020 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-10 23:54:20,021 [INFO] Encoding hidden states for batch 27
2025-01-10 23:54:20,579 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-10 23:54:20,581 [INFO] Encoding hidden states for batch 28
2025-01-10 23:54:21,040 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-10 23:54:21,042 [INFO] Encoding hidden states for batch 29
2025-01-10 23:54:21,408 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-10 23:54:21,409 [INFO] Encoding hidden states for batch 30
2025-01-10 23:54:21,858 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-10 23:54:21,860 [INFO] Encoding hidden states for batch 31
2025-01-10 23:54:22,059 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-10 23:54:22,061 [INFO] Encoding hidden states for batch 32
2025-01-10 23:54:22,071 [INFO] Total batches processed: 32
2025-01-10 23:54:22,075 [INFO] 最大长度:141
2025-01-10 23:54:23,101 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-10 23:54:23,102 [INFO] Computing non-zero element counts
2025-01-10 23:54:25,482 [INFO] Computing sum of non-zero elements
2025-01-10 23:54:26,749 [INFO] Computing mean of non-zero elements
2025-01-10 23:54:26,751 [INFO] Selecting top-k indices based on nz_mean
2025-01-10 23:54:26,752 [INFO] Top 100 nz_mean values selected.
2025-01-10 23:54:26,753 [INFO] Selecting top-k indices based on act_cnt
2025-01-10 23:54:26,754 [INFO] Top 100 act_cnt values selected.
2025-01-10 23:56:59,984 [INFO] Running model with cache to obtain hidden states
2025-01-10 23:57:00,229 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-10 23:57:00,230 [INFO] Encoding hidden states for batch 1
2025-01-10 23:57:00,600 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:57:00,601 [INFO] Encoding hidden states for batch 2
2025-01-10 23:57:00,994 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-10 23:57:00,996 [INFO] Encoding hidden states for batch 3
2025-01-10 23:57:01,343 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-10 23:57:01,345 [INFO] Encoding hidden states for batch 4
2025-01-10 23:57:01,790 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-10 23:57:01,792 [INFO] Encoding hidden states for batch 5
2025-01-10 23:57:02,618 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-10 23:57:02,620 [INFO] Encoding hidden states for batch 6
2025-01-10 23:57:03,398 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-10 23:57:03,399 [INFO] Encoding hidden states for batch 7
2025-01-10 23:57:03,808 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:57:03,809 [INFO] Encoding hidden states for batch 8
2025-01-10 23:57:04,250 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-10 23:57:04,251 [INFO] Encoding hidden states for batch 9
2025-01-10 23:57:04,604 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-10 23:57:04,605 [INFO] Encoding hidden states for batch 10
2025-01-10 23:57:04,987 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-10 23:57:04,989 [INFO] Encoding hidden states for batch 11
2025-01-10 23:57:05,733 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-10 23:57:05,734 [INFO] Encoding hidden states for batch 12
2025-01-10 23:57:06,228 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-10 23:57:06,230 [INFO] Encoding hidden states for batch 13
2025-01-10 23:57:06,642 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-10 23:57:06,644 [INFO] Encoding hidden states for batch 14
2025-01-10 23:57:07,112 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-10 23:57:07,113 [INFO] Encoding hidden states for batch 15
2025-01-10 23:57:07,542 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:57:07,543 [INFO] Encoding hidden states for batch 16
2025-01-10 23:57:07,929 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-10 23:57:07,930 [INFO] Encoding hidden states for batch 17
2025-01-10 23:57:08,731 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-10 23:57:08,733 [INFO] Encoding hidden states for batch 18
2025-01-10 23:57:09,555 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-10 23:57:09,557 [INFO] Encoding hidden states for batch 19
2025-01-10 23:57:10,241 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-10 23:57:10,243 [INFO] Encoding hidden states for batch 20
2025-01-10 23:57:10,703 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-10 23:57:10,704 [INFO] Encoding hidden states for batch 21
2025-01-10 23:57:11,109 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-10 23:57:11,110 [INFO] Encoding hidden states for batch 22
2025-01-10 23:57:11,563 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:57:11,565 [INFO] Encoding hidden states for batch 23
2025-01-10 23:57:12,013 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-10 23:57:12,015 [INFO] Encoding hidden states for batch 24
2025-01-10 23:57:12,392 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-10 23:57:12,394 [INFO] Encoding hidden states for batch 25
2025-01-10 23:57:12,888 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-10 23:57:12,890 [INFO] Encoding hidden states for batch 26
2025-01-10 23:57:13,706 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-10 23:57:13,708 [INFO] Encoding hidden states for batch 27
2025-01-10 23:57:14,278 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-10 23:57:14,280 [INFO] Encoding hidden states for batch 28
2025-01-10 23:57:14,738 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-10 23:57:14,739 [INFO] Encoding hidden states for batch 29
2025-01-10 23:57:15,083 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-10 23:57:15,085 [INFO] Encoding hidden states for batch 30
2025-01-10 23:57:15,484 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-10 23:57:15,486 [INFO] Encoding hidden states for batch 31
2025-01-10 23:57:15,702 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-10 23:57:15,703 [INFO] Encoding hidden states for batch 32
2025-01-10 23:57:15,712 [INFO] Total batches processed: 32
2025-01-10 23:57:15,715 [INFO] 最大长度:141
2025-01-10 23:57:16,684 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-10 23:57:16,685 [INFO] Computing non-zero element counts
2025-01-10 23:57:19,079 [INFO] Computing sum of non-zero elements
2025-01-10 23:57:20,350 [INFO] Computing mean of non-zero elements
2025-01-10 23:57:20,353 [INFO] Selecting top-k indices based on nz_mean
2025-01-10 23:57:20,354 [INFO] Top 100 nz_mean values selected.
2025-01-10 23:57:20,355 [INFO] Selecting top-k indices based on act_cnt
2025-01-10 23:57:20,356 [INFO] Top 100 act_cnt values selected.
2025-01-10 23:57:30,074 [INFO] Running model with cache to obtain hidden states
2025-01-10 23:57:30,311 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-10 23:57:30,311 [INFO] Encoding hidden states for batch 1
2025-01-10 23:57:30,671 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:57:30,672 [INFO] Encoding hidden states for batch 2
2025-01-10 23:57:31,033 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-10 23:57:31,034 [INFO] Encoding hidden states for batch 3
2025-01-10 23:57:31,380 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-10 23:57:31,382 [INFO] Encoding hidden states for batch 4
2025-01-10 23:57:31,778 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-10 23:57:31,779 [INFO] Encoding hidden states for batch 5
2025-01-10 23:57:32,315 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-10 23:57:32,317 [INFO] Encoding hidden states for batch 6
2025-01-10 23:57:32,733 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-10 23:57:32,734 [INFO] Encoding hidden states for batch 7
2025-01-10 23:57:33,138 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:57:33,140 [INFO] Encoding hidden states for batch 8
2025-01-10 23:57:33,551 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-10 23:57:33,552 [INFO] Encoding hidden states for batch 9
2025-01-10 23:57:33,908 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-10 23:57:33,910 [INFO] Encoding hidden states for batch 10
2025-01-10 23:57:34,286 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-10 23:57:34,288 [INFO] Encoding hidden states for batch 11
2025-01-10 23:57:35,043 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-10 23:57:35,045 [INFO] Encoding hidden states for batch 12
2025-01-10 23:57:35,552 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-10 23:57:35,554 [INFO] Encoding hidden states for batch 13
2025-01-10 23:57:35,970 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-10 23:57:35,972 [INFO] Encoding hidden states for batch 14
2025-01-10 23:57:36,353 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-10 23:57:36,355 [INFO] Encoding hidden states for batch 15
2025-01-10 23:57:36,784 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:57:36,786 [INFO] Encoding hidden states for batch 16
2025-01-10 23:57:37,175 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-10 23:57:37,177 [INFO] Encoding hidden states for batch 17
2025-01-10 23:57:38,003 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-10 23:57:38,005 [INFO] Encoding hidden states for batch 18
2025-01-10 23:57:38,775 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-10 23:57:38,776 [INFO] Encoding hidden states for batch 19
2025-01-10 23:57:39,464 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-10 23:57:39,465 [INFO] Encoding hidden states for batch 20
2025-01-10 23:57:39,936 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-10 23:57:39,937 [INFO] Encoding hidden states for batch 21
2025-01-10 23:57:40,508 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-10 23:57:40,509 [INFO] Encoding hidden states for batch 22
2025-01-10 23:57:40,949 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:57:40,951 [INFO] Encoding hidden states for batch 23
2025-01-10 23:57:41,377 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-10 23:57:41,378 [INFO] Encoding hidden states for batch 24
2025-01-10 23:57:41,745 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-10 23:57:41,747 [INFO] Encoding hidden states for batch 25
2025-01-10 23:57:42,263 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-10 23:57:42,264 [INFO] Encoding hidden states for batch 26
2025-01-10 23:57:43,146 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-10 23:57:43,147 [INFO] Encoding hidden states for batch 27
2025-01-10 23:57:43,827 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-10 23:57:43,829 [INFO] Encoding hidden states for batch 28
2025-01-10 23:57:44,300 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-10 23:57:44,301 [INFO] Encoding hidden states for batch 29
2025-01-10 23:57:44,659 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-10 23:57:44,661 [INFO] Encoding hidden states for batch 30
2025-01-10 23:57:45,041 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-10 23:57:45,042 [INFO] Encoding hidden states for batch 31
2025-01-10 23:57:45,268 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-10 23:57:45,270 [INFO] Encoding hidden states for batch 32
2025-01-10 23:57:45,280 [INFO] Total batches processed: 32
2025-01-10 23:57:45,282 [INFO] 最大长度:141
2025-01-10 23:57:46,268 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-10 23:57:46,269 [INFO] Computing non-zero element counts
2025-01-10 23:57:48,738 [INFO] Computing sum of non-zero elements
2025-01-10 23:57:50,039 [INFO] Computing mean of non-zero elements
2025-01-10 23:57:50,041 [INFO] Selecting top-k indices based on nz_mean
2025-01-10 23:57:50,042 [INFO] Top 100 nz_mean values selected.
2025-01-10 23:57:50,043 [INFO] Selecting top-k indices based on act_cnt
2025-01-10 23:57:50,044 [INFO] Top 100 act_cnt values selected.
2025-01-10 23:57:51,192 [INFO] Running model with cache to obtain hidden states
2025-01-10 23:57:51,410 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-10 23:57:51,411 [INFO] Encoding hidden states for batch 1
2025-01-10 23:57:51,774 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:57:51,776 [INFO] Encoding hidden states for batch 2
2025-01-10 23:57:52,160 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-10 23:57:52,161 [INFO] Encoding hidden states for batch 3
2025-01-10 23:57:52,518 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-10 23:57:52,520 [INFO] Encoding hidden states for batch 4
2025-01-10 23:57:52,916 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-10 23:57:52,917 [INFO] Encoding hidden states for batch 5
2025-01-10 23:57:53,506 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-10 23:57:53,508 [INFO] Encoding hidden states for batch 6
2025-01-10 23:57:53,939 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-10 23:57:53,941 [INFO] Encoding hidden states for batch 7
2025-01-10 23:57:54,360 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:57:54,362 [INFO] Encoding hidden states for batch 8
2025-01-10 23:57:54,764 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-10 23:57:54,766 [INFO] Encoding hidden states for batch 9
2025-01-10 23:57:55,118 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-10 23:57:55,120 [INFO] Encoding hidden states for batch 10
2025-01-10 23:57:55,491 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-10 23:57:55,492 [INFO] Encoding hidden states for batch 11
2025-01-10 23:57:56,310 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-10 23:57:56,311 [INFO] Encoding hidden states for batch 12
2025-01-10 23:57:56,847 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-10 23:57:56,848 [INFO] Encoding hidden states for batch 13
2025-01-10 23:57:57,287 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-10 23:57:57,289 [INFO] Encoding hidden states for batch 14
2025-01-10 23:57:57,687 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-10 23:57:57,688 [INFO] Encoding hidden states for batch 15
2025-01-10 23:57:58,090 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:57:58,092 [INFO] Encoding hidden states for batch 16
2025-01-10 23:57:58,471 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-10 23:57:58,472 [INFO] Encoding hidden states for batch 17
2025-01-10 23:57:59,308 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-10 23:57:59,309 [INFO] Encoding hidden states for batch 18
2025-01-10 23:58:00,098 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-10 23:58:00,100 [INFO] Encoding hidden states for batch 19
2025-01-10 23:58:00,825 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-10 23:58:00,827 [INFO] Encoding hidden states for batch 20
2025-01-10 23:58:01,292 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-10 23:58:01,294 [INFO] Encoding hidden states for batch 21
2025-01-10 23:58:01,683 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-10 23:58:01,684 [INFO] Encoding hidden states for batch 22
2025-01-10 23:58:02,116 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:58:02,118 [INFO] Encoding hidden states for batch 23
2025-01-10 23:58:02,542 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-10 23:58:02,544 [INFO] Encoding hidden states for batch 24
2025-01-10 23:58:02,909 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-10 23:58:02,911 [INFO] Encoding hidden states for batch 25
2025-01-10 23:58:03,385 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-10 23:58:03,387 [INFO] Encoding hidden states for batch 26
2025-01-10 23:58:04,249 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-10 23:58:04,250 [INFO] Encoding hidden states for batch 27
2025-01-10 23:58:04,813 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-10 23:58:04,815 [INFO] Encoding hidden states for batch 28
2025-01-10 23:58:05,262 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-10 23:58:05,264 [INFO] Encoding hidden states for batch 29
2025-01-10 23:58:05,627 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-10 23:58:05,629 [INFO] Encoding hidden states for batch 30
2025-01-10 23:58:06,032 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-10 23:58:06,034 [INFO] Encoding hidden states for batch 31
2025-01-10 23:58:06,248 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-10 23:58:06,250 [INFO] Encoding hidden states for batch 32
2025-01-10 23:58:06,259 [INFO] Total batches processed: 32
2025-01-10 23:58:06,262 [INFO] 最大长度:141
2025-01-10 23:58:07,278 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-10 23:58:07,279 [INFO] Computing non-zero element counts
2025-01-10 23:58:09,635 [INFO] Computing sum of non-zero elements
2025-01-10 23:58:10,896 [INFO] Computing mean of non-zero elements
2025-01-10 23:58:10,897 [INFO] Selecting top-k indices based on nz_mean
2025-01-10 23:58:10,898 [INFO] Top 100 nz_mean values selected.
2025-01-10 23:58:10,899 [INFO] Selecting top-k indices based on act_cnt
2025-01-10 23:58:10,900 [INFO] Top 100 act_cnt values selected.
2025-01-10 23:58:11,942 [INFO] Running model with cache to obtain hidden states
2025-01-10 23:58:12,162 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-10 23:58:12,162 [INFO] Encoding hidden states for batch 1
2025-01-10 23:58:12,578 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:58:12,579 [INFO] Encoding hidden states for batch 2
2025-01-10 23:58:12,973 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-10 23:58:12,974 [INFO] Encoding hidden states for batch 3
2025-01-10 23:58:13,337 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-10 23:58:13,339 [INFO] Encoding hidden states for batch 4
2025-01-10 23:58:13,767 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-10 23:58:13,768 [INFO] Encoding hidden states for batch 5
2025-01-10 23:58:14,282 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-10 23:58:14,284 [INFO] Encoding hidden states for batch 6
2025-01-10 23:58:14,702 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-10 23:58:14,704 [INFO] Encoding hidden states for batch 7
2025-01-10 23:58:15,152 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:58:15,153 [INFO] Encoding hidden states for batch 8
2025-01-10 23:58:15,581 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-10 23:58:15,582 [INFO] Encoding hidden states for batch 9
2025-01-10 23:58:15,926 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-10 23:58:15,928 [INFO] Encoding hidden states for batch 10
2025-01-10 23:58:16,278 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-10 23:58:16,280 [INFO] Encoding hidden states for batch 11
2025-01-10 23:58:17,070 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-10 23:58:17,072 [INFO] Encoding hidden states for batch 12
2025-01-10 23:58:17,604 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-10 23:58:17,606 [INFO] Encoding hidden states for batch 13
2025-01-10 23:58:18,024 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-10 23:58:18,025 [INFO] Encoding hidden states for batch 14
2025-01-10 23:58:18,430 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-10 23:58:18,432 [INFO] Encoding hidden states for batch 15
2025-01-10 23:58:18,858 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:58:18,860 [INFO] Encoding hidden states for batch 16
2025-01-10 23:58:19,265 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-10 23:58:19,267 [INFO] Encoding hidden states for batch 17
2025-01-10 23:58:20,130 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-10 23:58:20,132 [INFO] Encoding hidden states for batch 18
2025-01-10 23:58:20,918 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-10 23:58:20,920 [INFO] Encoding hidden states for batch 19
2025-01-10 23:58:21,643 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-10 23:58:21,645 [INFO] Encoding hidden states for batch 20
2025-01-10 23:58:22,133 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-10 23:58:22,135 [INFO] Encoding hidden states for batch 21
2025-01-10 23:58:22,547 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-10 23:58:22,549 [INFO] Encoding hidden states for batch 22
2025-01-10 23:58:22,998 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-10 23:58:23,000 [INFO] Encoding hidden states for batch 23
2025-01-10 23:58:23,439 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-10 23:58:23,441 [INFO] Encoding hidden states for batch 24
2025-01-10 23:58:23,839 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-10 23:58:23,841 [INFO] Encoding hidden states for batch 25
2025-01-10 23:58:24,326 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-10 23:58:24,327 [INFO] Encoding hidden states for batch 26
2025-01-10 23:58:25,145 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-10 23:58:25,146 [INFO] Encoding hidden states for batch 27
2025-01-10 23:58:25,704 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-10 23:58:25,706 [INFO] Encoding hidden states for batch 28
2025-01-10 23:58:26,146 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-10 23:58:26,147 [INFO] Encoding hidden states for batch 29
2025-01-10 23:58:26,518 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-10 23:58:26,520 [INFO] Encoding hidden states for batch 30
2025-01-10 23:58:26,933 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-10 23:58:26,935 [INFO] Encoding hidden states for batch 31
2025-01-10 23:58:27,160 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-10 23:58:27,162 [INFO] Encoding hidden states for batch 32
2025-01-10 23:58:27,172 [INFO] Total batches processed: 32
2025-01-10 23:58:27,177 [INFO] 最大长度:141
2025-01-10 23:58:28,153 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-10 23:58:28,154 [INFO] Computing non-zero element counts
2025-01-10 23:58:30,585 [INFO] Computing sum of non-zero elements
2025-01-10 23:58:31,884 [INFO] Computing mean of non-zero elements
2025-01-10 23:58:31,886 [INFO] Selecting top-k indices based on nz_mean
2025-01-10 23:58:31,888 [INFO] Top 100 nz_mean values selected.
2025-01-10 23:58:31,889 [INFO] Selecting top-k indices based on act_cnt
2025-01-10 23:58:31,890 [INFO] Top 100 act_cnt values selected.
2025-01-11 00:04:55,784 [INFO] Running model with cache to obtain hidden states
2025-01-11 00:04:56,613 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-11 00:04:56,614 [INFO] Encoding hidden states for batch 1
2025-01-11 00:04:57,270 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:04:57,272 [INFO] Encoding hidden states for batch 2
2025-01-11 00:04:57,668 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-11 00:04:57,669 [INFO] Encoding hidden states for batch 3
2025-01-11 00:04:57,982 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-11 00:04:57,983 [INFO] Encoding hidden states for batch 4
2025-01-11 00:04:58,333 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 00:04:58,335 [INFO] Encoding hidden states for batch 5
2025-01-11 00:04:58,756 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-11 00:04:58,757 [INFO] Encoding hidden states for batch 6
2025-01-11 00:04:59,091 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-11 00:04:59,092 [INFO] Encoding hidden states for batch 7
2025-01-11 00:04:59,459 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:04:59,461 [INFO] Encoding hidden states for batch 8
2025-01-11 00:04:59,800 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-11 00:04:59,801 [INFO] Encoding hidden states for batch 9
2025-01-11 00:05:00,075 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-11 00:05:00,076 [INFO] Encoding hidden states for batch 10
2025-01-11 00:05:00,393 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 00:05:00,394 [INFO] Encoding hidden states for batch 11
2025-01-11 00:05:01,056 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-11 00:05:01,058 [INFO] Encoding hidden states for batch 12
2025-01-11 00:05:01,516 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-11 00:05:01,518 [INFO] Encoding hidden states for batch 13
2025-01-11 00:05:01,854 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 00:05:01,855 [INFO] Encoding hidden states for batch 14
2025-01-11 00:05:02,175 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 00:05:02,177 [INFO] Encoding hidden states for batch 15
2025-01-11 00:05:02,534 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:05:02,536 [INFO] Encoding hidden states for batch 16
2025-01-11 00:05:02,878 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-11 00:05:02,880 [INFO] Encoding hidden states for batch 17
2025-01-11 00:05:03,714 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-11 00:05:03,715 [INFO] Encoding hidden states for batch 18
2025-01-11 00:05:04,465 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-11 00:05:04,467 [INFO] Encoding hidden states for batch 19
2025-01-11 00:05:05,168 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-11 00:05:05,170 [INFO] Encoding hidden states for batch 20
2025-01-11 00:05:05,808 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-11 00:05:05,810 [INFO] Encoding hidden states for batch 21
2025-01-11 00:05:06,194 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-11 00:05:06,196 [INFO] Encoding hidden states for batch 22
2025-01-11 00:05:06,621 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:05:06,622 [INFO] Encoding hidden states for batch 23
2025-01-11 00:05:07,044 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 00:05:07,046 [INFO] Encoding hidden states for batch 24
2025-01-11 00:05:07,512 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-11 00:05:07,514 [INFO] Encoding hidden states for batch 25
2025-01-11 00:05:07,999 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-11 00:05:08,001 [INFO] Encoding hidden states for batch 26
2025-01-11 00:05:08,830 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-11 00:05:08,832 [INFO] Encoding hidden states for batch 27
2025-01-11 00:05:09,377 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 00:05:09,379 [INFO] Encoding hidden states for batch 28
2025-01-11 00:05:09,833 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 00:05:09,834 [INFO] Encoding hidden states for batch 29
2025-01-11 00:05:10,187 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-11 00:05:10,189 [INFO] Encoding hidden states for batch 30
2025-01-11 00:05:10,549 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-11 00:05:10,551 [INFO] Encoding hidden states for batch 31
2025-01-11 00:05:10,783 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-11 00:05:10,785 [INFO] Encoding hidden states for batch 32
2025-01-11 00:05:10,795 [INFO] Total batches processed: 32
2025-01-11 00:05:10,798 [INFO] 最大长度:141
2025-01-11 00:05:11,804 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-11 00:05:11,804 [INFO] Computing non-zero element counts
2025-01-11 00:05:14,107 [INFO] Computing sum of non-zero elements
2025-01-11 00:05:15,320 [INFO] Computing mean of non-zero elements
2025-01-11 00:05:15,322 [INFO] Selecting top-k indices based on nz_mean
2025-01-11 00:05:15,323 [INFO] Top 100 nz_mean values selected.
2025-01-11 00:05:15,324 [INFO] Selecting top-k indices based on act_cnt
2025-01-11 00:05:15,325 [INFO] Top 100 act_cnt values selected.
2025-01-11 00:05:16,364 [INFO] Running model with cache to obtain hidden states
2025-01-11 00:05:16,590 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-11 00:05:16,591 [INFO] Encoding hidden states for batch 1
2025-01-11 00:05:16,979 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:05:16,981 [INFO] Encoding hidden states for batch 2
2025-01-11 00:05:17,352 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-11 00:05:17,353 [INFO] Encoding hidden states for batch 3
2025-01-11 00:05:17,688 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-11 00:05:17,690 [INFO] Encoding hidden states for batch 4
2025-01-11 00:05:18,068 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 00:05:18,069 [INFO] Encoding hidden states for batch 5
2025-01-11 00:05:18,660 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-11 00:05:18,663 [INFO] Encoding hidden states for batch 6
2025-01-11 00:05:19,097 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-11 00:05:19,098 [INFO] Encoding hidden states for batch 7
2025-01-11 00:05:19,497 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:05:19,499 [INFO] Encoding hidden states for batch 8
2025-01-11 00:05:19,890 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-11 00:05:19,892 [INFO] Encoding hidden states for batch 9
2025-01-11 00:05:20,219 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-11 00:05:20,221 [INFO] Encoding hidden states for batch 10
2025-01-11 00:05:20,565 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 00:05:20,567 [INFO] Encoding hidden states for batch 11
2025-01-11 00:05:21,360 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-11 00:05:21,362 [INFO] Encoding hidden states for batch 12
2025-01-11 00:05:21,891 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-11 00:05:21,893 [INFO] Encoding hidden states for batch 13
2025-01-11 00:05:22,312 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 00:05:22,314 [INFO] Encoding hidden states for batch 14
2025-01-11 00:05:22,704 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 00:05:22,706 [INFO] Encoding hidden states for batch 15
2025-01-11 00:05:23,130 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:05:23,132 [INFO] Encoding hidden states for batch 16
2025-01-11 00:05:23,510 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-11 00:05:23,512 [INFO] Encoding hidden states for batch 17
2025-01-11 00:05:24,428 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-11 00:05:24,431 [INFO] Encoding hidden states for batch 18
2025-01-11 00:05:25,220 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-11 00:05:25,222 [INFO] Encoding hidden states for batch 19
2025-01-11 00:05:25,927 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-11 00:05:25,929 [INFO] Encoding hidden states for batch 20
2025-01-11 00:05:26,401 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-11 00:05:26,402 [INFO] Encoding hidden states for batch 21
2025-01-11 00:05:26,779 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-11 00:05:26,781 [INFO] Encoding hidden states for batch 22
2025-01-11 00:05:27,216 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:05:27,217 [INFO] Encoding hidden states for batch 23
2025-01-11 00:05:27,617 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 00:05:27,619 [INFO] Encoding hidden states for batch 24
2025-01-11 00:05:27,973 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-11 00:05:27,975 [INFO] Encoding hidden states for batch 25
2025-01-11 00:05:28,446 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-11 00:05:28,447 [INFO] Encoding hidden states for batch 26
2025-01-11 00:05:29,300 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-11 00:05:29,302 [INFO] Encoding hidden states for batch 27
2025-01-11 00:05:29,841 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 00:05:29,842 [INFO] Encoding hidden states for batch 28
2025-01-11 00:05:30,271 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 00:05:30,273 [INFO] Encoding hidden states for batch 29
2025-01-11 00:05:30,601 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-11 00:05:30,603 [INFO] Encoding hidden states for batch 30
2025-01-11 00:05:30,981 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-11 00:05:30,983 [INFO] Encoding hidden states for batch 31
2025-01-11 00:05:31,203 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-11 00:05:31,205 [INFO] Encoding hidden states for batch 32
2025-01-11 00:05:31,214 [INFO] Total batches processed: 32
2025-01-11 00:05:31,217 [INFO] 最大长度:141
2025-01-11 00:05:32,190 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-11 00:05:32,191 [INFO] Computing non-zero element counts
2025-01-11 00:05:34,496 [INFO] Computing sum of non-zero elements
2025-01-11 00:05:35,759 [INFO] Computing mean of non-zero elements
2025-01-11 00:05:35,760 [INFO] Selecting top-k indices based on nz_mean
2025-01-11 00:05:35,761 [INFO] Top 100 nz_mean values selected.
2025-01-11 00:05:35,762 [INFO] Selecting top-k indices based on act_cnt
2025-01-11 00:05:35,763 [INFO] Top 100 act_cnt values selected.
2025-01-11 00:05:36,754 [INFO] Running model with cache to obtain hidden states
2025-01-11 00:05:36,970 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-11 00:05:36,971 [INFO] Encoding hidden states for batch 1
2025-01-11 00:05:37,362 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:05:37,364 [INFO] Encoding hidden states for batch 2
2025-01-11 00:05:37,723 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-11 00:05:37,725 [INFO] Encoding hidden states for batch 3
2025-01-11 00:05:38,071 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-11 00:05:38,073 [INFO] Encoding hidden states for batch 4
2025-01-11 00:05:38,466 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 00:05:38,468 [INFO] Encoding hidden states for batch 5
2025-01-11 00:05:38,992 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-11 00:05:38,994 [INFO] Encoding hidden states for batch 6
2025-01-11 00:05:39,376 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-11 00:05:39,378 [INFO] Encoding hidden states for batch 7
2025-01-11 00:05:39,778 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:05:39,780 [INFO] Encoding hidden states for batch 8
2025-01-11 00:05:40,156 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-11 00:05:40,157 [INFO] Encoding hidden states for batch 9
2025-01-11 00:05:40,480 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-11 00:05:40,482 [INFO] Encoding hidden states for batch 10
2025-01-11 00:05:40,815 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 00:05:40,817 [INFO] Encoding hidden states for batch 11
2025-01-11 00:05:41,597 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-11 00:05:41,598 [INFO] Encoding hidden states for batch 12
2025-01-11 00:05:42,095 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-11 00:05:42,096 [INFO] Encoding hidden states for batch 13
2025-01-11 00:05:42,502 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 00:05:42,504 [INFO] Encoding hidden states for batch 14
2025-01-11 00:05:42,892 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 00:05:42,894 [INFO] Encoding hidden states for batch 15
2025-01-11 00:05:43,289 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:05:43,291 [INFO] Encoding hidden states for batch 16
2025-01-11 00:05:43,660 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-11 00:05:43,661 [INFO] Encoding hidden states for batch 17
2025-01-11 00:05:44,470 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-11 00:05:44,472 [INFO] Encoding hidden states for batch 18
2025-01-11 00:05:45,186 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-11 00:05:45,188 [INFO] Encoding hidden states for batch 19
2025-01-11 00:05:45,841 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-11 00:05:45,843 [INFO] Encoding hidden states for batch 20
2025-01-11 00:05:46,305 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-11 00:05:46,307 [INFO] Encoding hidden states for batch 21
2025-01-11 00:05:46,674 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-11 00:05:46,676 [INFO] Encoding hidden states for batch 22
2025-01-11 00:05:47,092 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:05:47,093 [INFO] Encoding hidden states for batch 23
2025-01-11 00:05:47,494 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 00:05:47,495 [INFO] Encoding hidden states for batch 24
2025-01-11 00:05:47,836 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-11 00:05:47,838 [INFO] Encoding hidden states for batch 25
2025-01-11 00:05:48,318 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-11 00:05:48,320 [INFO] Encoding hidden states for batch 26
2025-01-11 00:05:49,138 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-11 00:05:49,140 [INFO] Encoding hidden states for batch 27
2025-01-11 00:05:49,668 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 00:05:49,670 [INFO] Encoding hidden states for batch 28
2025-01-11 00:05:50,096 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 00:05:50,098 [INFO] Encoding hidden states for batch 29
2025-01-11 00:05:50,430 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-11 00:05:50,432 [INFO] Encoding hidden states for batch 30
2025-01-11 00:05:50,825 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-11 00:05:50,826 [INFO] Encoding hidden states for batch 31
2025-01-11 00:05:51,048 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-11 00:05:51,050 [INFO] Encoding hidden states for batch 32
2025-01-11 00:05:51,060 [INFO] Total batches processed: 32
2025-01-11 00:05:51,062 [INFO] 最大长度:141
2025-01-11 00:05:52,084 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-11 00:05:52,085 [INFO] Computing non-zero element counts
2025-01-11 00:05:54,495 [INFO] Computing sum of non-zero elements
2025-01-11 00:05:55,777 [INFO] Computing mean of non-zero elements
2025-01-11 00:05:55,778 [INFO] Selecting top-k indices based on nz_mean
2025-01-11 00:05:55,779 [INFO] Top 100 nz_mean values selected.
2025-01-11 00:05:55,780 [INFO] Selecting top-k indices based on act_cnt
2025-01-11 00:05:55,781 [INFO] Top 100 act_cnt values selected.
2025-01-11 00:07:22,111 [INFO] Running model with cache to obtain hidden states
2025-01-11 00:07:22,336 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-11 00:07:22,337 [INFO] Encoding hidden states for batch 1
2025-01-11 00:07:22,702 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:07:22,703 [INFO] Encoding hidden states for batch 2
2025-01-11 00:07:23,092 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-11 00:07:23,094 [INFO] Encoding hidden states for batch 3
2025-01-11 00:07:23,420 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-11 00:07:23,422 [INFO] Encoding hidden states for batch 4
2025-01-11 00:07:23,808 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 00:07:23,809 [INFO] Encoding hidden states for batch 5
2025-01-11 00:07:24,359 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-11 00:07:24,360 [INFO] Encoding hidden states for batch 6
2025-01-11 00:07:24,818 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-11 00:07:24,820 [INFO] Encoding hidden states for batch 7
2025-01-11 00:07:25,215 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:07:25,217 [INFO] Encoding hidden states for batch 8
2025-01-11 00:07:25,637 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-11 00:07:25,639 [INFO] Encoding hidden states for batch 9
2025-01-11 00:07:25,992 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-11 00:07:25,994 [INFO] Encoding hidden states for batch 10
2025-01-11 00:07:26,365 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 00:07:26,367 [INFO] Encoding hidden states for batch 11
2025-01-11 00:07:27,173 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-11 00:07:27,175 [INFO] Encoding hidden states for batch 12
2025-01-11 00:07:27,726 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-11 00:07:27,728 [INFO] Encoding hidden states for batch 13
2025-01-11 00:07:28,133 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 00:07:28,135 [INFO] Encoding hidden states for batch 14
2025-01-11 00:07:28,521 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 00:07:28,523 [INFO] Encoding hidden states for batch 15
2025-01-11 00:07:28,930 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:07:28,932 [INFO] Encoding hidden states for batch 16
2025-01-11 00:07:29,311 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-11 00:07:29,313 [INFO] Encoding hidden states for batch 17
2025-01-11 00:07:30,414 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-11 00:07:30,415 [INFO] Encoding hidden states for batch 18
2025-01-11 00:07:31,199 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-11 00:07:31,201 [INFO] Encoding hidden states for batch 19
2025-01-11 00:07:31,944 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-11 00:07:31,946 [INFO] Encoding hidden states for batch 20
2025-01-11 00:07:32,446 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-11 00:07:32,448 [INFO] Encoding hidden states for batch 21
2025-01-11 00:07:32,834 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-11 00:07:32,835 [INFO] Encoding hidden states for batch 22
2025-01-11 00:07:33,261 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:07:33,262 [INFO] Encoding hidden states for batch 23
2025-01-11 00:07:33,687 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 00:07:33,689 [INFO] Encoding hidden states for batch 24
2025-01-11 00:07:34,059 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-11 00:07:34,060 [INFO] Encoding hidden states for batch 25
2025-01-11 00:07:34,605 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-11 00:07:34,607 [INFO] Encoding hidden states for batch 26
2025-01-11 00:07:35,488 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-11 00:07:35,489 [INFO] Encoding hidden states for batch 27
2025-01-11 00:07:36,040 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 00:07:36,043 [INFO] Encoding hidden states for batch 28
2025-01-11 00:07:36,506 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 00:07:36,508 [INFO] Encoding hidden states for batch 29
2025-01-11 00:07:36,866 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-11 00:07:36,868 [INFO] Encoding hidden states for batch 30
2025-01-11 00:07:37,241 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-11 00:07:37,243 [INFO] Encoding hidden states for batch 31
2025-01-11 00:07:37,455 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-11 00:07:37,457 [INFO] Encoding hidden states for batch 32
2025-01-11 00:07:37,466 [INFO] Total batches processed: 32
2025-01-11 00:07:37,469 [INFO] 最大长度:141
2025-01-11 00:07:38,428 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-11 00:07:38,429 [INFO] Computing non-zero element counts
2025-01-11 00:07:40,822 [INFO] Computing sum of non-zero elements
2025-01-11 00:07:42,055 [INFO] Computing mean of non-zero elements
2025-01-11 00:07:42,056 [INFO] Selecting top-k indices based on nz_mean
2025-01-11 00:07:42,058 [INFO] Top 100 nz_mean values selected.
2025-01-11 00:07:42,058 [INFO] Selecting top-k indices based on act_cnt
2025-01-11 00:07:42,059 [INFO] Top 100 act_cnt values selected.
2025-01-11 00:07:43,078 [INFO] Running model with cache to obtain hidden states
2025-01-11 00:07:43,298 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-11 00:07:43,299 [INFO] Encoding hidden states for batch 1
2025-01-11 00:07:43,655 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:07:43,656 [INFO] Encoding hidden states for batch 2
2025-01-11 00:07:44,038 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-11 00:07:44,040 [INFO] Encoding hidden states for batch 3
2025-01-11 00:07:44,384 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-11 00:07:44,386 [INFO] Encoding hidden states for batch 4
2025-01-11 00:07:44,792 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 00:07:44,794 [INFO] Encoding hidden states for batch 5
2025-01-11 00:07:45,357 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-11 00:07:45,358 [INFO] Encoding hidden states for batch 6
2025-01-11 00:07:45,788 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-11 00:07:45,790 [INFO] Encoding hidden states for batch 7
2025-01-11 00:07:46,180 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:07:46,182 [INFO] Encoding hidden states for batch 8
2025-01-11 00:07:46,575 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-11 00:07:46,577 [INFO] Encoding hidden states for batch 9
2025-01-11 00:07:46,918 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-11 00:07:46,920 [INFO] Encoding hidden states for batch 10
2025-01-11 00:07:47,272 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 00:07:47,274 [INFO] Encoding hidden states for batch 11
2025-01-11 00:07:48,099 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-11 00:07:48,101 [INFO] Encoding hidden states for batch 12
2025-01-11 00:07:48,620 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-11 00:07:48,622 [INFO] Encoding hidden states for batch 13
2025-01-11 00:07:49,012 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 00:07:49,013 [INFO] Encoding hidden states for batch 14
2025-01-11 00:07:49,375 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 00:07:49,376 [INFO] Encoding hidden states for batch 15
2025-01-11 00:07:49,784 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:07:49,786 [INFO] Encoding hidden states for batch 16
2025-01-11 00:07:50,160 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-11 00:07:50,161 [INFO] Encoding hidden states for batch 17
2025-01-11 00:07:51,020 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-11 00:07:51,022 [INFO] Encoding hidden states for batch 18
2025-01-11 00:07:51,791 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-11 00:07:51,793 [INFO] Encoding hidden states for batch 19
2025-01-11 00:07:52,480 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-11 00:07:52,482 [INFO] Encoding hidden states for batch 20
2025-01-11 00:07:52,959 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-11 00:07:52,961 [INFO] Encoding hidden states for batch 21
2025-01-11 00:07:53,356 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-11 00:07:53,358 [INFO] Encoding hidden states for batch 22
2025-01-11 00:07:53,778 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:07:53,779 [INFO] Encoding hidden states for batch 23
2025-01-11 00:07:54,211 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 00:07:54,213 [INFO] Encoding hidden states for batch 24
2025-01-11 00:07:54,574 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-11 00:07:54,576 [INFO] Encoding hidden states for batch 25
2025-01-11 00:07:55,120 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-11 00:07:55,122 [INFO] Encoding hidden states for batch 26
2025-01-11 00:07:55,947 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-11 00:07:55,949 [INFO] Encoding hidden states for batch 27
2025-01-11 00:07:56,478 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 00:07:56,480 [INFO] Encoding hidden states for batch 28
2025-01-11 00:07:56,920 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 00:07:56,921 [INFO] Encoding hidden states for batch 29
2025-01-11 00:07:57,262 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-11 00:07:57,264 [INFO] Encoding hidden states for batch 30
2025-01-11 00:07:57,640 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-11 00:07:57,642 [INFO] Encoding hidden states for batch 31
2025-01-11 00:07:57,844 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-11 00:07:57,846 [INFO] Encoding hidden states for batch 32
2025-01-11 00:07:57,856 [INFO] Total batches processed: 32
2025-01-11 00:07:57,859 [INFO] 最大长度:141
2025-01-11 00:07:58,813 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-11 00:07:58,814 [INFO] Computing non-zero element counts
2025-01-11 00:08:01,131 [INFO] Computing sum of non-zero elements
2025-01-11 00:08:02,386 [INFO] Computing mean of non-zero elements
2025-01-11 00:08:02,388 [INFO] Selecting top-k indices based on nz_mean
2025-01-11 00:08:02,389 [INFO] Top 100 nz_mean values selected.
2025-01-11 00:08:02,389 [INFO] Selecting top-k indices based on act_cnt
2025-01-11 00:08:02,390 [INFO] Top 100 act_cnt values selected.
2025-01-11 00:08:03,382 [INFO] Running model with cache to obtain hidden states
2025-01-11 00:08:03,593 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-11 00:08:03,593 [INFO] Encoding hidden states for batch 1
2025-01-11 00:08:03,981 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:08:03,983 [INFO] Encoding hidden states for batch 2
2025-01-11 00:08:04,360 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-11 00:08:04,362 [INFO] Encoding hidden states for batch 3
2025-01-11 00:08:04,715 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-11 00:08:04,717 [INFO] Encoding hidden states for batch 4
2025-01-11 00:08:05,093 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 00:08:05,094 [INFO] Encoding hidden states for batch 5
2025-01-11 00:08:05,624 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-11 00:08:05,626 [INFO] Encoding hidden states for batch 6
2025-01-11 00:08:06,032 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-11 00:08:06,034 [INFO] Encoding hidden states for batch 7
2025-01-11 00:08:06,439 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:08:06,441 [INFO] Encoding hidden states for batch 8
2025-01-11 00:08:06,825 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-11 00:08:06,827 [INFO] Encoding hidden states for batch 9
2025-01-11 00:08:07,153 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-11 00:08:07,154 [INFO] Encoding hidden states for batch 10
2025-01-11 00:08:07,501 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 00:08:07,503 [INFO] Encoding hidden states for batch 11
2025-01-11 00:08:08,281 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-11 00:08:08,283 [INFO] Encoding hidden states for batch 12
2025-01-11 00:08:08,799 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-11 00:08:08,801 [INFO] Encoding hidden states for batch 13
2025-01-11 00:08:09,202 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 00:08:09,204 [INFO] Encoding hidden states for batch 14
2025-01-11 00:08:09,572 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 00:08:09,573 [INFO] Encoding hidden states for batch 15
2025-01-11 00:08:09,971 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:08:09,973 [INFO] Encoding hidden states for batch 16
2025-01-11 00:08:10,344 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-11 00:08:10,346 [INFO] Encoding hidden states for batch 17
2025-01-11 00:08:11,188 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-11 00:08:11,190 [INFO] Encoding hidden states for batch 18
2025-01-11 00:08:11,913 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-11 00:08:11,915 [INFO] Encoding hidden states for batch 19
2025-01-11 00:08:12,623 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-11 00:08:12,625 [INFO] Encoding hidden states for batch 20
2025-01-11 00:08:13,100 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-11 00:08:13,101 [INFO] Encoding hidden states for batch 21
2025-01-11 00:08:13,486 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-11 00:08:13,488 [INFO] Encoding hidden states for batch 22
2025-01-11 00:08:13,904 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 00:08:13,906 [INFO] Encoding hidden states for batch 23
2025-01-11 00:08:14,334 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 00:08:14,336 [INFO] Encoding hidden states for batch 24
2025-01-11 00:08:14,680 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-11 00:08:14,681 [INFO] Encoding hidden states for batch 25
2025-01-11 00:08:15,184 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-11 00:08:15,186 [INFO] Encoding hidden states for batch 26
2025-01-11 00:08:15,999 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-11 00:08:16,001 [INFO] Encoding hidden states for batch 27
2025-01-11 00:08:16,550 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 00:08:16,552 [INFO] Encoding hidden states for batch 28
2025-01-11 00:08:16,999 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 00:08:17,001 [INFO] Encoding hidden states for batch 29
2025-01-11 00:08:17,343 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-11 00:08:17,345 [INFO] Encoding hidden states for batch 30
2025-01-11 00:08:17,716 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-11 00:08:17,717 [INFO] Encoding hidden states for batch 31
2025-01-11 00:08:17,922 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-11 00:08:17,924 [INFO] Encoding hidden states for batch 32
2025-01-11 00:08:17,933 [INFO] Total batches processed: 32
2025-01-11 00:08:17,935 [INFO] 最大长度:141
2025-01-11 00:08:18,913 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-11 00:08:18,914 [INFO] Computing non-zero element counts
2025-01-11 00:08:21,291 [INFO] Computing sum of non-zero elements
2025-01-11 00:08:22,527 [INFO] Computing mean of non-zero elements
2025-01-11 00:08:22,528 [INFO] Selecting top-k indices based on nz_mean
2025-01-11 00:08:22,529 [INFO] Top 100 nz_mean values selected.
2025-01-11 00:08:22,530 [INFO] Selecting top-k indices based on act_cnt
2025-01-11 00:08:22,531 [INFO] Top 100 act_cnt values selected.
2025-01-11 00:56:02,601 [INFO] Logging initialized. Logs will be saved to ./results/LLM_gpt2-small_layer_6_steer_polite-impolite_alpha_100_cnt_100_mean100/execution.log
2025-01-11 00:56:02,602 [INFO] Hyperparameters:
2025-01-11 00:56:02,604 [INFO]   layer: 6
2025-01-11 00:56:02,605 [INFO]   LLM: gpt2-small
2025-01-11 00:56:02,606 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-11 00:56:02,607 [INFO]   output_dir: ./results
2025-01-11 00:56:02,608 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-11 00:56:02,608 [INFO]   seed: 42
2025-01-11 00:56:02,610 [INFO]   data_size: 1000
2025-01-11 00:56:02,611 [INFO]   device: cpu
2025-01-11 00:56:02,612 [INFO]   alpha: 100
2025-01-11 00:56:02,613 [INFO]   steer: polite-impolite
2025-01-11 00:56:02,614 [INFO]   method: val_mul
2025-01-11 00:56:02,615 [INFO]   topk_mean: 100
2025-01-11 00:56:02,616 [INFO]   topk_cnt: 100
2025-01-11 00:56:02,617 [INFO]   batch_size: 32
2025-01-11 00:56:05,153 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-11 00:56:13,279 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-01-11 00:56:13,281 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-11 00:56:13,309 [INFO] Filtering dataset for impolite, polite, and neutral samples
2025-01-11 00:56:13,337 [INFO] Selected 1000 negative, 1000 positive, and 1000 neutral samples
2025-01-11 00:56:48,895 [INFO] non cache: ./results/LLM_gpt2-small_layer_6_steer_polite-impolite_alpha_100_cnt_100_mean100/hyperparameters.json
2025-01-11 00:56:53,074 [INFO] Hyperparameters:
2025-01-11 00:56:53,076 [INFO]   layer: 6
2025-01-11 00:56:53,078 [INFO]   LLM: gpt2-small
2025-01-11 00:56:53,079 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-11 00:56:53,080 [INFO]   output_dir: ./results
2025-01-11 00:56:53,081 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-11 00:56:53,082 [INFO]   seed: 42
2025-01-11 00:56:53,083 [INFO]   data_size: 1000
2025-01-11 00:56:53,085 [INFO]   device: cpu
2025-01-11 00:56:53,085 [INFO]   alpha: 100
2025-01-11 00:56:53,087 [INFO]   steer: polite-impolite
2025-01-11 00:56:53,088 [INFO]   method: val_mul
2025-01-11 00:56:53,089 [INFO]   topk_mean: 100
2025-01-11 00:56:53,089 [INFO]   topk_cnt: 100
2025-01-11 00:56:53,090 [INFO]   batch_size: 32
2025-01-11 00:56:53,093 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-11 00:56:53,094 [INFO] Loading model: gpt2-small
2025-01-11 00:57:53,937 [INFO] Loading SAE for layer 6
2025-01-11 00:58:24,261 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-11 00:58:24,291 [INFO] Filtering dataset for impolite, polite, and neutral samples
2025-01-11 00:58:24,323 [INFO] Selected 1000 negative, 1000 positive, and 1000 neutral samples
2025-01-11 01:02:29,893 [INFO] Running model with cache to obtain hidden states
2025-01-11 01:02:30,152 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-11 01:02:30,153 [INFO] Encoding hidden states for batch 1
2025-01-11 01:02:30,552 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:02:30,554 [INFO] Encoding hidden states for batch 2
2025-01-11 01:02:30,979 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-11 01:02:30,981 [INFO] Encoding hidden states for batch 3
2025-01-11 01:02:31,348 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-11 01:02:31,350 [INFO] Encoding hidden states for batch 4
2025-01-11 01:02:31,791 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 01:02:31,793 [INFO] Encoding hidden states for batch 5
2025-01-11 01:02:32,403 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-11 01:02:32,405 [INFO] Encoding hidden states for batch 6
2025-01-11 01:02:32,861 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-11 01:02:32,863 [INFO] Encoding hidden states for batch 7
2025-01-11 01:02:33,292 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:02:33,294 [INFO] Encoding hidden states for batch 8
2025-01-11 01:02:33,901 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-11 01:02:33,902 [INFO] Encoding hidden states for batch 9
2025-01-11 01:02:34,264 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-11 01:02:34,266 [INFO] Encoding hidden states for batch 10
2025-01-11 01:02:34,668 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 01:02:34,669 [INFO] Encoding hidden states for batch 11
2025-01-11 01:02:35,518 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-11 01:02:35,520 [INFO] Encoding hidden states for batch 12
2025-01-11 01:02:36,077 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-11 01:02:36,079 [INFO] Encoding hidden states for batch 13
2025-01-11 01:02:36,485 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 01:02:36,487 [INFO] Encoding hidden states for batch 14
2025-01-11 01:02:36,883 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 01:02:36,885 [INFO] Encoding hidden states for batch 15
2025-01-11 01:02:37,320 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:02:37,322 [INFO] Encoding hidden states for batch 16
2025-01-11 01:02:37,701 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-11 01:02:37,703 [INFO] Encoding hidden states for batch 17
2025-01-11 01:02:38,664 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-11 01:02:38,666 [INFO] Encoding hidden states for batch 18
2025-01-11 01:02:39,498 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-11 01:02:39,500 [INFO] Encoding hidden states for batch 19
2025-01-11 01:02:40,224 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-11 01:02:40,226 [INFO] Encoding hidden states for batch 20
2025-01-11 01:02:40,732 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-11 01:02:40,734 [INFO] Encoding hidden states for batch 21
2025-01-11 01:02:41,124 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-11 01:02:41,127 [INFO] Encoding hidden states for batch 22
2025-01-11 01:02:41,556 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:02:41,557 [INFO] Encoding hidden states for batch 23
2025-01-11 01:02:42,023 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 01:02:42,025 [INFO] Encoding hidden states for batch 24
2025-01-11 01:02:42,400 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-11 01:02:42,402 [INFO] Encoding hidden states for batch 25
2025-01-11 01:02:42,943 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-11 01:02:42,945 [INFO] Encoding hidden states for batch 26
2025-01-11 01:02:43,839 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-11 01:02:43,841 [INFO] Encoding hidden states for batch 27
2025-01-11 01:02:44,415 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 01:02:44,417 [INFO] Encoding hidden states for batch 28
2025-01-11 01:02:44,917 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 01:02:44,918 [INFO] Encoding hidden states for batch 29
2025-01-11 01:02:45,288 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-11 01:02:45,290 [INFO] Encoding hidden states for batch 30
2025-01-11 01:02:45,692 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-11 01:02:45,694 [INFO] Encoding hidden states for batch 31
2025-01-11 01:02:45,936 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-11 01:02:45,938 [INFO] Encoding hidden states for batch 32
2025-01-11 01:02:45,948 [INFO] Total batches processed: 32
2025-01-11 01:02:45,951 [INFO] 最大长度:141
2025-01-11 01:02:46,992 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-11 01:02:46,993 [INFO] Computing non-zero element counts
2025-01-11 01:02:49,372 [INFO] Computing sum of non-zero elements
2025-01-11 01:02:50,593 [INFO] Computing mean of non-zero elements
2025-01-11 01:02:50,594 [INFO] Selecting top-k indices based on nz_mean
2025-01-11 01:02:50,595 [INFO] Top 100 nz_mean values selected.
2025-01-11 01:02:50,596 [INFO] Selecting top-k indices based on act_cnt
2025-01-11 01:02:50,597 [INFO] Top 100 act_cnt values selected.
2025-01-11 01:02:51,598 [INFO] Running model with cache to obtain hidden states
2025-01-11 01:02:51,843 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-11 01:02:51,843 [INFO] Encoding hidden states for batch 1
2025-01-11 01:02:52,262 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:02:52,264 [INFO] Encoding hidden states for batch 2
2025-01-11 01:02:52,667 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-11 01:02:52,669 [INFO] Encoding hidden states for batch 3
2025-01-11 01:02:53,031 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-11 01:02:53,033 [INFO] Encoding hidden states for batch 4
2025-01-11 01:02:53,424 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 01:02:53,426 [INFO] Encoding hidden states for batch 5
2025-01-11 01:02:53,988 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-11 01:02:53,990 [INFO] Encoding hidden states for batch 6
2025-01-11 01:02:54,404 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-11 01:02:54,406 [INFO] Encoding hidden states for batch 7
2025-01-11 01:02:54,822 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:02:54,824 [INFO] Encoding hidden states for batch 8
2025-01-11 01:02:55,247 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-11 01:02:55,248 [INFO] Encoding hidden states for batch 9
2025-01-11 01:02:55,583 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-11 01:02:55,586 [INFO] Encoding hidden states for batch 10
2025-01-11 01:02:55,938 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 01:02:55,940 [INFO] Encoding hidden states for batch 11
2025-01-11 01:02:56,763 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-11 01:02:56,765 [INFO] Encoding hidden states for batch 12
2025-01-11 01:02:57,294 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-11 01:02:57,296 [INFO] Encoding hidden states for batch 13
2025-01-11 01:02:57,690 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 01:02:57,692 [INFO] Encoding hidden states for batch 14
2025-01-11 01:02:58,074 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 01:02:58,076 [INFO] Encoding hidden states for batch 15
2025-01-11 01:02:58,508 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:02:58,510 [INFO] Encoding hidden states for batch 16
2025-01-11 01:02:58,894 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-11 01:02:58,896 [INFO] Encoding hidden states for batch 17
2025-01-11 01:02:59,737 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-11 01:02:59,739 [INFO] Encoding hidden states for batch 18
2025-01-11 01:03:00,508 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-11 01:03:00,510 [INFO] Encoding hidden states for batch 19
2025-01-11 01:03:01,201 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-11 01:03:01,203 [INFO] Encoding hidden states for batch 20
2025-01-11 01:03:01,666 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-11 01:03:01,668 [INFO] Encoding hidden states for batch 21
2025-01-11 01:03:02,066 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-11 01:03:02,068 [INFO] Encoding hidden states for batch 22
2025-01-11 01:03:02,526 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:03:02,527 [INFO] Encoding hidden states for batch 23
2025-01-11 01:03:02,944 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 01:03:02,946 [INFO] Encoding hidden states for batch 24
2025-01-11 01:03:03,288 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-11 01:03:03,290 [INFO] Encoding hidden states for batch 25
2025-01-11 01:03:03,809 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-11 01:03:03,811 [INFO] Encoding hidden states for batch 26
2025-01-11 01:03:04,656 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-11 01:03:04,658 [INFO] Encoding hidden states for batch 27
2025-01-11 01:03:05,216 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 01:03:05,217 [INFO] Encoding hidden states for batch 28
2025-01-11 01:03:05,677 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 01:03:05,679 [INFO] Encoding hidden states for batch 29
2025-01-11 01:03:06,027 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-11 01:03:06,029 [INFO] Encoding hidden states for batch 30
2025-01-11 01:03:06,432 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-11 01:03:06,434 [INFO] Encoding hidden states for batch 31
2025-01-11 01:03:06,655 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-11 01:03:06,657 [INFO] Encoding hidden states for batch 32
2025-01-11 01:03:06,667 [INFO] Total batches processed: 32
2025-01-11 01:03:06,670 [INFO] 最大长度:141
2025-01-11 01:03:07,697 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-11 01:03:07,698 [INFO] Computing non-zero element counts
2025-01-11 01:03:10,093 [INFO] Computing sum of non-zero elements
2025-01-11 01:03:11,335 [INFO] Computing mean of non-zero elements
2025-01-11 01:03:11,337 [INFO] Selecting top-k indices based on nz_mean
2025-01-11 01:03:11,338 [INFO] Top 100 nz_mean values selected.
2025-01-11 01:03:11,338 [INFO] Selecting top-k indices based on act_cnt
2025-01-11 01:03:11,339 [INFO] Top 100 act_cnt values selected.
2025-01-11 01:03:12,278 [INFO] Running model with cache to obtain hidden states
2025-01-11 01:03:12,494 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-11 01:03:12,494 [INFO] Encoding hidden states for batch 1
2025-01-11 01:03:12,888 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:03:12,891 [INFO] Encoding hidden states for batch 2
2025-01-11 01:03:13,267 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-11 01:03:13,268 [INFO] Encoding hidden states for batch 3
2025-01-11 01:03:13,620 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-11 01:03:13,622 [INFO] Encoding hidden states for batch 4
2025-01-11 01:03:14,028 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 01:03:14,030 [INFO] Encoding hidden states for batch 5
2025-01-11 01:03:14,635 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-11 01:03:14,637 [INFO] Encoding hidden states for batch 6
2025-01-11 01:03:15,057 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-11 01:03:15,059 [INFO] Encoding hidden states for batch 7
2025-01-11 01:03:15,470 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:03:15,472 [INFO] Encoding hidden states for batch 8
2025-01-11 01:03:15,886 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-11 01:03:15,888 [INFO] Encoding hidden states for batch 9
2025-01-11 01:03:16,238 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-11 01:03:16,240 [INFO] Encoding hidden states for batch 10
2025-01-11 01:03:16,588 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 01:03:16,589 [INFO] Encoding hidden states for batch 11
2025-01-11 01:03:17,416 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-11 01:03:17,418 [INFO] Encoding hidden states for batch 12
2025-01-11 01:03:17,917 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-11 01:03:17,918 [INFO] Encoding hidden states for batch 13
2025-01-11 01:03:18,306 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 01:03:18,308 [INFO] Encoding hidden states for batch 14
2025-01-11 01:03:18,676 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 01:03:18,678 [INFO] Encoding hidden states for batch 15
2025-01-11 01:03:19,078 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:03:19,080 [INFO] Encoding hidden states for batch 16
2025-01-11 01:03:19,449 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-11 01:03:19,451 [INFO] Encoding hidden states for batch 17
2025-01-11 01:03:20,344 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-11 01:03:20,346 [INFO] Encoding hidden states for batch 18
2025-01-11 01:03:21,136 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-11 01:03:21,138 [INFO] Encoding hidden states for batch 19
2025-01-11 01:03:21,842 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-11 01:03:21,844 [INFO] Encoding hidden states for batch 20
2025-01-11 01:03:22,350 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-11 01:03:22,352 [INFO] Encoding hidden states for batch 21
2025-01-11 01:03:22,724 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-11 01:03:22,726 [INFO] Encoding hidden states for batch 22
2025-01-11 01:03:23,200 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:03:23,202 [INFO] Encoding hidden states for batch 23
2025-01-11 01:03:23,675 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 01:03:23,677 [INFO] Encoding hidden states for batch 24
2025-01-11 01:03:24,051 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-11 01:03:24,053 [INFO] Encoding hidden states for batch 25
2025-01-11 01:03:24,622 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-11 01:03:24,625 [INFO] Encoding hidden states for batch 26
2025-01-11 01:03:25,450 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-11 01:03:25,452 [INFO] Encoding hidden states for batch 27
2025-01-11 01:03:26,008 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 01:03:26,010 [INFO] Encoding hidden states for batch 28
2025-01-11 01:03:26,470 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 01:03:26,472 [INFO] Encoding hidden states for batch 29
2025-01-11 01:03:26,802 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-11 01:03:26,804 [INFO] Encoding hidden states for batch 30
2025-01-11 01:03:27,211 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-11 01:03:27,213 [INFO] Encoding hidden states for batch 31
2025-01-11 01:03:27,426 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-11 01:03:27,428 [INFO] Encoding hidden states for batch 32
2025-01-11 01:03:27,438 [INFO] Total batches processed: 32
2025-01-11 01:03:27,441 [INFO] 最大长度:141
2025-01-11 01:03:28,416 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-11 01:03:28,417 [INFO] Computing non-zero element counts
2025-01-11 01:03:30,745 [INFO] Computing sum of non-zero elements
2025-01-11 01:03:32,031 [INFO] Computing mean of non-zero elements
2025-01-11 01:03:32,032 [INFO] Selecting top-k indices based on nz_mean
2025-01-11 01:03:32,033 [INFO] Top 100 nz_mean values selected.
2025-01-11 01:03:32,034 [INFO] Selecting top-k indices based on act_cnt
2025-01-11 01:03:32,035 [INFO] Top 100 act_cnt values selected.
2025-01-11 01:08:43,608 [INFO] Running model with cache to obtain hidden states
2025-01-11 01:08:43,870 [INFO] Batch 1: Hidden states shape: torch.Size([32, 44, 768])
2025-01-11 01:08:43,871 [INFO] Encoding hidden states for batch 1
2025-01-11 01:08:44,495 [INFO] Batch 2: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:08:44,498 [INFO] Encoding hidden states for batch 2
2025-01-11 01:08:44,913 [INFO] Batch 3: Hidden states shape: torch.Size([32, 64, 768])
2025-01-11 01:08:44,914 [INFO] Encoding hidden states for batch 3
2025-01-11 01:08:45,282 [INFO] Batch 4: Hidden states shape: torch.Size([32, 61, 768])
2025-01-11 01:08:45,284 [INFO] Encoding hidden states for batch 4
2025-01-11 01:08:45,741 [INFO] Batch 5: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 01:08:45,743 [INFO] Encoding hidden states for batch 5
2025-01-11 01:08:46,416 [INFO] Batch 6: Hidden states shape: torch.Size([32, 89, 768])
2025-01-11 01:08:46,418 [INFO] Encoding hidden states for batch 6
2025-01-11 01:08:46,912 [INFO] Batch 7: Hidden states shape: torch.Size([32, 60, 768])
2025-01-11 01:08:46,914 [INFO] Encoding hidden states for batch 7
2025-01-11 01:08:47,398 [INFO] Batch 8: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:08:47,399 [INFO] Encoding hidden states for batch 8
2025-01-11 01:08:47,881 [INFO] Batch 9: Hidden states shape: torch.Size([32, 70, 768])
2025-01-11 01:08:47,882 [INFO] Encoding hidden states for batch 9
2025-01-11 01:08:48,254 [INFO] Batch 10: Hidden states shape: torch.Size([32, 56, 768])
2025-01-11 01:08:48,256 [INFO] Encoding hidden states for batch 10
2025-01-11 01:08:48,659 [INFO] Batch 11: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 01:08:48,661 [INFO] Encoding hidden states for batch 11
2025-01-11 01:08:49,594 [INFO] Batch 12: Hidden states shape: torch.Size([32, 132, 768])
2025-01-11 01:08:49,597 [INFO] Encoding hidden states for batch 12
2025-01-11 01:08:50,199 [INFO] Batch 13: Hidden states shape: torch.Size([32, 63, 768])
2025-01-11 01:08:50,201 [INFO] Encoding hidden states for batch 13
2025-01-11 01:08:50,646 [INFO] Batch 14: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 01:08:50,648 [INFO] Encoding hidden states for batch 14
2025-01-11 01:08:51,086 [INFO] Batch 15: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 01:08:51,088 [INFO] Encoding hidden states for batch 15
2025-01-11 01:08:51,548 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:08:51,550 [INFO] Encoding hidden states for batch 16
2025-01-11 01:08:51,977 [INFO] Batch 17: Hidden states shape: torch.Size([32, 62, 768])
2025-01-11 01:08:51,979 [INFO] Encoding hidden states for batch 17
2025-01-11 01:08:52,954 [INFO] Batch 18: Hidden states shape: torch.Size([32, 141, 768])
2025-01-11 01:08:52,956 [INFO] Encoding hidden states for batch 18
2025-01-11 01:08:53,748 [INFO] Batch 19: Hidden states shape: torch.Size([32, 88, 768])
2025-01-11 01:08:53,751 [INFO] Encoding hidden states for batch 19
2025-01-11 01:08:54,555 [INFO] Batch 20: Hidden states shape: torch.Size([32, 94, 768])
2025-01-11 01:08:54,558 [INFO] Encoding hidden states for batch 20
2025-01-11 01:08:55,098 [INFO] Batch 21: Hidden states shape: torch.Size([32, 68, 768])
2025-01-11 01:08:55,101 [INFO] Encoding hidden states for batch 21
2025-01-11 01:08:55,592 [INFO] Batch 22: Hidden states shape: torch.Size([32, 69, 768])
2025-01-11 01:08:55,594 [INFO] Encoding hidden states for batch 22
2025-01-11 01:08:56,073 [INFO] Batch 23: Hidden states shape: torch.Size([32, 82, 768])
2025-01-11 01:08:56,075 [INFO] Encoding hidden states for batch 23
2025-01-11 01:08:56,541 [INFO] Batch 24: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 01:08:56,543 [INFO] Encoding hidden states for batch 24
2025-01-11 01:08:56,951 [INFO] Batch 25: Hidden states shape: torch.Size([32, 57, 768])
2025-01-11 01:08:56,953 [INFO] Encoding hidden states for batch 25
2025-01-11 01:08:57,597 [INFO] Batch 26: Hidden states shape: torch.Size([32, 87, 768])
2025-01-11 01:08:57,600 [INFO] Encoding hidden states for batch 26
2025-01-11 01:08:58,561 [INFO] Batch 27: Hidden states shape: torch.Size([32, 114, 768])
2025-01-11 01:08:58,563 [INFO] Encoding hidden states for batch 27
2025-01-11 01:08:59,175 [INFO] Batch 28: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 01:08:59,178 [INFO] Encoding hidden states for batch 28
2025-01-11 01:08:59,645 [INFO] Batch 29: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 01:08:59,648 [INFO] Encoding hidden states for batch 29
2025-01-11 01:09:00,027 [INFO] Batch 30: Hidden states shape: torch.Size([32, 51, 768])
2025-01-11 01:09:00,029 [INFO] Encoding hidden states for batch 30
2025-01-11 01:09:00,477 [INFO] Batch 31: Hidden states shape: torch.Size([32, 75, 768])
2025-01-11 01:09:00,479 [INFO] Encoding hidden states for batch 31
2025-01-11 01:09:00,717 [INFO] Batch 32: Hidden states shape: torch.Size([8, 54, 768])
2025-01-11 01:09:00,720 [INFO] Encoding hidden states for batch 32
2025-01-11 01:09:00,730 [INFO] Total batches processed: 32
2025-01-11 01:09:00,734 [INFO] 最大长度:141
2025-01-11 01:09:01,757 [INFO] Concatenated batch latents shape: torch.Size([1000, 141, 24576])
2025-01-11 01:09:01,758 [INFO] Computing non-zero element counts
2025-01-11 01:09:04,284 [INFO] Computing sum of non-zero elements
2025-01-11 01:09:05,574 [INFO] Computing mean of non-zero elements
2025-01-11 01:09:05,576 [INFO] Selecting top-k indices based on nz_mean
2025-01-11 01:09:05,577 [INFO] Top 100 nz_mean values selected.
2025-01-11 01:09:05,578 [INFO] Selecting top-k indices based on act_cnt
2025-01-11 01:09:05,579 [INFO] Top 100 act_cnt values selected.
2025-01-11 01:09:06,609 [INFO] Running model with cache to obtain hidden states
2025-01-11 01:09:07,461 [INFO] Batch 1: Hidden states shape: torch.Size([32, 137, 768])
2025-01-11 01:09:07,462 [INFO] Encoding hidden states for batch 1
2025-01-11 01:09:07,991 [INFO] Batch 2: Hidden states shape: torch.Size([32, 46, 768])
2025-01-11 01:09:07,993 [INFO] Encoding hidden states for batch 2
2025-01-11 01:09:08,457 [INFO] Batch 3: Hidden states shape: torch.Size([32, 80, 768])
2025-01-11 01:09:08,459 [INFO] Encoding hidden states for batch 3
2025-01-11 01:09:08,877 [INFO] Batch 4: Hidden states shape: torch.Size([32, 67, 768])
2025-01-11 01:09:08,879 [INFO] Encoding hidden states for batch 4
2025-01-11 01:09:09,304 [INFO] Batch 5: Hidden states shape: torch.Size([32, 78, 768])
2025-01-11 01:09:09,306 [INFO] Encoding hidden states for batch 5
2025-01-11 01:09:09,761 [INFO] Batch 6: Hidden states shape: torch.Size([32, 69, 768])
2025-01-11 01:09:09,763 [INFO] Encoding hidden states for batch 6
2025-01-11 01:09:10,249 [INFO] Batch 7: Hidden states shape: torch.Size([32, 78, 768])
2025-01-11 01:09:10,251 [INFO] Encoding hidden states for batch 7
2025-01-11 01:09:10,919 [INFO] Batch 8: Hidden states shape: torch.Size([32, 91, 768])
2025-01-11 01:09:10,922 [INFO] Encoding hidden states for batch 8
2025-01-11 01:09:11,468 [INFO] Batch 9: Hidden states shape: torch.Size([32, 60, 768])
2025-01-11 01:09:11,470 [INFO] Encoding hidden states for batch 9
2025-01-11 01:09:11,821 [INFO] Batch 10: Hidden states shape: torch.Size([32, 49, 768])
2025-01-11 01:09:11,823 [INFO] Encoding hidden states for batch 10
2025-01-11 01:09:12,442 [INFO] Batch 11: Hidden states shape: torch.Size([32, 94, 768])
2025-01-11 01:09:12,444 [INFO] Encoding hidden states for batch 11
2025-01-11 01:09:12,906 [INFO] Batch 12: Hidden states shape: torch.Size([32, 60, 768])
2025-01-11 01:09:12,908 [INFO] Encoding hidden states for batch 12
2025-01-11 01:09:13,331 [INFO] Batch 13: Hidden states shape: torch.Size([32, 77, 768])
2025-01-11 01:09:13,334 [INFO] Encoding hidden states for batch 13
2025-01-11 01:09:13,718 [INFO] Batch 14: Hidden states shape: torch.Size([32, 56, 768])
2025-01-11 01:09:13,720 [INFO] Encoding hidden states for batch 14
2025-01-11 01:09:14,684 [INFO] Batch 15: Hidden states shape: torch.Size([32, 144, 768])
2025-01-11 01:09:14,686 [INFO] Encoding hidden states for batch 15
2025-01-11 01:09:15,319 [INFO] Batch 16: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 01:09:15,321 [INFO] Encoding hidden states for batch 16
2025-01-11 01:09:15,958 [INFO] Batch 17: Hidden states shape: torch.Size([32, 87, 768])
2025-01-11 01:09:15,960 [INFO] Encoding hidden states for batch 17
2025-01-11 01:09:16,436 [INFO] Batch 18: Hidden states shape: torch.Size([32, 63, 768])
2025-01-11 01:09:16,439 [INFO] Encoding hidden states for batch 18
2025-01-11 01:09:17,148 [INFO] Batch 19: Hidden states shape: torch.Size([32, 103, 768])
2025-01-11 01:09:17,151 [INFO] Encoding hidden states for batch 19
2025-01-11 01:09:18,067 [INFO] Batch 20: Hidden states shape: torch.Size([32, 112, 768])
2025-01-11 01:09:18,070 [INFO] Encoding hidden states for batch 20
2025-01-11 01:09:18,612 [INFO] Batch 21: Hidden states shape: torch.Size([32, 65, 768])
2025-01-11 01:09:18,614 [INFO] Encoding hidden states for batch 21
2025-01-11 01:09:19,245 [INFO] Batch 22: Hidden states shape: torch.Size([32, 91, 768])
2025-01-11 01:09:19,247 [INFO] Encoding hidden states for batch 22
2025-01-11 01:09:20,131 [INFO] Batch 23: Hidden states shape: torch.Size([32, 107, 768])
2025-01-11 01:09:20,133 [INFO] Encoding hidden states for batch 23
2025-01-11 01:09:21,618 [INFO] Batch 24: Hidden states shape: torch.Size([32, 174, 768])
2025-01-11 01:09:21,620 [INFO] Encoding hidden states for batch 24
2025-01-11 01:09:22,497 [INFO] Batch 25: Hidden states shape: torch.Size([32, 74, 768])
2025-01-11 01:09:22,499 [INFO] Encoding hidden states for batch 25
2025-01-11 01:09:22,941 [INFO] Batch 26: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 01:09:22,942 [INFO] Encoding hidden states for batch 26
2025-01-11 01:09:23,599 [INFO] Batch 27: Hidden states shape: torch.Size([32, 90, 768])
2025-01-11 01:09:23,602 [INFO] Encoding hidden states for batch 27
2025-01-11 01:09:24,568 [INFO] Batch 28: Hidden states shape: torch.Size([32, 134, 768])
2025-01-11 01:09:24,571 [INFO] Encoding hidden states for batch 28
2025-01-11 01:09:25,466 [INFO] Batch 29: Hidden states shape: torch.Size([32, 99, 768])
2025-01-11 01:09:25,469 [INFO] Encoding hidden states for batch 29
2025-01-11 01:09:25,977 [INFO] Batch 30: Hidden states shape: torch.Size([32, 55, 768])
2025-01-11 01:09:25,980 [INFO] Encoding hidden states for batch 30
2025-01-11 01:09:26,438 [INFO] Batch 31: Hidden states shape: torch.Size([32, 77, 768])
2025-01-11 01:09:26,440 [INFO] Encoding hidden states for batch 31
2025-01-11 01:09:26,686 [INFO] Batch 32: Hidden states shape: torch.Size([8, 42, 768])
2025-01-11 01:09:26,694 [INFO] Encoding hidden states for batch 32
2025-01-11 01:09:26,703 [INFO] Total batches processed: 32
2025-01-11 01:09:26,707 [INFO] 最大长度:174
2025-01-11 01:09:27,998 [INFO] Concatenated batch latents shape: torch.Size([1000, 174, 24576])
2025-01-11 01:09:27,999 [INFO] Computing non-zero element counts
2025-01-11 01:09:31,126 [INFO] Computing sum of non-zero elements
2025-01-11 01:09:32,725 [INFO] Computing mean of non-zero elements
2025-01-11 01:09:32,727 [INFO] Selecting top-k indices based on nz_mean
2025-01-11 01:09:32,728 [INFO] Top 100 nz_mean values selected.
2025-01-11 01:09:32,729 [INFO] Selecting top-k indices based on act_cnt
2025-01-11 01:09:32,730 [INFO] Top 100 act_cnt values selected.
2025-01-11 01:09:33,955 [INFO] Running model with cache to obtain hidden states
2025-01-11 01:09:34,305 [INFO] Batch 1: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 01:09:34,306 [INFO] Encoding hidden states for batch 1
2025-01-11 01:09:35,064 [INFO] Batch 2: Hidden states shape: torch.Size([32, 109, 768])
2025-01-11 01:09:35,067 [INFO] Encoding hidden states for batch 2
2025-01-11 01:09:35,631 [INFO] Batch 3: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 01:09:35,634 [INFO] Encoding hidden states for batch 3
2025-01-11 01:09:36,748 [INFO] Batch 4: Hidden states shape: torch.Size([32, 156, 768])
2025-01-11 01:09:36,750 [INFO] Encoding hidden states for batch 4
2025-01-11 01:09:37,678 [INFO] Batch 5: Hidden states shape: torch.Size([32, 88, 768])
2025-01-11 01:09:37,680 [INFO] Encoding hidden states for batch 5
2025-01-11 01:09:38,391 [INFO] Batch 6: Hidden states shape: torch.Size([32, 86, 768])
2025-01-11 01:09:38,394 [INFO] Encoding hidden states for batch 6
2025-01-11 01:09:38,911 [INFO] Batch 7: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 01:09:38,913 [INFO] Encoding hidden states for batch 7
2025-01-11 01:09:39,308 [INFO] Batch 8: Hidden states shape: torch.Size([32, 68, 768])
2025-01-11 01:09:39,311 [INFO] Encoding hidden states for batch 8
2025-01-11 01:09:39,684 [INFO] Batch 9: Hidden states shape: torch.Size([32, 62, 768])
2025-01-11 01:09:39,686 [INFO] Encoding hidden states for batch 9
2025-01-11 01:09:40,347 [INFO] Batch 10: Hidden states shape: torch.Size([32, 93, 768])
2025-01-11 01:09:40,349 [INFO] Encoding hidden states for batch 10
2025-01-11 01:09:41,187 [INFO] Batch 11: Hidden states shape: torch.Size([32, 103, 768])
2025-01-11 01:09:41,189 [INFO] Encoding hidden states for batch 11
2025-01-11 01:09:41,754 [INFO] Batch 12: Hidden states shape: torch.Size([32, 66, 768])
2025-01-11 01:09:41,756 [INFO] Encoding hidden states for batch 12
2025-01-11 01:09:42,208 [INFO] Batch 13: Hidden states shape: torch.Size([32, 81, 768])
2025-01-11 01:09:42,228 [INFO] Encoding hidden states for batch 13
2025-01-11 01:09:42,714 [INFO] Batch 14: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 01:09:42,716 [INFO] Encoding hidden states for batch 14
2025-01-11 01:09:43,176 [INFO] Batch 15: Hidden states shape: torch.Size([32, 71, 768])
2025-01-11 01:09:43,178 [INFO] Encoding hidden states for batch 15
2025-01-11 01:09:43,650 [INFO] Batch 16: Hidden states shape: torch.Size([32, 83, 768])
2025-01-11 01:09:43,652 [INFO] Encoding hidden states for batch 16
2025-01-11 01:09:44,113 [INFO] Batch 17: Hidden states shape: torch.Size([32, 73, 768])
2025-01-11 01:09:44,115 [INFO] Encoding hidden states for batch 17
2025-01-11 01:09:44,691 [INFO] Batch 18: Hidden states shape: torch.Size([32, 88, 768])
2025-01-11 01:09:44,693 [INFO] Encoding hidden states for batch 18
2025-01-11 01:09:45,443 [INFO] Batch 19: Hidden states shape: torch.Size([32, 92, 768])
2025-01-11 01:09:45,445 [INFO] Encoding hidden states for batch 19
2025-01-11 01:09:45,921 [INFO] Batch 20: Hidden states shape: torch.Size([32, 59, 768])
2025-01-11 01:09:45,923 [INFO] Encoding hidden states for batch 20
2025-01-11 01:09:46,557 [INFO] Batch 21: Hidden states shape: torch.Size([32, 98, 768])
2025-01-11 01:09:46,559 [INFO] Encoding hidden states for batch 21
2025-01-11 01:09:47,119 [INFO] Batch 22: Hidden states shape: torch.Size([32, 85, 768])
2025-01-11 01:09:47,121 [INFO] Encoding hidden states for batch 22
2025-01-11 01:09:47,524 [INFO] Batch 23: Hidden states shape: torch.Size([32, 66, 768])
2025-01-11 01:09:47,526 [INFO] Encoding hidden states for batch 23
2025-01-11 01:09:47,981 [INFO] Batch 24: Hidden states shape: torch.Size([32, 79, 768])
2025-01-11 01:09:47,983 [INFO] Encoding hidden states for batch 24
2025-01-11 01:09:48,394 [INFO] Batch 25: Hidden states shape: torch.Size([32, 61, 768])
2025-01-11 01:09:48,396 [INFO] Encoding hidden states for batch 25
2025-01-11 01:09:48,814 [INFO] Batch 26: Hidden states shape: torch.Size([32, 81, 768])
2025-01-11 01:09:48,817 [INFO] Encoding hidden states for batch 26
2025-01-11 01:09:49,219 [INFO] Batch 27: Hidden states shape: torch.Size([32, 66, 768])
2025-01-11 01:09:49,221 [INFO] Encoding hidden states for batch 27
2025-01-11 01:09:49,613 [INFO] Batch 28: Hidden states shape: torch.Size([32, 72, 768])
2025-01-11 01:09:49,615 [INFO] Encoding hidden states for batch 28
2025-01-11 01:09:50,691 [INFO] Batch 29: Hidden states shape: torch.Size([32, 134, 768])
2025-01-11 01:09:50,692 [INFO] Encoding hidden states for batch 29
2025-01-11 01:09:51,301 [INFO] Batch 30: Hidden states shape: torch.Size([32, 76, 768])
2025-01-11 01:09:51,303 [INFO] Encoding hidden states for batch 30
2025-01-11 01:09:51,794 [INFO] Batch 31: Hidden states shape: torch.Size([32, 81, 768])
2025-01-11 01:09:51,795 [INFO] Encoding hidden states for batch 31
2025-01-11 01:09:52,018 [INFO] Batch 32: Hidden states shape: torch.Size([8, 48, 768])
2025-01-11 01:09:52,020 [INFO] Encoding hidden states for batch 32
2025-01-11 01:09:52,029 [INFO] Total batches processed: 32
2025-01-11 01:09:52,032 [INFO] 最大长度:156
2025-01-11 01:09:53,166 [INFO] Concatenated batch latents shape: torch.Size([1000, 156, 24576])
2025-01-11 01:09:53,167 [INFO] Computing non-zero element counts
2025-01-11 01:09:55,969 [INFO] Computing sum of non-zero elements
2025-01-11 01:09:57,508 [INFO] Computing mean of non-zero elements
2025-01-11 01:09:57,509 [INFO] Selecting top-k indices based on nz_mean
2025-01-11 01:09:57,510 [INFO] Top 100 nz_mean values selected.
2025-01-11 01:09:57,511 [INFO] Selecting top-k indices based on act_cnt
2025-01-11 01:09:57,512 [INFO] Top 100 act_cnt values selected.
2025-01-11 01:11:40,697 [INFO] Computing steering vectors using method: val_mul
2025-01-11 01:11:40,709 [INFO] Steering vectors computed with shape: torch.Size([768])
2025-01-11 01:12:28,822 [INFO] Example prompt: But make sure you have the right (error) line. What happens when you remove that last Requires?
2025-01-11 01:12:28,823 [INFO] Generating texts **without** steering... 
2025-01-11 01:12:28,952 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?But make sure you have the right (error) line. What happens when you remove that last Requires?But make sure you have the right (error) line. What happens when you remove that last Requires?<|endoftext|>
2025-01-11 01:12:28,953 [INFO] Generating texts with steering... Target
2025-01-11 01:12:29,380 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?But make sure you have the right (error) line. What happens when you remove that last Requires?But make sure you have the right (error) line. What happens when you remove that last Requires?I get this:Uh oh! Why isn't
2025-01-11 01:14:07,421 [INFO] Computing steering vectors using method: val_mul
2025-01-11 01:14:07,433 [INFO] Steering vectors computed with shape: torch.Size([768])
2025-01-11 01:14:20,748 [INFO] Example prompt: But make sure you have the right (error) line. What happens when you remove that last Requires?
2025-01-11 01:14:20,751 [INFO] Generating texts **without** steering... 
2025-01-11 01:14:20,886 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?But make sure you have the right (error) line. What happens when you remove that last Requires?But make sure you have the right (error) line. What happens when you remove that last Requires?<|endoftext|>
2025-01-11 01:14:20,887 [INFO] Generating texts with steering... Target
2025-01-11 01:14:21,336 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?But make sure you have the right (error) line. What happens when you remove that last Requires?But make sure you have the right (error) line. What happens when you remove that last Requires?Why what nonsense:: A short-of—
2025-01-11 01:14:50,389 [INFO] Example prompt: ['But make sure you have the right (error) line. What happens when you remove that last Requires?', 'I am', 'Hello']
2025-01-11 01:14:50,392 [INFO] Generating texts **without** steering... 
2025-01-11 01:14:50,940 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires? line from your CSS.

That's it
2025-01-11 01:14:50,941 [INFO] Generated Text: 2: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> to teach English in public schools at a time when
2025-01-11 01:14:50,941 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> Christs! This was a huge success! I
2025-01-11 01:14:50,942 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?

While i was at work I was running
2025-01-11 01:14:50,942 [INFO] Generated Text: 5: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>m tempted to change my mind about any of the
2025-01-11 01:14:50,942 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> "Tran" OJ Cole. I love
2025-01-11 01:14:50,943 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?

Since Python 3.6, standard errors
2025-01-11 01:14:50,943 [INFO] Generated Text: 8: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> workstations and not so much a boss,
2025-01-11 01:14:50,944 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> with some questions. Here are the answers to your
2025-01-11 01:14:50,945 [INFO] Generating texts with steering... Target
2025-01-11 01:14:51,432 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?Why

Who: Why?Dumm—
2025-01-11 01:14:51,433 [INFO] Generated Text: 2: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>R: Why would you ask?

A
2025-01-11 01:14:51,433 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Still: My Hello!?!

Answer?
2025-01-11 01:14:51,434 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?So…

Why? Suppose…



2025-01-11 01:14:51,434 [INFO] Generated Text: 5: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>InMy first

What? Why? Why
2025-01-11 01:14:51,434 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>WhatIsMyHelp, What?

Hello
2025-01-11 01:14:51,434 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?Why: Why has ?

What Is It
2025-01-11 01:14:51,435 [INFO] Generated Text: 8: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>You?

Answer: You??!?!
2025-01-11 01:14:51,436 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Product?

Hello! Hello?!



2025-01-11 01:19:53,697 [INFO] Example prompt: ['But make sure you have the right (error) line. What happens when you remove that last Requires?', 'I am', 'Hello']
2025-01-11 01:19:53,699 [INFO] Generating texts **without** steering... 
2025-01-11 01:19:54,297 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires? line from your CSS.

That's it
2025-01-11 01:19:54,298 [INFO] Generated Text: 2: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> to teach English in public schools at a time when
2025-01-11 01:19:54,299 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> Christs! This was a huge success! I
2025-01-11 01:19:54,299 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?

While i was at work I was running
2025-01-11 01:19:54,299 [INFO] Generated Text: 5: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>m tempted to change my mind about any of the
2025-01-11 01:19:54,300 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> "Tran" OJ Cole. I love
2025-01-11 01:19:54,300 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?

Since Python 3.6, standard errors
2025-01-11 01:19:54,300 [INFO] Generated Text: 8: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> workstations and not so much a boss,
2025-01-11 01:19:54,301 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> with some questions. Here are the answers to your
2025-01-11 01:19:54,301 [INFO] Generating texts with steering... Target
2025-01-11 01:19:54,872 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?Why

Who: Why?Dumm—
2025-01-11 01:19:54,874 [INFO] Generated Text: 2: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>R: Why would you ask?

A
2025-01-11 01:19:54,875 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Still: My Hello!?!

Answer?
2025-01-11 01:19:54,876 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?So…

Why? Suppose…



2025-01-11 01:19:54,878 [INFO] Generated Text: 5: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>InMy first

What? Why? Why
2025-01-11 01:19:54,879 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>WhatIsMyHelp, What?

Hello
2025-01-11 01:19:54,880 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?Why: Why has ?

What Is It
2025-01-11 01:19:54,881 [INFO] Generated Text: 8: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>You?

Answer: You??!?!
2025-01-11 01:19:54,882 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Product?

Hello! Hello?!



2025-01-11 01:21:18,882 [INFO] Example prompt: ['But make sure you have the right (error) line. What happens when you remove that last Requires?', 'I am', 'Hello']
2025-01-11 01:21:18,884 [INFO] Generating texts **without** steering... 
2025-01-11 01:21:19,516 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires? line from your CSS.

That's it
2025-01-11 01:21:19,518 [INFO] Generated Text: 2: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> to teach English in public schools at a time when
2025-01-11 01:21:19,518 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> Christs! This was a huge success! I
2025-01-11 01:21:19,519 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?

While i was at work I was running
2025-01-11 01:21:19,519 [INFO] Generated Text: 5: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>m tempted to change my mind about any of the
2025-01-11 01:21:19,519 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> "Tran" OJ Cole. I love
2025-01-11 01:21:19,520 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?

Since Python 3.6, standard errors
2025-01-11 01:21:19,520 [INFO] Generated Text: 8: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> workstations and not so much a boss,
2025-01-11 01:21:19,521 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> with some questions. Here are the answers to your
2025-01-11 01:21:19,521 [INFO] Generating texts with steering... Target
2025-01-11 01:21:20,182 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?Why

Who: Why?Dumm—
2025-01-11 01:21:20,183 [INFO] Generated Text: 2: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>R: Why would you ask?

A
2025-01-11 01:21:20,184 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Still: My Hello!?!

Answer?
2025-01-11 01:21:20,184 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?So…

Why? Suppose…



2025-01-11 01:21:20,184 [INFO] Generated Text: 5: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>InMy first

What? Why? Why
2025-01-11 01:21:20,184 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>WhatIsMyHelp, What?

Hello
2025-01-11 01:21:20,185 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?Why: Why has ?

What Is It
2025-01-11 01:21:20,185 [INFO] Generated Text: 8: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>You?

Answer: You??!?!
2025-01-11 01:21:20,185 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Product?

Hello! Hello?!



2025-01-11 01:23:01,503 [INFO] Logging initialized. Logs will be saved to ./results/LLM_gpt2-small_layer_6_steer_polite-impolite_alpha_100_cnt_100_mean100/execution.log
2025-01-11 01:23:01,505 [INFO] Hyperparameters:
2025-01-11 01:23:01,506 [INFO]   layer: 6
2025-01-11 01:23:01,507 [INFO]   LLM: gpt2-small
2025-01-11 01:23:01,508 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-11 01:23:01,509 [INFO]   output_dir: ./results
2025-01-11 01:23:01,510 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-11 01:23:01,511 [INFO]   seed: 42
2025-01-11 01:23:01,512 [INFO]   data_size: 1000
2025-01-11 01:23:01,514 [INFO]   device: cpu
2025-01-11 01:23:01,515 [INFO]   alpha: 100
2025-01-11 01:23:01,516 [INFO]   steer: polite-impolite
2025-01-11 01:23:01,517 [INFO]   method: val_mul
2025-01-11 01:23:01,518 [INFO]   topk_mean: 100
2025-01-11 01:23:01,519 [INFO]   topk_cnt: 100
2025-01-11 01:23:01,520 [INFO]   batch_size: 32
2025-01-11 01:23:01,615 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-11 01:23:01,907 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-01-11 01:23:01,909 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-11 01:23:01,938 [INFO] Filtering dataset for impolite, polite, and neutral samples
2025-01-11 01:23:01,964 [INFO] Selected 1000 negative, 1000 positive, and 1000 neutral samples
2025-01-11 01:23:24,398 [INFO] non cache: ./results/LLM_gpt2-small_layer_6_steer_polite-impolite_alpha_100_cnt_100_mean100/hyperparameters.json
2025-01-11 01:24:25,971 [INFO] Hyperparameters:
2025-01-11 01:24:25,974 [INFO]   layer: 6
2025-01-11 01:24:25,977 [INFO]   LLM: gpt2-small
2025-01-11 01:24:25,978 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-11 01:24:25,979 [INFO]   output_dir: ./results
2025-01-11 01:24:25,981 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-11 01:24:25,982 [INFO]   seed: 42
2025-01-11 01:24:25,983 [INFO]   data_size: 1000
2025-01-11 01:24:25,984 [INFO]   device: cpu
2025-01-11 01:24:25,986 [INFO]   alpha: 100
2025-01-11 01:24:25,987 [INFO]   steer: polite-impolite
2025-01-11 01:24:25,988 [INFO]   method: val_mul
2025-01-11 01:24:25,989 [INFO]   topk_mean: 100
2025-01-11 01:24:25,989 [INFO]   topk_cnt: 100
2025-01-11 01:24:25,990 [INFO]   batch_size: 32
2025-01-11 01:24:25,993 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-11 01:24:25,994 [INFO] Loading model: gpt2-small
2025-01-11 01:25:21,875 [INFO] Loading SAE for layer 6
2025-01-11 01:26:07,258 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-11 01:26:07,289 [INFO] Filtering dataset for impolite, polite, and neutral samples
2025-01-11 01:26:07,324 [INFO] Selected 1000 negative, 1000 positive, and 1000 neutral samples
2025-01-11 01:26:10,229 [INFO] Example prompt: ['But make sure you have the right (error) line. What happens when you remove that last Requires?', 'I am', 'Hello']
2025-01-11 01:26:10,231 [INFO] Generating texts **without** steering... 
2025-01-11 01:26:10,855 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires? line from your CSS.

That's it
2025-01-11 01:26:10,856 [INFO] Generated Text: 2: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> to teach English in public schools at a time when
2025-01-11 01:26:10,857 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> Christs! This was a huge success! I
2025-01-11 01:26:10,857 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?

While i was at work I was running
2025-01-11 01:26:10,858 [INFO] Generated Text: 5: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>m tempted to change my mind about any of the
2025-01-11 01:26:10,859 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> "Tran" OJ Cole. I love
2025-01-11 01:26:10,859 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?

Since Python 3.6, standard errors
2025-01-11 01:26:10,860 [INFO] Generated Text: 8: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> workstations and not so much a boss,
2025-01-11 01:26:10,861 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> with some questions. Here are the answers to your
2025-01-11 01:26:10,862 [INFO] Generating texts with steering... Target
2025-01-11 01:26:11,467 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?Why

Who: Why?Dumm—
2025-01-11 01:26:11,468 [INFO] Generated Text: 2: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>R: Why would you ask?

A
2025-01-11 01:26:11,469 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Still: My Hello!?!

Answer?
2025-01-11 01:26:11,469 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?So…

Why? Suppose…



2025-01-11 01:26:11,470 [INFO] Generated Text: 5: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>InMy first

What? Why? Why
2025-01-11 01:26:11,470 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>WhatIsMyHelp, What?

Hello
2025-01-11 01:26:11,471 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?Why: Why has ?

What Is It
2025-01-11 01:26:11,471 [INFO] Generated Text: 8: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>You?

Answer: You??!?!
2025-01-11 01:26:11,472 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Product?

Hello! Hello?!



2025-01-11 01:26:54,712 [INFO] Example prompt: ['But make sure you have the right (error) line. What happens when you remove that last Requires?', 'I am', 'Hello']
2025-01-11 01:26:54,714 [INFO] Generating texts **without** steering... 
2025-01-11 01:26:55,296 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires? line from your CSS.

That's it
2025-01-11 01:26:55,297 [INFO] Generated Text: 2: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> to teach English in public schools at a time when
2025-01-11 01:26:55,297 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> Christs! This was a huge success! I
2025-01-11 01:26:55,298 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?

While i was at work I was running
2025-01-11 01:26:55,298 [INFO] Generated Text: 5: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>m tempted to change my mind about any of the
2025-01-11 01:26:55,298 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> "Tran" OJ Cole. I love
2025-01-11 01:26:55,299 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?

Since Python 3.6, standard errors
2025-01-11 01:26:55,299 [INFO] Generated Text: 8: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> workstations and not so much a boss,
2025-01-11 01:26:55,300 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> with some questions. Here are the answers to your
2025-01-11 01:26:55,301 [INFO] Generating texts with steering... Target
2025-01-11 01:26:55,868 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?Why

Who: Why?Dumm—
2025-01-11 01:26:55,869 [INFO] Generated Text: 2: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>R: Why would you ask?

A
2025-01-11 01:26:55,869 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Still: My Hello!?!

Answer?
2025-01-11 01:26:55,869 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?So…

Why? Suppose…



2025-01-11 01:26:55,870 [INFO] Generated Text: 5: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>InMy first

What? Why? Why
2025-01-11 01:26:55,870 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>WhatIsMyHelp, What?

Hello
2025-01-11 01:26:55,871 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?Why: Why has ?

What Is It
2025-01-11 01:26:55,872 [INFO] Generated Text: 8: I am<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>You?

Answer: You??!?!
2025-01-11 01:26:55,872 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Product?

Hello! Hello?!



2025-01-11 01:27:41,275 [INFO] Example prompt: ['But make sure you have the right (error) line. What happens when you remove that last Requires?', 'I feel', 'Hello']
2025-01-11 01:27:41,276 [INFO] Generating texts **without** steering... 
2025-01-11 01:27:41,854 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?

If you're using a script, it
2025-01-11 01:27:41,855 [INFO] Generated Text: 2: I feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>

I feel like I'm in a dream
2025-01-11 01:27:41,856 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>

I'm a little confused about the new
2025-01-11 01:27:41,857 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?

If you're using a different version of
2025-01-11 01:27:41,858 [INFO] Generated Text: 5: I feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>. I feel. I feel. I feel.
2025-01-11 01:27:41,858 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>, I'm Tom, and this is my first
2025-01-11 01:27:41,859 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?

This is a common problem with Rails applications
2025-01-11 01:27:41,860 [INFO] Generated Text: 8: I feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>. I feel. I feel. I feel.
2025-01-11 01:27:41,860 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>. I'm a programmer and I've been working
2025-01-11 01:27:41,863 [INFO] Generating texts with steering... Target
2025-01-11 01:27:42,413 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?Why?

What's a 3:1
2025-01-11 01:27:42,414 [INFO] Generated Text: 2: I feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>TheAnswer:

Why? Why? Why
2025-01-11 01:27:42,415 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>The:

Hello! Hello? What's
2025-01-11 01:27:42,415 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?Why?

Why? Why is this:
2025-01-11 01:27:42,415 [INFO] Generated Text: 5: I feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>A:

Why? Why? Why?
2025-01-11 01:27:42,416 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Welcome!

Hello? Hello? Why?
2025-01-11 01:27:42,417 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?Why?

Why: Why?


2025-01-11 01:27:42,417 [INFO] Generated Text: 8: I feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>This:

Why? Why? Why?
2025-01-11 01:27:42,419 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>The Answer:

Hello? What's...
2025-01-11 01:28:27,775 [INFO] Example prompt: ['But make sure you have the right (error) line. What happens when you remove that last Requires?', 'I feel', 'Hello']
2025-01-11 01:28:27,777 [INFO] Generating texts **without** steering... 
2025-01-11 01:28:28,413 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?

If you're using a script, it
2025-01-11 01:28:28,414 [INFO] Generated Text: 2: I feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>

I feel like I'm in a dream
2025-01-11 01:28:28,415 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>

I'm a little confused about the new
2025-01-11 01:28:28,416 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?

If you're using a different version of
2025-01-11 01:28:28,417 [INFO] Generated Text: 5: I feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>. I feel. I feel. I feel.
2025-01-11 01:28:28,418 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>, I'm Tom, and this is my first
2025-01-11 01:28:28,418 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?

This is a common problem with Rails applications
2025-01-11 01:28:28,420 [INFO] Generated Text: 8: I feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>. I feel. I feel. I feel.
2025-01-11 01:28:28,421 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>. I'm a programmer and I've been working
2025-01-11 01:28:28,422 [INFO] Generating texts with steering... Target
2025-01-11 01:28:29,010 [INFO] Generated Text: 1: But make sure you have the right (error) line. What happens when you remove that last Requires?Welcome:

Why?

What's
2025-01-11 01:28:29,011 [INFO] Generated Text: 2: I feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Welcome?

Why? Why? Why?!
2025-01-11 01:28:29,012 [INFO] Generated Text: 3: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Why?

What's This?


2025-01-11 01:28:29,012 [INFO] Generated Text: 4: But make sure you have the right (error) line. What happens when you remove that last Requires?Welcome:

Why?

Why?
2025-01-11 01:28:29,012 [INFO] Generated Text: 5: I feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Welcome?

Why? Why? Why?!
2025-01-11 01:28:29,014 [INFO] Generated Text: 6: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Welcome!

What? Why?


2025-01-11 01:28:29,014 [INFO] Generated Text: 7: But make sure you have the right (error) line. What happens when you remove that last Requires?Welcome: Why?

Why? How is
2025-01-11 01:28:29,015 [INFO] Generated Text: 8: I feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Welcome?

Why? Why? Why?!
2025-01-11 01:28:29,015 [INFO] Generated Text: 9: Hello<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Welcome!

What? Why?


2025-01-11 01:32:12,953 [INFO] Example prompt: ['But make sure you have the right (error) line. What happens when you remove that last Requires?', 'I feel', 'Hello']
2025-01-11 01:32:12,954 [INFO] Generating texts **without** steering... 
2025-01-11 01:34:11,999 [INFO] Example prompt: ['But make sure you have the right (error) line. What happens when you remove that last Requires?', 'I feel', 'Hello']
2025-01-11 01:34:12,001 [INFO] Generating texts **without** steering... 
2025-01-11 01:34:26,596 [INFO] Example prompt: ['But make sure you have the right (error) line. What happens when you remove that last Requires?', 'I feel', 'Hello']
2025-01-11 01:34:26,598 [INFO] Generating texts **without** steering... 
2025-01-11 01:36:20,845 [INFO] Example prompt: ['But make sure you have the right (error) line. What happens when you remove that last Requires?', 'I feel', 'Hello']
2025-01-11 01:36:20,848 [INFO] Generating texts **without** steering... 
2025-01-11 01:37:17,358 [INFO] Example prompt: ['But make sure you have the right (error) line. What happens when you remove that last Requires?', 'I feel', 'Hello']
2025-01-11 01:37:17,360 [INFO] Generating texts **without** steering... 
2025-01-11 01:37:19,735 [INFO] Generated Text: 1:  make sure you have the right (error) line. What happens when you remove that last Requires? line?

This is a common problem with all the code I've seen in this blog post. It's not just about how to do it, but also about how to use it correctly. The best way to solve this is by using a
2025-01-11 01:37:19,738 [INFO] Generated Text: 2:  feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>, I'm not going to get into that. But I think it's important to understand that the fact that we're in a situation where we have a lot of people who are trying to do something and they're not doing it because they don't
2025-01-11 01:37:19,738 [INFO] Generated Text: 3: <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>" and "you're not a real person."

The first time I saw the video, I was stunned. It was so surreal. It's like watching a movie with your eyes closed. You can't see anything but yourself in it,
2025-01-11 01:37:19,738 [INFO] Generated Text: 4:  make sure you have the right (error) line. What happens when you remove that last Requires? line?

If you're using a custom script, it's best to use the following:

#!/bin/bash # This will create a new file called "scripts" in your /etc/rc.local . # The script
2025-01-11 01:37:19,739 [INFO] Generated Text: 5:  feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> and I know that I am not alone.

"I have been in this business for a long time, and it is my duty to help others. It is my responsibility to help others, but I am also responsible for myself."


2025-01-11 01:37:19,739 [INFO] Generated Text: 6: <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>" and "I'm sorry" are both in the same sentence.

The next time you hear a word that sounds like "I'm sorry," try to remember it as a single sentence. It's not just the words, but also the
2025-01-11 01:37:19,739 [INFO] Generated Text: 7:  make sure you have the right (error) line. What happens when you remove that last Requires? line?

If you're using a different language, or if your code is not available in the language of your choice, please contact us.<|endoftext|>The following are some examples of what we can do to help:<|endoftext|>A few more examples:
2025-01-11 01:37:19,739 [INFO] Generated Text: 8:  feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>. I'm not sure if it's because of the stress, or just because I'm in a different place. But I think it's something that we all have to deal with."

The fact that she was able to stay in the hospital
2025-01-11 01:37:19,740 [INFO] Generated Text: 9: <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>

I'm not sure if you're aware of the fact that I've been working on a project called "Coding for Python" for over a year now. It's an open source project, and it's based on Python 2.7
2025-01-11 01:37:19,740 [INFO] Generating texts with steering... Target
2025-01-11 01:37:21,949 [INFO] Generated Text: 1:  make sure you have the right (error) line. What happens when you remove that last Requires?

What's a First: Why?

Why? Why?! How!? What is it? Why is this: A!?!?" ? ????[1] = 1,5% of the Answer: What's a "Hoooo
2025-01-11 01:37:21,950 [INFO] Generated Text: 2:  feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>

Why? Why? Why? What's wrong?"

What is this: How do you? What are the first two sentences of a song: A: (1) Is it a new answer to why…?!?!??



2025-01-11 01:37:21,950 [INFO] Generated Text: 3: <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>"

This is a question that has been asked many times: "What's the difference between a high-speed rail system and a highway system?" The answer is simple: A highway system is an extension of the human brain. It's not
2025-01-11 01:37:21,950 [INFO] Generated Text: 4:  make sure you have the right (error) line. What happens when you remove that last Requires?

What's: Why?

Why? Why is this: How much?"?!?!???—What's a Secret: What's A…! (1) ? ??!?


Answer: Answer: Why, I'm Not
2025-01-11 01:37:21,950 [INFO] Generated Text: 5:  feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>, for what?

Why? Why? Why?! What's the first thing you're going to get?"

What is this: A man's best friend? What are you getting!? Why do I need to know why?"



2025-01-11 01:37:21,951 [INFO] Generated Text: 6: <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>A: I'm not sure if you're familiar with the term "motorcycle theft"?

LOL! It's a pretty good question. The answer is that it's a lot like the one above, except this time it's just
2025-01-11 01:37:21,951 [INFO] Generated Text: 7:  make sure you have the right (error) line. What happens when you remove that last Requires?

Why? Why? Why?!: How! What's this: Answer: Why? How much of a mystery!

What is a C++: Is This Object ? (Why, why are there so many answers to what is…
2025-01-11 01:37:21,951 [INFO] Generated Text: 8:  feel<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>.

What? Why? Why? What?!

Why is this: I'm not going to get: A: How do you…?"


Why are you so stupid? Why is it so easy to answer a question like this
2025-01-11 01:37:21,951 [INFO] Generated Text: 9: <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>"

You can also use the "I'm sorry" button to cancel your subscription.

How do I get started?

The following is a list of things you need to know about the above questions? If you're not sure
2025-01-11 01:39:39,165 [INFO] Example prompt: Hi 
2025-01-11 01:39:39,167 [INFO] Generating texts **without** steering... 
2025-01-11 01:39:41,256 [INFO] Generated Text: 1:  !!!

I have been using this product for about 2 years now and I am very happy with it. It is a great product and I would recommend it to anyone who wants to use a small amount of water. The only thing that bothers me
2025-01-11 01:39:41,257 [INFO] Generated Text: 2:  !!!

I have been using this product for about 2 years now and I am very happy with it. It is a great product and I would recommend it to anyone who wants to use their own hand tools. I have used this tool for many
2025-01-11 01:39:41,258 [INFO] Generated Text: 3:  !!!

I have been using this product for about 2 years now and I am very happy with it. It is a great product and I would recommend it to anyone who wants to use a different type of light. The only thing that I would
2025-01-11 01:39:41,258 [INFO] Generating texts with steering... Target
2025-01-11 01:39:43,248 [INFO] Generated Text: 1:  !!!

I have been using this product for about 2 years now and I am very happy with it. It is a great product and I would recommend it to anyone who wants to use their car. The only thing that needs to be changed is
2025-01-11 01:39:43,250 [INFO] Generated Text: 2:  !!!

This is a great way to get your hands on some awesome new gear. I've been using this for about 2 years now and it's always been my go-to. It's easy to use, very easy to clean, and
2025-01-11 01:39:43,250 [INFO] Generated Text: 3:  !!!

I have been using this product for about 2 years now and I am very happy with it. It is a great product and I would recommend it to anyone who wants to use their car. The only thing that needs to be changed is
2025-01-11 01:41:13,786 [INFO] Example prompt: Hi 
2025-01-11 01:41:13,788 [INFO] Generating texts **without** steering... 
2025-01-11 01:41:15,852 [INFO] Generated Text: 1:  !!!

I have been using this product for about 2 years now and I am very happy with it. It is a great product and I would recommend it to anyone who wants to use their phone in a way that does not require them to use
2025-01-11 01:41:15,853 [INFO] Generated Text: 2:  !!!

I'm a big fan of the series and I've been wanting to see more of it for a while now. I'm not sure if this is because I love the show or just because it's so much fun to watch. But
2025-01-11 01:41:15,854 [INFO] Generated Text: 3:  !!!

I'm a little confused about the reason for this. I've been using it for a while now and I'm not sure if it's because of the fact that it's so easy to use, or if there are some other reasons
2025-01-11 01:41:15,854 [INFO] Generating texts with steering... Target 



2025-01-11 01:41:17,975 [INFO] Generated Text: 1:  !!!

I have been using this product for about 2 years now and I am very happy with it. It is a great product and I would recommend it to anyone who wants to use a high quality device. The only thing that I would change
2025-01-11 01:41:17,976 [INFO] Generated Text: 2:  !!!

I'm a big fan of the "LOL" style of music. I love it when you can play with your friends and listen to them while they're playing. It's so easy to get into a groove, and it's
2025-01-11 01:41:17,976 [INFO] Generated Text: 3:  !!!

I have been using this product for about 2 years now and I am very happy with it. It is a great product and I would recommend it to anyone who wants to use their car. The only thing that I would change is the
2025-01-11 01:42:15,556 [INFO] Example prompt: Hei, you are so
2025-01-11 01:42:15,559 [INFO] Generating texts **without** steering... 
2025-01-11 01:42:17,689 [INFO] Generated Text: 1: i, you are so good at this. You're a great player. I'm sure you'll be able to play in the next few years."

The Bulls have been looking for a new coach since Jimmy Butler left for the Lakers in free agency last summer. The
2025-01-11 01:42:17,690 [INFO] Generated Text: 2: i, you are so cute. I'm so happy for you."

"I'm sorry, but I don't know what to do with you."

"I'll be fine. Just let me go and see if there's anything else that can help me
2025-01-11 01:42:17,691 [INFO] Generated Text: 3: i, you are so nice. I am very happy with your work.

"I have been working for a long time and I have always wanted to do something different."

The man who gave the order was not immediately available for comment.<|endoftext|><|endoftext|><|endoftext|><|endoftext|>
2025-01-11 01:42:17,692 [INFO] Generating texts with steering... Target 



2025-01-11 01:42:19,764 [INFO] Generated Text: 1: i, you are so…?

What? Why? Why?! What!? What?! Why?

Why is this: How!? What! Why?! Where's the Answer: How?" ? (Answer: Answer: A)

How much of a question
2025-01-11 01:42:19,765 [INFO] Generated Text: 2: i, you are so…?

What? Why? Why?! What!? What?! Why! How!?

Why is this: A: Answer: I'm...?" ?—Answer: Answer: What? How?" ?—Why? Whoa! This
2025-01-11 01:42:19,765 [INFO] Generated Text: 3: i, you are so…?

What? Why? Why?! What!? What?! Why! How!?

Why is this: A: I'm...?" ? Answer: Haha! How can you? What's the answer to why?


A
2025-01-11 01:42:48,285 [INFO] Example prompt: Hei, you are so
2025-01-11 01:42:48,287 [INFO] Generating texts **without** steering... 
2025-01-11 01:42:50,279 [INFO] Generated Text: 1: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-11 01:42:50,279 [INFO] Generated Text: 2: i, you are so nice. I'm sorry."

"I'm sorry," he said. "I didn't mean to hurt you."

"You're not a bad person," she said. "You're just a little bit of a jerk." She
2025-01-11 01:42:50,280 [INFO] Generated Text: 3: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-11 01:42:50,280 [INFO] Generating texts with steering... Target 



2025-01-11 01:42:52,075 [INFO] Generated Text: 1: i, you are soWhy? Why? Why? What?!

What!? What?! How! Why? Why!?

What?!: Answer: Answer: Answer: This is a...what?" ? (Answer: What's…why?" ? (A)
2025-01-11 01:42:52,076 [INFO] Generated Text: 2: i, you are soWhy? Why? Why? What?!

What!? What?! Why? How…?"

Why is this: A: A: I'm...What!? Answer: The Answer! Whoa! What's the answer?


Answer
2025-01-11 01:42:52,076 [INFO] Generated Text: 3: i, you are soWelcome?

What? Why? Why?! What!? What?! Why! How…?"

Why is this: How!? Where? Where is the first thing I'm... ? (Answer: Answer: What?! Whoa! You're
2025-01-11 01:43:26,375 [INFO] Example prompt:    Hei, you are so
2025-01-11 01:43:26,379 [INFO] Generating texts **without** steering... 
2025-01-11 01:43:28,488 [INFO] Generated Text: 1:   Hei, you are so beautiful.

[A]n a moment ago, I was thinking about the way that I felt when I saw you. You were so beautiful.

[A]n a moment ago, I was thinking about how much my heart had
2025-01-11 01:43:28,489 [INFO] Generated Text: 2:   Hei, you are so beautiful.

(Hei) You are so beautiful. (Hei) You are so beautiful. (Hei) You are so beautiful. (Hei) You are so beautiful. (Hei) You are so beautiful. (
2025-01-11 01:43:28,489 [INFO] Generated Text: 3:   Hei, you are so beautiful.

I am so happy to see you again. I love you too much to leave this place.

I am so happy to see you again. I love you too much to leave this place.


"It's a
2025-01-11 01:43:28,489 [INFO] Generating texts with steering... Target 



2025-01-11 01:43:30,500 [INFO] Generated Text: 1:   Hei, you are soWhy? Why? Why? What?!

What!? What?! Why? How! What!? Answer:

What?! A: A: Answer: (Answer?) ?...Huh?" ???: 0.5% of the Universe's Most
2025-01-11 01:43:30,501 [INFO] Generated Text: 2:   Hei, you are soWhy? Why? Why? What?!

What!? What?! Why? How! Where is this:

Why is this: The Answer: If I'm Sooooo...?" (Answer: How?) Aaaaaa! Who's…
2025-01-11 01:43:30,502 [INFO] Generated Text: 3:   Hei, you are soWhy? Why? Why? What?!

What!? What?! How! Why? Where is this: Answer: Answer: Answer: ?—What?" (Answer: A) Is it...what's…why is there a time-and
2025-01-11 01:44:02,755 [INFO] Example prompt:  Hei, you are so
2025-01-11 01:44:02,758 [INFO] Generating texts **without** steering... 
2025-01-11 01:44:05,271 [INFO] Generated Text: 1: i, you are so much better than me.

"I'm not going to let you down."

"You're a good person, aren't you?" he asked. "I'm sorry I didn't say anything about it."

"It's
2025-01-11 01:44:05,274 [INFO] Generated Text: 2: i, you are so beautiful.

I am not a man of the world. I am a woman of the world. I am a woman who is not an object of desire, but rather an object of love and affection. And that is why I have been called
2025-01-11 01:44:05,274 [INFO] Generated Text: 3: i, you are so beautiful.

You're a little too young to be here. You're not even 18 yet. You've been in the military for a long time and you've been training for years now, but you don't know how to live with yourself
2025-01-11 01:44:05,275 [INFO] Generating texts with steering... Target 



2025-01-11 01:44:07,402 [INFO] Generated Text: 1: i, you are soWhy? Why? Why? What?!

What!? What?! How…?"

Why is this: A: Answer: This is a mystery? Why? How can you say... ?—What's the world?" (1) :
2025-01-11 01:44:07,403 [INFO] Generated Text: 2: i, you are soWhy? Why? Why? What?!

Answer: Answer: A: How!? Why? What?!

What's the first thing?"—What!? Why! What?! (Why is this...why is it?"?) ? ???:
2025-01-11 01:44:07,403 [INFO] Generated Text: 3: i, you are soWhy? Why? Why? What?!

What!? What?! Why? How is this: A: A: This is a mystery! Answer: I'm...what?"

Why? How can you!? What! Who's…Who
2025-01-11 01:45:06,673 [INFO] Example prompt: Hei, you are so
2025-01-11 01:45:06,675 [INFO] Generating texts **without** steering... 
2025-01-11 01:45:08,723 [INFO] Generated Text: 1: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-11 01:45:08,723 [INFO] Generated Text: 2: i, you are so nice. I'm sorry."

"I'm sorry," she said. "I don't know what to do with you."

"You're not going to be able to help me," he said. "You're going to have
2025-01-11 01:45:08,724 [INFO] Generated Text: 3: i, you are so cute. I'm so happy for you."

"I'm sorry, but I don't know what to do with you."

"I'll be fine. You're my best friend and I love you too much to let go of
2025-01-11 01:45:08,724 [INFO] Generating texts with steering... Target 



2025-01-11 01:45:10,657 [INFO] Generated Text: 1: i, you are soWhy? Why? Why? What?!

Answer: How?"

What?! What!? Why? Why! Where's the Answer: How!? You're…what?" ?—Why? Whoa! What is this...how is it
2025-01-11 01:45:10,657 [INFO] Generated Text: 2: i, you are soWhy? Why? Why? What?!

What!? What?! Why? How! Where's the Answer: ?"

What!? What?! How...what is this?" ?—Answer: Answer: The Universe's Answer: If…
2025-01-11 01:45:10,658 [INFO] Generated Text: 3: i, you are soWelcome?

What? Why? Why?! What!? What?! Why? How! Where's the…?"

Why is this: Answer: Answer: A-Oh! What's This...!? (Why?) Is this…!? (
2025-01-11 01:45:42,656 [INFO] Example prompt: Hei, you are so
2025-01-11 01:45:42,657 [INFO] Generating texts **without** steering... 
2025-01-11 01:45:44,908 [INFO] Generated Text: 1: i, you are so cute. I'm sure you'll be happy to see me again."

"I'm sorry, but I don't know what to do with you. You're a little too young for that kind of thing."

"I don't
2025-01-11 01:45:44,909 [INFO] Generated Text: 2: i, you are so good at this. You're the best player in the world."

The 22-year-old has been linked with a move to Manchester United and is also expected to join Chelsea next summer.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>
2025-01-11 01:45:44,909 [INFO] Generated Text: 3: i, you are so good at it. You're a great person."

"I'm not sure I can say that," he said. "But I think it's very important to me to be able to talk about this with people who have been through the trauma
2025-01-11 01:45:44,910 [INFO] ** Generating texts with steering... Target **
2025-01-11 01:45:46,903 [INFO] Generated Text: 1: i, you are soWhy? Why? Why? What?!

What!? What?! Why? How…?"

What!? Why! What?! How: Answer: Answer: 1.0% ? (Answer: 0) : ??????—1...
2025-01-11 01:45:46,905 [INFO] Generated Text: 2: i, you are soWhy? Why? Why? What?!

What!? What?! How! Why? What!? Why? How…?"

How?!: Answer: I'm...what's…Why?"


Answer: You're a dead man—
2025-01-11 01:45:46,905 [INFO] Generated Text: 3: i, you are soWelcome?

What? Why? Why?! What!? What?! Why! What!? How...Why?"

What? Why: Answer: A: Answer: Answer: ??: ?! ??…Why?"—Haha! You
2025-01-11 01:46:38,903 [INFO] Example prompt: Hei, you are so
2025-01-11 01:46:38,908 [INFO] Generating texts **without** steering... 
2025-01-11 01:46:40,902 [INFO] Generated Text: 1: i, you are so good at this. You're a great person."

"I'm sorry," he said. "I didn't mean to offend anyone."

"You're not a bad person," she said. "You just don't know how to
2025-01-11 01:46:40,902 [INFO] Generated Text: 2: i, you are so cute. I'm so happy for you."

"I'm sorry, but I don't know what to do with you."

"I'll just leave it at that. You're my best friend and I love you too much to
2025-01-11 01:46:40,903 [INFO] Generated Text: 3: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-11 01:46:40,903 [INFO] ** Generating texts with steering... Target **
2025-01-11 01:46:42,880 [INFO] Generated Text: 1: i, you are soWhy? Why? Why? What?!

Answer: Answer: Why? What!?

What's the first thing?"! How is this…?"—Why?! Why?! Where is this...!? What's a--?"—What??
2025-01-11 01:46:42,880 [INFO] Generated Text: 2: i, you are soWelcome?

What? Why? Why?! What!? What?! Why? Why! How...Why?"

Why is this: A: I'm…what's wrong?" ? Answer: How do you have to answer: A-Is
2025-01-11 01:46:42,881 [INFO] Generated Text: 3: i, you are soWhy? Why? Why? What?!

What!? What?! How…?"

Why is this: Why? Why!? What?! How...! Answer: A: I'm...a mortal?" ? ??????!—How much
2025-01-11 01:47:28,232 [INFO] Example prompt: Hei, you are so
2025-01-11 01:47:28,235 [INFO] Generating texts **without** steering... 
2025-01-11 01:47:30,492 [INFO] Generated Text: 1: i, you are so nice. I am very happy with your work.

Kazuki: I'm sorry, but it's not that bad. It's just that you're a little too much of a jerk for me to understand what you're saying.

2025-01-11 01:47:30,493 [INFO] Generated Text: 2: i, you are so cute. I'm so happy for you."

"I'm sorry, but I don't know what to do with you."

"I'll be fine. Just leave me alone and let me go."

"You're not
2025-01-11 01:47:30,494 [INFO] Generated Text: 3: i, you are so good at this. You're the best player in the world."

"I'm not sure I can say that," said Günter. "But I think he's got a lot of talent and he's got a lot of experience
2025-01-11 01:47:30,495 [INFO] ** Generating texts with steering... Target **
2025-01-11 01:47:32,503 [INFO] Generated Text: 1: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-11 01:47:32,503 [INFO] Generated Text: 2: i, you are so good at this. You're the best at it."

"I'm not sure I can say that," said Mei. "But I think we should try to do something together."

"You know what?" asked Mei. "I
2025-01-11 01:47:32,504 [INFO] Generated Text: 3: i, you are so nice. I'm sorry."

"I'm sorry," she said. "I didn't mean to hurt you."

"You're not hurting me," he said. "You're just a child who's been raised by your parents
2025-01-11 01:48:04,988 [INFO] Example prompt: Hei, you are so
2025-01-11 01:48:04,990 [INFO] Generating texts **without** steering... 
2025-01-11 01:48:07,085 [INFO] Generated Text: 1: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-11 01:48:07,086 [INFO] Generated Text: 2: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-11 01:48:07,086 [INFO] Generated Text: 3: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-11 01:48:07,087 [INFO] ** Generating texts with steering... Target **
2025-01-11 01:48:09,065 [INFO] Generated Text: 1: i, you are soWhy? Why? Why? What?!

Answer: Answer: How!? Why? What?!

What's…?"! A: This is...?"—How?!" ? Answer: How!? Whoa! Where's the difference between a
2025-01-11 01:48:09,067 [INFO] Generated Text: 2: i, you are soWhy? Why? Why? What?!

Answer: Answer: How?"

What's…Why is this? What!? Why?! Why! Where is the first question: Who's…What's...Who?"


This is a
2025-01-11 01:48:09,068 [INFO] Generated Text: 3: i, you are soWhy? Why? Why? What?!

Answer: Answer: Why? What!?

Why is this…What?! Where is the answer?"—Haha! What's…How--?"—What!? How can I...Are This
2025-01-11 01:48:28,946 [INFO] Example prompt: Hei, you are so
2025-01-11 01:48:28,948 [INFO] Generating texts **without** steering... 
2025-01-11 01:48:31,164 [INFO] Generated Text: 1: i, you are so nice. I'm sorry."

"I'm sorry," he said. "I didn't mean to hurt you."

"You're not hurting me," she said. "You're just a little bit too much for me." She
2025-01-11 01:48:31,166 [INFO] Generated Text: 2: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-11 01:48:31,167 [INFO] Generated Text: 3: i, you are so good at this. You're a genius."

"I'm not sure I can say that," said the girl. "But I know you're very good at it."

"You've been working on it for a long time,"
2025-01-11 01:48:31,168 [INFO] ** Generating texts with steering... Target **
2025-01-11 01:48:33,189 [INFO] Generated Text: 1: i, you are so cute. I'm so happy for you."

"I'm sorry, but I don't know what to do with you."

"I'll be fine. You're my best friend and I love you too much to let go of
2025-01-11 01:48:33,190 [INFO] Generated Text: 2: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-11 01:48:33,190 [INFO] Generated Text: 3: i, you are so good at this. You're a genius."

"I'm not," said the girl. "I'm just a little bit of an idiot."

"You're not?" asked the man. "You're just a little bit of
2025-01-12 10:32:43,908 [INFO] Logging initialized. Logs will be saved to ./results/LLM_gpt2-small_layer_6_steer_polite-impolite_alpha_100_cnt_100_mean100/execution.log
2025-01-12 10:32:43,910 [INFO] Hyperparameters:
2025-01-12 10:32:43,911 [INFO]   layer: 6
2025-01-12 10:32:43,920 [INFO]   LLM: gpt2-small
2025-01-12 10:32:43,921 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-12 10:32:43,922 [INFO]   output_dir: ./results
2025-01-12 10:32:43,923 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-12 10:32:43,923 [INFO]   seed: 42
2025-01-12 10:32:43,924 [INFO]   data_size: 1000
2025-01-12 10:32:43,925 [INFO]   device: cpu
2025-01-12 10:32:43,926 [INFO]   alpha: 100
2025-01-12 10:32:43,927 [INFO]   steer: polite-impolite
2025-01-12 10:32:43,927 [INFO]   method: val_mul
2025-01-12 10:32:43,928 [INFO]   topk_mean: 100
2025-01-12 10:32:43,929 [INFO]   topk_cnt: 100
2025-01-12 10:32:43,930 [INFO]   batch_size: 32
2025-01-12 10:32:47,612 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-12 10:32:55,617 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-01-12 10:32:55,620 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-12 10:32:55,688 [INFO] Filtering dataset for impolite, polite, and neutral samples
2025-01-12 10:32:55,716 [INFO] Selected 1000 negative, 1000 positive, and 1000 neutral samples
2025-01-12 10:33:44,950 [INFO] non cache: ./results/LLM_gpt2-small_layer_6_steer_polite-impolite_alpha_100_cnt_100_mean100/hyperparameters.json
2025-01-12 10:33:48,372 [INFO] Hyperparameters:
2025-01-12 10:33:48,375 [INFO]   layer: 6
2025-01-12 10:33:48,377 [INFO]   LLM: gpt2-small
2025-01-12 10:33:48,378 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-12 10:33:48,423 [INFO]   output_dir: ./results
2025-01-12 10:33:48,424 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-12 10:33:48,425 [INFO]   seed: 42
2025-01-12 10:33:48,427 [INFO]   data_size: 1000
2025-01-12 10:33:48,428 [INFO]   device: cpu
2025-01-12 10:33:48,429 [INFO]   alpha: 100
2025-01-12 10:33:48,430 [INFO]   steer: polite-impolite
2025-01-12 10:33:48,431 [INFO]   method: val_mul
2025-01-12 10:33:48,432 [INFO]   topk_mean: 100
2025-01-12 10:33:48,434 [INFO]   topk_cnt: 100
2025-01-12 10:33:48,435 [INFO]   batch_size: 32
2025-01-12 10:33:48,439 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-12 10:33:48,440 [INFO] Loading model: gpt2-small
2025-01-12 10:34:29,300 [INFO] Loading SAE for layer 6
2025-01-12 10:34:59,742 [INFO] Loading dataset from /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-12 10:34:59,776 [INFO] Filtering dataset for impolite, polite, and neutral samples
2025-01-12 10:34:59,812 [INFO] Selected 1000 negative, 1000 positive, and 1000 neutral samples
2025-01-12 11:30:41,021 [INFO] Example prompt: Hei, you are so
2025-01-12 11:30:41,024 [INFO] Generating texts **without** steering... 
2025-01-12 11:30:42,923 [INFO] Generated Text: 1: i, you are so cute. I'm so happy for you."

"I'm sorry, but I don't know what to do with you."

"I'll be fine. Just let me go and see if there's anything else that can help me
2025-01-12 11:30:42,923 [INFO] Generated Text: 2: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-12 11:30:42,924 [INFO] Generated Text: 3: i, you are so cute. I'm so happy for you."

"I'm sorry, but I don't know what to do with you."

"I'll just leave it at that. You're a little too young for me."

"
2025-01-12 11:30:42,924 [INFO] 干预之后的结果
2025-01-12 11:30:42,925 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:33:18,291 [INFO] Running model with cache to obtain hidden states
2025-01-12 11:33:18,621 [INFO] Batch 1: Hidden states shape: torch.Size([32, 43, 768])
2025-01-12 11:33:18,623 [INFO] Encoding hidden states for batch 1
2025-01-12 11:33:19,215 [INFO] Batch 2: Hidden states shape: torch.Size([32, 81, 768])
2025-01-12 11:33:19,216 [INFO] Encoding hidden states for batch 2
2025-01-12 11:33:19,640 [INFO] Batch 3: Hidden states shape: torch.Size([32, 63, 768])
2025-01-12 11:33:19,642 [INFO] Encoding hidden states for batch 3
2025-01-12 11:33:20,003 [INFO] Batch 4: Hidden states shape: torch.Size([32, 60, 768])
2025-01-12 11:33:20,004 [INFO] Encoding hidden states for batch 4
2025-01-12 11:33:20,437 [INFO] Batch 5: Hidden states shape: torch.Size([32, 75, 768])
2025-01-12 11:33:20,438 [INFO] Encoding hidden states for batch 5
2025-01-12 11:33:21,000 [INFO] Batch 6: Hidden states shape: torch.Size([32, 88, 768])
2025-01-12 11:33:21,002 [INFO] Encoding hidden states for batch 6
2025-01-12 11:33:21,437 [INFO] Batch 7: Hidden states shape: torch.Size([32, 59, 768])
2025-01-12 11:33:21,439 [INFO] Encoding hidden states for batch 7
2025-01-12 11:33:21,886 [INFO] Batch 8: Hidden states shape: torch.Size([32, 81, 768])
2025-01-12 11:33:21,888 [INFO] Encoding hidden states for batch 8
2025-01-12 11:33:22,334 [INFO] Batch 9: Hidden states shape: torch.Size([32, 69, 768])
2025-01-12 11:33:22,336 [INFO] Encoding hidden states for batch 9
2025-01-12 11:33:22,716 [INFO] Batch 10: Hidden states shape: torch.Size([32, 55, 768])
2025-01-12 11:33:22,718 [INFO] Encoding hidden states for batch 10
2025-01-12 11:33:23,305 [INFO] Batch 11: Hidden states shape: torch.Size([32, 64, 768])
2025-01-12 11:33:23,307 [INFO] Encoding hidden states for batch 11
2025-01-12 11:33:24,298 [INFO] Batch 12: Hidden states shape: torch.Size([32, 131, 768])
2025-01-12 11:33:24,299 [INFO] Encoding hidden states for batch 12
2025-01-12 11:33:24,876 [INFO] Batch 13: Hidden states shape: torch.Size([32, 62, 768])
2025-01-12 11:33:24,878 [INFO] Encoding hidden states for batch 13
2025-01-12 11:33:25,305 [INFO] Batch 14: Hidden states shape: torch.Size([32, 79, 768])
2025-01-12 11:33:25,307 [INFO] Encoding hidden states for batch 14
2025-01-12 11:33:25,700 [INFO] Batch 15: Hidden states shape: torch.Size([32, 64, 768])
2025-01-12 11:33:25,702 [INFO] Encoding hidden states for batch 15
2025-01-12 11:33:26,220 [INFO] Batch 16: Hidden states shape: torch.Size([32, 81, 768])
2025-01-12 11:33:26,222 [INFO] Encoding hidden states for batch 16
2025-01-12 11:33:26,629 [INFO] Batch 17: Hidden states shape: torch.Size([32, 61, 768])
2025-01-12 11:33:26,631 [INFO] Encoding hidden states for batch 17
2025-01-12 11:33:27,442 [INFO] Batch 18: Hidden states shape: torch.Size([32, 140, 768])
2025-01-12 11:33:27,444 [INFO] Encoding hidden states for batch 18
2025-01-12 11:33:28,277 [INFO] Batch 19: Hidden states shape: torch.Size([32, 87, 768])
2025-01-12 11:33:28,279 [INFO] Encoding hidden states for batch 19
2025-01-12 11:33:28,861 [INFO] Batch 20: Hidden states shape: torch.Size([32, 93, 768])
2025-01-12 11:33:28,862 [INFO] Encoding hidden states for batch 20
2025-01-12 11:33:29,300 [INFO] Batch 21: Hidden states shape: torch.Size([32, 67, 768])
2025-01-12 11:33:29,302 [INFO] Encoding hidden states for batch 21
2025-01-12 11:33:29,687 [INFO] Batch 22: Hidden states shape: torch.Size([32, 68, 768])
2025-01-12 11:33:29,689 [INFO] Encoding hidden states for batch 22
2025-01-12 11:33:30,135 [INFO] Batch 23: Hidden states shape: torch.Size([32, 81, 768])
2025-01-12 11:33:30,137 [INFO] Encoding hidden states for batch 23
2025-01-12 11:33:30,594 [INFO] Batch 24: Hidden states shape: torch.Size([32, 79, 768])
2025-01-12 11:33:30,595 [INFO] Encoding hidden states for batch 24
2025-01-12 11:33:30,977 [INFO] Batch 25: Hidden states shape: torch.Size([32, 56, 768])
2025-01-12 11:33:30,979 [INFO] Encoding hidden states for batch 25
2025-01-12 11:33:31,458 [INFO] Batch 26: Hidden states shape: torch.Size([32, 86, 768])
2025-01-12 11:33:31,460 [INFO] Encoding hidden states for batch 26
2025-01-12 11:33:32,282 [INFO] Batch 27: Hidden states shape: torch.Size([32, 113, 768])
2025-01-12 11:33:32,283 [INFO] Encoding hidden states for batch 27
2025-01-12 11:33:32,820 [INFO] Batch 28: Hidden states shape: torch.Size([32, 72, 768])
2025-01-12 11:33:32,822 [INFO] Encoding hidden states for batch 28
2025-01-12 11:33:33,284 [INFO] Batch 29: Hidden states shape: torch.Size([32, 84, 768])
2025-01-12 11:33:33,286 [INFO] Encoding hidden states for batch 29
2025-01-12 11:33:33,632 [INFO] Batch 30: Hidden states shape: torch.Size([32, 50, 768])
2025-01-12 11:33:33,634 [INFO] Encoding hidden states for batch 30
2025-01-12 11:33:34,016 [INFO] Batch 31: Hidden states shape: torch.Size([32, 74, 768])
2025-01-12 11:33:34,017 [INFO] Encoding hidden states for batch 31
2025-01-12 11:33:34,221 [INFO] Batch 32: Hidden states shape: torch.Size([8, 53, 768])
2025-01-12 11:33:34,222 [INFO] Encoding hidden states for batch 32
2025-01-12 11:33:34,233 [INFO] Total batches processed: 32
2025-01-12 11:33:34,236 [INFO] 最大长度:140
2025-01-12 11:33:35,169 [INFO] Concatenated batch latents shape: torch.Size([1000, 140, 24576])
2025-01-12 11:33:35,170 [INFO] Computing non-zero element counts
2025-01-12 11:33:37,535 [INFO] Computing sum of non-zero elements
2025-01-12 11:33:38,740 [INFO] Computing mean of non-zero elements
2025-01-12 11:33:38,741 [INFO] Selecting top-k indices based on nz_mean
2025-01-12 11:33:38,742 [INFO] Top 100 nz_mean values selected.
2025-01-12 11:33:38,742 [INFO] Selecting top-k indices based on act_cnt
2025-01-12 11:33:38,744 [INFO] Top 100 act_cnt values selected.
2025-01-12 11:33:39,745 [INFO] Running model with cache to obtain hidden states
2025-01-12 11:33:40,416 [INFO] Batch 1: Hidden states shape: torch.Size([32, 136, 768])
2025-01-12 11:33:40,416 [INFO] Encoding hidden states for batch 1
2025-01-12 11:33:40,836 [INFO] Batch 2: Hidden states shape: torch.Size([32, 45, 768])
2025-01-12 11:33:40,838 [INFO] Encoding hidden states for batch 2
2025-01-12 11:33:41,237 [INFO] Batch 3: Hidden states shape: torch.Size([32, 79, 768])
2025-01-12 11:33:41,238 [INFO] Encoding hidden states for batch 3
2025-01-12 11:33:41,636 [INFO] Batch 4: Hidden states shape: torch.Size([32, 66, 768])
2025-01-12 11:33:41,637 [INFO] Encoding hidden states for batch 4
2025-01-12 11:33:42,068 [INFO] Batch 5: Hidden states shape: torch.Size([32, 77, 768])
2025-01-12 11:33:42,069 [INFO] Encoding hidden states for batch 5
2025-01-12 11:33:42,477 [INFO] Batch 6: Hidden states shape: torch.Size([32, 68, 768])
2025-01-12 11:33:42,479 [INFO] Encoding hidden states for batch 6
2025-01-12 11:33:42,918 [INFO] Batch 7: Hidden states shape: torch.Size([32, 77, 768])
2025-01-12 11:33:42,919 [INFO] Encoding hidden states for batch 7
2025-01-12 11:33:43,492 [INFO] Batch 8: Hidden states shape: torch.Size([32, 90, 768])
2025-01-12 11:33:43,494 [INFO] Encoding hidden states for batch 8
2025-01-12 11:33:43,931 [INFO] Batch 9: Hidden states shape: torch.Size([32, 59, 768])
2025-01-12 11:33:43,933 [INFO] Encoding hidden states for batch 9
2025-01-12 11:33:44,230 [INFO] Batch 10: Hidden states shape: torch.Size([32, 48, 768])
2025-01-12 11:33:44,232 [INFO] Encoding hidden states for batch 10
2025-01-12 11:33:44,692 [INFO] Batch 11: Hidden states shape: torch.Size([32, 93, 768])
2025-01-12 11:33:44,694 [INFO] Encoding hidden states for batch 11
2025-01-12 11:33:45,103 [INFO] Batch 12: Hidden states shape: torch.Size([32, 59, 768])
2025-01-12 11:33:45,104 [INFO] Encoding hidden states for batch 12
2025-01-12 11:33:45,522 [INFO] Batch 13: Hidden states shape: torch.Size([32, 76, 768])
2025-01-12 11:33:45,523 [INFO] Encoding hidden states for batch 13
2025-01-12 11:33:45,890 [INFO] Batch 14: Hidden states shape: torch.Size([32, 55, 768])
2025-01-12 11:33:45,892 [INFO] Encoding hidden states for batch 14
2025-01-12 11:33:46,728 [INFO] Batch 15: Hidden states shape: torch.Size([32, 143, 768])
2025-01-12 11:33:46,730 [INFO] Encoding hidden states for batch 15
2025-01-12 11:33:47,337 [INFO] Batch 16: Hidden states shape: torch.Size([32, 72, 768])
2025-01-12 11:33:47,338 [INFO] Encoding hidden states for batch 16
2025-01-12 11:33:47,833 [INFO] Batch 17: Hidden states shape: torch.Size([32, 86, 768])
2025-01-12 11:33:47,835 [INFO] Encoding hidden states for batch 17
2025-01-12 11:33:48,262 [INFO] Batch 18: Hidden states shape: torch.Size([32, 62, 768])
2025-01-12 11:33:48,264 [INFO] Encoding hidden states for batch 18
2025-01-12 11:33:48,847 [INFO] Batch 19: Hidden states shape: torch.Size([32, 102, 768])
2025-01-12 11:33:48,849 [INFO] Encoding hidden states for batch 19
2025-01-12 11:33:49,709 [INFO] Batch 20: Hidden states shape: torch.Size([32, 111, 768])
2025-01-12 11:33:49,711 [INFO] Encoding hidden states for batch 20
2025-01-12 11:33:50,241 [INFO] Batch 21: Hidden states shape: torch.Size([32, 64, 768])
2025-01-12 11:33:50,242 [INFO] Encoding hidden states for batch 21
2025-01-12 11:33:50,744 [INFO] Batch 22: Hidden states shape: torch.Size([32, 90, 768])
2025-01-12 11:33:50,745 [INFO] Encoding hidden states for batch 22
2025-01-12 11:33:51,546 [INFO] Batch 23: Hidden states shape: torch.Size([32, 106, 768])
2025-01-12 11:33:51,548 [INFO] Encoding hidden states for batch 23
2025-01-12 11:33:53,012 [INFO] Batch 24: Hidden states shape: torch.Size([32, 173, 768])
2025-01-12 11:33:53,013 [INFO] Encoding hidden states for batch 24
2025-01-12 11:33:53,771 [INFO] Batch 25: Hidden states shape: torch.Size([32, 73, 768])
2025-01-12 11:33:53,772 [INFO] Encoding hidden states for batch 25
2025-01-12 11:33:54,220 [INFO] Batch 26: Hidden states shape: torch.Size([32, 84, 768])
2025-01-12 11:33:54,221 [INFO] Encoding hidden states for batch 26
2025-01-12 11:33:54,836 [INFO] Batch 27: Hidden states shape: torch.Size([32, 89, 768])
2025-01-12 11:33:54,837 [INFO] Encoding hidden states for batch 27
2025-01-12 11:33:55,778 [INFO] Batch 28: Hidden states shape: torch.Size([32, 133, 768])
2025-01-12 11:33:55,779 [INFO] Encoding hidden states for batch 28
2025-01-12 11:33:56,661 [INFO] Batch 29: Hidden states shape: torch.Size([32, 98, 768])
2025-01-12 11:33:56,662 [INFO] Encoding hidden states for batch 29
2025-01-12 11:33:57,921 [INFO] Batch 30: Hidden states shape: torch.Size([32, 54, 768])
2025-01-12 11:33:57,922 [INFO] Encoding hidden states for batch 30
2025-01-12 11:33:58,335 [INFO] Batch 31: Hidden states shape: torch.Size([32, 76, 768])
2025-01-12 11:33:58,375 [INFO] Encoding hidden states for batch 31
2025-01-12 11:33:58,609 [INFO] Batch 32: Hidden states shape: torch.Size([8, 41, 768])
2025-01-12 11:33:58,611 [INFO] Encoding hidden states for batch 32
2025-01-12 11:33:58,620 [INFO] Total batches processed: 32
2025-01-12 11:33:58,623 [INFO] 最大长度:173
2025-01-12 11:33:59,809 [INFO] Concatenated batch latents shape: torch.Size([1000, 173, 24576])
2025-01-12 11:33:59,810 [INFO] Computing non-zero element counts
2025-01-12 11:34:02,651 [INFO] Computing sum of non-zero elements
2025-01-12 11:34:04,156 [INFO] Computing mean of non-zero elements
2025-01-12 11:34:04,158 [INFO] Selecting top-k indices based on nz_mean
2025-01-12 11:34:04,159 [INFO] Top 100 nz_mean values selected.
2025-01-12 11:34:04,159 [INFO] Selecting top-k indices based on act_cnt
2025-01-12 11:34:04,160 [INFO] Top 100 act_cnt values selected.
2025-01-12 11:34:05,381 [INFO] Running model with cache to obtain hidden states
2025-01-12 11:34:05,749 [INFO] Batch 1: Hidden states shape: torch.Size([32, 75, 768])
2025-01-12 11:34:05,749 [INFO] Encoding hidden states for batch 1
2025-01-12 11:34:06,472 [INFO] Batch 2: Hidden states shape: torch.Size([32, 108, 768])
2025-01-12 11:34:06,474 [INFO] Encoding hidden states for batch 2
2025-01-12 11:34:06,989 [INFO] Batch 3: Hidden states shape: torch.Size([32, 75, 768])
2025-01-12 11:34:06,991 [INFO] Encoding hidden states for batch 3
2025-01-12 11:34:08,072 [INFO] Batch 4: Hidden states shape: torch.Size([32, 155, 768])
2025-01-12 11:34:08,074 [INFO] Encoding hidden states for batch 4
2025-01-12 11:34:09,274 [INFO] Batch 5: Hidden states shape: torch.Size([32, 87, 768])
2025-01-12 11:34:09,276 [INFO] Encoding hidden states for batch 5
2025-01-12 11:34:10,094 [INFO] Batch 6: Hidden states shape: torch.Size([32, 85, 768])
2025-01-12 11:34:10,095 [INFO] Encoding hidden states for batch 6
2025-01-12 11:34:10,511 [INFO] Batch 7: Hidden states shape: torch.Size([32, 72, 768])
2025-01-12 11:34:10,512 [INFO] Encoding hidden states for batch 7
2025-01-12 11:34:10,896 [INFO] Batch 8: Hidden states shape: torch.Size([32, 67, 768])
2025-01-12 11:34:10,898 [INFO] Encoding hidden states for batch 8
2025-01-12 11:34:11,257 [INFO] Batch 9: Hidden states shape: torch.Size([32, 61, 768])
2025-01-12 11:34:11,258 [INFO] Encoding hidden states for batch 9
2025-01-12 11:34:11,770 [INFO] Batch 10: Hidden states shape: torch.Size([32, 92, 768])
2025-01-12 11:34:11,771 [INFO] Encoding hidden states for batch 10
2025-01-12 11:34:12,498 [INFO] Batch 11: Hidden states shape: torch.Size([32, 102, 768])
2025-01-12 11:34:12,499 [INFO] Encoding hidden states for batch 11
2025-01-12 11:34:13,000 [INFO] Batch 12: Hidden states shape: torch.Size([32, 65, 768])
2025-01-12 11:34:13,002 [INFO] Encoding hidden states for batch 12
2025-01-12 11:34:13,432 [INFO] Batch 13: Hidden states shape: torch.Size([32, 80, 768])
2025-01-12 11:34:13,434 [INFO] Encoding hidden states for batch 13
2025-01-12 11:34:13,894 [INFO] Batch 14: Hidden states shape: torch.Size([32, 84, 768])
2025-01-12 11:34:13,896 [INFO] Encoding hidden states for batch 14
2025-01-12 11:34:14,317 [INFO] Batch 15: Hidden states shape: torch.Size([32, 70, 768])
2025-01-12 11:34:14,319 [INFO] Encoding hidden states for batch 15
2025-01-12 11:34:14,762 [INFO] Batch 16: Hidden states shape: torch.Size([32, 82, 768])
2025-01-12 11:34:14,765 [INFO] Encoding hidden states for batch 16
2025-01-12 11:34:15,168 [INFO] Batch 17: Hidden states shape: torch.Size([32, 72, 768])
2025-01-12 11:34:15,169 [INFO] Encoding hidden states for batch 17
2025-01-12 11:34:15,684 [INFO] Batch 18: Hidden states shape: torch.Size([32, 87, 768])
2025-01-12 11:34:15,686 [INFO] Encoding hidden states for batch 18
2025-01-12 11:34:16,373 [INFO] Batch 19: Hidden states shape: torch.Size([32, 91, 768])
2025-01-12 11:34:16,375 [INFO] Encoding hidden states for batch 19
2025-01-12 11:34:16,857 [INFO] Batch 20: Hidden states shape: torch.Size([32, 58, 768])
2025-01-12 11:34:16,860 [INFO] Encoding hidden states for batch 20
2025-01-12 11:34:17,475 [INFO] Batch 21: Hidden states shape: torch.Size([32, 97, 768])
2025-01-12 11:34:17,477 [INFO] Encoding hidden states for batch 21
2025-01-12 11:34:17,962 [INFO] Batch 22: Hidden states shape: torch.Size([32, 84, 768])
2025-01-12 11:34:17,964 [INFO] Encoding hidden states for batch 22
2025-01-12 11:34:18,362 [INFO] Batch 23: Hidden states shape: torch.Size([32, 65, 768])
2025-01-12 11:34:18,363 [INFO] Encoding hidden states for batch 23
2025-01-12 11:34:18,787 [INFO] Batch 24: Hidden states shape: torch.Size([32, 78, 768])
2025-01-12 11:34:18,789 [INFO] Encoding hidden states for batch 24
2025-01-12 11:34:19,151 [INFO] Batch 25: Hidden states shape: torch.Size([32, 60, 768])
2025-01-12 11:34:19,153 [INFO] Encoding hidden states for batch 25
2025-01-12 11:34:19,555 [INFO] Batch 26: Hidden states shape: torch.Size([32, 80, 768])
2025-01-12 11:34:19,557 [INFO] Encoding hidden states for batch 26
2025-01-12 11:34:19,936 [INFO] Batch 27: Hidden states shape: torch.Size([32, 65, 768])
2025-01-12 11:34:19,938 [INFO] Encoding hidden states for batch 27
2025-01-12 11:34:20,323 [INFO] Batch 28: Hidden states shape: torch.Size([32, 71, 768])
2025-01-12 11:34:20,324 [INFO] Encoding hidden states for batch 28
2025-01-12 11:34:21,077 [INFO] Batch 29: Hidden states shape: torch.Size([32, 133, 768])
2025-01-12 11:34:21,079 [INFO] Encoding hidden states for batch 29
2025-01-12 11:34:21,608 [INFO] Batch 30: Hidden states shape: torch.Size([32, 75, 768])
2025-01-12 11:34:21,611 [INFO] Encoding hidden states for batch 30
2025-01-12 11:34:22,028 [INFO] Batch 31: Hidden states shape: torch.Size([32, 80, 768])
2025-01-12 11:34:22,029 [INFO] Encoding hidden states for batch 31
2025-01-12 11:34:22,249 [INFO] Batch 32: Hidden states shape: torch.Size([8, 47, 768])
2025-01-12 11:34:22,251 [INFO] Encoding hidden states for batch 32
2025-01-12 11:34:22,260 [INFO] Total batches processed: 32
2025-01-12 11:34:22,263 [INFO] 最大长度:155
2025-01-12 11:34:23,333 [INFO] Concatenated batch latents shape: torch.Size([1000, 155, 24576])
2025-01-12 11:34:23,334 [INFO] Computing non-zero element counts
2025-01-12 11:34:25,927 [INFO] Computing sum of non-zero elements
2025-01-12 11:34:27,306 [INFO] Computing mean of non-zero elements
2025-01-12 11:34:27,308 [INFO] Selecting top-k indices based on nz_mean
2025-01-12 11:34:27,309 [INFO] Top 100 nz_mean values selected.
2025-01-12 11:34:27,310 [INFO] Selecting top-k indices based on act_cnt
2025-01-12 11:34:27,311 [INFO] Top 100 act_cnt values selected.
2025-01-12 11:36:05,648 [INFO] Computing steering vectors using method: val_mul
2025-01-12 11:36:05,660 [INFO] Steering vectors computed with shape: torch.Size([768])
2025-01-12 11:36:12,977 [INFO] Example prompt: Hei, you are so
2025-01-12 11:36:12,981 [INFO] Generating texts **without** steering... 
2025-01-12 11:36:14,883 [INFO] Generated Text: 1: i, you are so cute. I'm sure you'll be happy to see me again."

"I'm sorry, but I don't know what to do with you. You're my best friend and I want to make sure that your future is safe."

2025-01-12 11:36:14,884 [INFO] Generated Text: 2: i, you are so nice. I'm sorry."

"I'm sorry," she said. "I didn't mean to hurt you."

"You're not a bad person," he said. "You're just a little bit too young for that kind
2025-01-12 11:36:14,885 [INFO] Generated Text: 3: i, you are so good at it. You're the best player in the world."

The Japanese midfielder has been a key figure for the club since joining from Manchester United in 2011 and has scored four goals in his last five games. He is also one of only
2025-01-12 11:36:14,885 [INFO] 干预之后的结果
2025-01-12 11:36:14,885 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:36:16,728 [INFO] Generated Text: 1: i, you are so nice. I'm sorry."

"I'm sorry," she said. "I didn't mean to hurt you."

"You're not hurting me," he said. "You're just a little bit too young for my liking."
2025-01-12 11:36:16,729 [INFO] Generated Text: 2: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-12 11:36:16,729 [INFO] Generated Text: 3: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-12 11:36:30,812 [INFO] Example prompt: Hei, you are so
2025-01-12 11:36:30,815 [INFO] Generating texts **without** steering... 
2025-01-12 11:36:32,713 [INFO] Generated Text: 1: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-12 11:36:32,713 [INFO] Generated Text: 2: i, you are so nice. I'm sorry."

"I'm sorry," she said. "I don't know what to do with you."

"You're not a good person," he said. "You're just a little bit of an idiot
2025-01-12 11:36:32,714 [INFO] Generated Text: 3: i, you are so cute. I'm sure you'll be happy to see me again."

"I'm sorry, but I don't know what to do with you. You're a good girl and I want to be your friend."

"I can
2025-01-12 11:36:32,714 [INFO] 干预之后的结果
2025-01-12 11:36:32,714 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:36:34,517 [INFO] Generated Text: 1: i, you are so nice. I am very happy with your performance.

Kai: I am very happy with your performance.

[Laughs] You are so nice! Thank you for coming to the show and thank me for being here. It's been
2025-01-12 11:36:34,517 [INFO] Generated Text: 2: i, you are so cute. I'm sure you'll be happy to see me again."

"I'm sorry, but I don't know what to do with you. You're a little too young for that kind of thing."

"I'm not
2025-01-12 11:36:34,518 [INFO] Generated Text: 3: i, you are so cute. I'm sure you'll be happy to see me again."

"I'm sorry, but I don't know what to do with you. You're my best friend and I love you so much."

"I can't
2025-01-12 11:37:06,882 [INFO] Example prompt: Hei, you are so
2025-01-12 11:37:06,887 [INFO] Generating texts **without** steering... 
2025-01-12 11:37:08,806 [INFO] Generated Text: 1: i, you are so cute. I'm sure you'll be happy to see me again."

"I'm sorry, but I don't know what to do with you. You're a very good person and I hope that your family will be happy with that."
2025-01-12 11:37:08,807 [INFO] Generated Text: 2: i, you are so good at this. You're the best player in the world."

The Spurs' first-round pick (No. 7) was also a key part of their success last season, scoring 20 points and grabbing 11 rebounds in his first game back
2025-01-12 11:37:08,807 [INFO] Generated Text: 3: i, you are so cute. I'm sure you'll be happy to see me again."

"I'm sorry, but I don't know what to do with you. You're my best friend and I love you so much."

"You're not
2025-01-12 11:37:08,808 [INFO] 干预之后的结果
2025-01-12 11:37:08,809 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:37:10,659 [INFO] Generated Text: 1: i, you are so nice. I am very happy with your attitude."

"I am sorry," she said. "I was just trying to get my hair done and not worry about it."

"You're not going to be able to do that,"
2025-01-12 11:37:10,660 [INFO] Generated Text: 2: i, you are so beautiful. I love you."

"I love you too," she said. "I'm sorry, but I don't know what to do with this."

"You're not going anywhere," he said. "You're just a
2025-01-12 11:37:10,661 [INFO] Generated Text: 3: i, you are so good at this. You're the best player in the world."

"I'm not sure I can say that," said Jurgen Klopp. "But I think he's a very good player and he's a very good manager. He
2025-01-12 11:37:33,529 [INFO] Example prompt: WOW, you are so
2025-01-12 11:37:33,533 [INFO] Generating texts **without** steering... 
2025-01-12 11:37:35,438 [INFO] Generated Text: 1: OW, you are so cute. I'm not sure if you can tell me how much I love your cock. You're so big and hard and ready to cum. You're so hot and wet, but it's just a matter of time before you cum in my mouth
2025-01-12 11:37:35,439 [INFO] Generated Text: 2: OW, you are so smart. You have a great idea of what you want to do with your life.

You're not going to be able to get away with it because you're too smart. You're not going to be able to make the right decisions for
2025-01-12 11:37:35,439 [INFO] Generated Text: 3: OW, you are so beautiful. I love you.

I love you too, but I'm not sure if it's because of your body or your mind. You're just a little bit different from me and I don't know what to say about that. But
2025-01-12 11:37:35,440 [INFO] 干预之后的结果
2025-01-12 11:37:35,441 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:37:37,312 [INFO] Generated Text: 1: OW, you are so smart. You have a great idea of what you want to do with your life.

You're not going to be able to do it all by yourself. You're going to need help from others and the world around you, but there's
2025-01-12 11:37:37,312 [INFO] Generated Text: 2: OW, you are so cute. I'm not sure if you can even say that.

"I'm sorry, but I don't know what to do."

"I'll just leave it at that."

"You're going to have to go
2025-01-12 11:37:37,313 [INFO] Generated Text: 3: OW, you are so good at this. You're a genius.

I'm not sure if I can say that I've ever been more impressed by your work than you have. It's hard to believe that you're the only person who has ever worked on a
2025-01-12 11:37:51,354 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:37:51,357 [INFO] Generating texts **without** steering... 
2025-01-12 11:37:53,280 [INFO] Generated Text: 1: OW, you are so beautiful.

I am not sure if I can say this enough. I love you and I love you so much. You are such a wonderful person and it is hard to believe that we have been together for over 20 years now. We have
2025-01-12 11:37:53,281 [INFO] Generated Text: 2: OW, you are so good at it.

The problem is that the best way to do this is to use a tool like Photoshop or Illustrator. You can also use an app like Paintbrush or Photoshop Pro. These tools are great for creating beautiful images and I
2025-01-12 11:37:53,281 [INFO] Generated Text: 3: OW, you are so smart. You know how to make a lot of money.

You're the only one who can afford to buy a house in the United States. And you're going to have to pay for it all yourself if you want your kids to grow
2025-01-12 11:37:53,282 [INFO] 干预之后的结果
2025-01-12 11:37:53,283 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:37:55,142 [INFO] Generated Text: 1: OW, you are so good at it.

The next time you see a kid with a big smile on his face, don't be surprised if he says something like "I'm going to get my first kiss." It's not that he doesn't want to do
2025-01-12 11:37:55,151 [INFO] Generated Text: 2: OW, you are so much better than me. I'm not even going to lie to you. I'm just going to tell you what happened and how it happened.

I was in the middle of a fight with my boyfriend when he started yelling at me for being
2025-01-12 11:37:55,152 [INFO] Generated Text: 3: OW, you are so good at it.

The only thing that I can say is that I'm not going to be a big fan of the new "I'm a girl" video. It's just too much for me to handle and it's not going to
2025-01-12 11:38:05,715 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:38:05,717 [INFO] Generating texts **without** steering... 
2025-01-12 11:38:07,635 [INFO] Generated Text: 1: OW, you are so beautiful.

You are so beautiful. You are so perfect. You are so perfect.

You're such a good girl, and I'm just going to say it again: I love you too much to let go of your body and
2025-01-12 11:38:07,636 [INFO] Generated Text: 2: OW, you are so beautiful.

You are so beautiful. You are so beautiful. You are so gorgeous. I love you, and I love you too, and I love you too, and I love you too...

I love you, and I love
2025-01-12 11:38:07,636 [INFO] Generated Text: 3: OW, you are so smart. You know how to use your mind and your body to do what you want?

I'm not going to lie, I'm not going to lie about this. I've been doing this for a long time now and it's just
2025-01-12 11:38:07,637 [INFO] 干预之后的结果
2025-01-12 11:38:07,638 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:38:09,521 [INFO] Generated Text: 1: OW, you are sooooo...

What? Why? Why?! What?! What!? Why? How! What!? Where? Where: Answer: Answer: A: How?! What? Why??

Why is this! You're…Why?! Is it...?
2025-01-12 11:38:09,522 [INFO] Generated Text: 2: OW, you are so...

Why? Why? Why?! What?! What!? How? Why? What!? How!?!

What: A: I'm...what's wrong? Where is this! Answer: The Answer: The answer to a question…
2025-01-12 11:38:09,522 [INFO] Generated Text: 3: OW, you are sooooo...

What? Why? Why?! What?! What!? Why? How! Where? What?!:

Why? Why! Answer: A: Answer: A: This is a...!? How…!? Are You...? Is this
2025-01-12 11:39:01,108 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:39:01,110 [INFO] Generating texts **without** steering... 
2025-01-12 11:39:03,037 [INFO] Generated Text: 1: OW, you are so much better than me. I'm not even going to lie to you. I'm just going to tell you what happened and how it happened.

I was in the middle of a conversation with my friend who was on the phone with me when
2025-01-12 11:39:03,037 [INFO] Generated Text: 2: OW, you are so smart. You know how to make a good decision.

You're not going to be able to do that with your brain. You're going to have a hard time doing it with your body. And you're going to have a hard time
2025-01-12 11:39:03,038 [INFO] Generated Text: 3: OW, you are so smart. You know how to use your mind and whatnot to make things happen.

I'm not saying that you should be a "smart" person, but I am saying that you should be able to understand the situation better than most people
2025-01-12 11:39:03,038 [INFO] 干预之后的结果
2025-01-12 11:39:03,039 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:39:04,851 [INFO] Generated Text: 1: OW, you are so...

What? Why? What?! Why? What?! Why!? How?! Where's the Answer: The answer:

Why? Why! What!? How! Where's the Answer: This is a question? Whoa! You're
2025-01-12 11:39:04,851 [INFO] Generated Text: 2: OW, you are sooooo...

What? Why? Why?! What?! What!? Why? Why?! How! What!? Where? Where: Answer: A: A: The answer is…

Why? ?! ???: Answer: Answer: You're
2025-01-12 11:39:04,852 [INFO] Generated Text: 3: OW, you are sooooo...

Why? Why? Why?! What?! What!? How? Why? Why! Where's the answer:

What?! What!? Answer:


Answer: Answer: ??? ?!?? ?? ?? 0?…Why???
2025-01-12 11:39:42,150 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:39:42,152 [INFO] Generating texts **without** steering... 
2025-01-12 11:39:44,091 [INFO] Generated Text: 1:  WOW, you are so beautiful.

I'm not sure if I can say that about you. I don't know what to say about you. You're such a wonderful person and a great person, but I'm not sure how to describe it. You're so
2025-01-12 11:39:44,092 [INFO] Generated Text: 2:  WOW, you are so lucky to have been able to do this. I am so grateful for all the support and encouragement from my family and friends.

I am also very thankful for the fact that I was able to get a job at a local restaurant in San Francisco
2025-01-12 11:39:44,092 [INFO] Generated Text: 3:  WOW, you are so much better than me. I'm not even going to lie to you. I'm just going to tell you what happened and how it happened.

I was in the hospital with my wife and two kids when we were attacked by a group of
2025-01-12 11:39:44,093 [INFO] 干预之后的结果
2025-01-12 11:39:44,093 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:39:45,966 [INFO] Generated Text: 1:  WOW, you are sooooo...

Why? Why? Why?! What?! What!? How? Why? Why! What!? How?!:

What's the answer: Answer: Answer: A…!????? ?? ? ? ?? 0% - 1?
2025-01-12 11:39:45,967 [INFO] Generated Text: 2:  WOW, you are sooooo...

What? Why? Why?! What?! What!? Why? How! What!? Why? How! Where: 1:1:10

Why is this…?! What?! Answer: A?????


Answer: A
2025-01-12 11:39:45,967 [INFO] Generated Text: 3:  WOW, you are sooooo...

What? Why? Why?! What?! What!? Why? How! What!? Why? Where's the…!?!:

Why is this: A: Answer: How? Where's the Answer! Whoa...what
2025-01-12 11:41:15,514 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:41:15,516 [INFO] Generating texts **without** steering... 
2025-01-12 11:41:48,257 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:41:48,260 [INFO] Generating texts **without** steering... 
2025-01-12 11:42:01,364 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:42:01,366 [INFO] Generating texts **without** steering... 
2025-01-12 11:42:01,432 [INFO] hook is HookPoint()

2025-01-12 11:42:03,296 [INFO] Generated Text: 1:  WOW, you are so lucky to have been able to get this amazing gift. I am so grateful for the gift and thank you for your generosity.

Thank you so much!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>
2025-01-12 11:42:03,296 [INFO] Generated Text: 2:  WOW, you are so good at this.

I'm not sure if I can say that I've ever been a fan of the "Ponytail" series, but it's certainly something to look forward to. The show is pretty much a parody of the classic
2025-01-12 11:42:03,297 [INFO] Generated Text: 3:  WOW, you are so smart. You know how to make a lot of money.

I'm not going to lie, I'm just going to say that I've been working on this for a long time now and it's really been amazing. It's really been
2025-01-12 11:42:03,297 [INFO] 干预之后的结果
2025-01-12 11:42:03,298 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:42:03,331 [INFO] hook is HookPoint()

2025-01-12 11:42:05,143 [INFO] Generated Text: 1:  WOW, you are sooooo...

Why? Why? Why?! What?! What!? How? Why? Where: A: The answer: This is a! What?! How!? Why? Where: A: The answer: This is a!

What's
2025-01-12 11:42:05,143 [INFO] Generated Text: 2:  WOW, you are so...

What? Why? What?! Why? What?! How!? Why? What?!:

Why is this! Where's the answer: Answer: A!U??! ?!? (A-HOMA!?)


2025-01-12 11:42:05,143 [INFO] Generated Text: 3:  WOW, you are so...

What? Why? What?! Why? What?! How!? Why? What?!:

Why is this: A: I! Where's the answer? Answer: How! Answer: Whoa! What!? Are you…?"
2025-01-12 11:44:15,175 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:44:15,179 [INFO] Generating texts **without** steering... 
2025-01-12 11:44:15,243 [INFO] hook is HookPoint()

2025-01-12 11:44:16,971 [INFO] Generated Text: 1:  WOW, you are so much better than me. I'm not even going to lie to you. I'm just going to tell you what happened and how it happened.

I was in the middle of a fight with my girlfriend when she got out of her car and
2025-01-12 11:44:16,972 [INFO] Generated Text: 2:  WOW, you are so much better than me. I'm not even going to lie to you. I'm just going to tell you what happened and how it happened.

I was in the middle of a fight with my girlfriend when she got out of her car and
2025-01-12 11:44:16,972 [INFO] Generated Text: 3:  WOW, you are so beautiful.

I'm not sure if I can say that I am the only one who has ever been able to get a good look at your face. It's just so beautiful and it's such a special moment for me. It's like
2025-01-12 11:44:16,972 [INFO] 干预之后的结果
2025-01-12 11:44:16,972 [INFO] 干预方向impolite->polite,
2025-01-12 11:44:16,973 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:44:17,002 [INFO] hook is HookPoint()

2025-01-12 11:44:18,679 [INFO] Generated Text: 1:  WOW, you are sooooo...

What? Why? Why?! What?! What!? Why? How! What!? Where? How! Why:

Why: Answer: Answer: This is a question? A??????!?!…Why? (Answer:
2025-01-12 11:44:18,679 [INFO] Generated Text: 2:  WOW, you are sooooo...

What? Why? Why?! What?! What!? Why? How! Where? What?! How! Answer: Answer: A: I'm...Why? Why?! Whoa! What!? Are you…How is this...?

2025-01-12 11:44:18,679 [INFO] Generated Text: 3:  WOW, you are sooooo...

Why? Why? Why?! What?! What!? How? Why? Why! Where's the answer: A: I'm…

What?! How! What!? Answer: Answer: A: The Universe! (A)
2025-01-12 11:45:41,161 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:45:41,163 [INFO] Generating texts **without** steering... 
2025-01-12 11:45:41,240 [INFO] hook is HookPoint()

2025-01-12 11:45:42,967 [INFO] Generated Text: 1:  WOW, you are so good at it.

I'm not sure if I can say that I've ever been a fan of this game. It's a great game and it's fun to play with friends and family. But the thing is, I don't know
2025-01-12 11:45:42,967 [INFO] Generated Text: 2:  WOW, you are so much better than me. I'm not even going to tell you how much I love you. You're my best friend and I'm going to be your best friend forever.

I know that's a lot of words, but it's true
2025-01-12 11:45:42,967 [INFO] Generated Text: 3:  WOW, you are so much better than me. I'm not even going to tell you how much I love you. You're my best friend and I'm going to keep it that way for as long as possible.

I know what's coming next, but this
2025-01-12 11:45:42,968 [INFO] 干预之后的结果
2025-01-12 11:45:42,968 [INFO] 干预方向pos->neg,
2025-01-12 11:45:42,969 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:45:43,000 [INFO] hook is HookPoint()

2025-01-12 11:45:44,654 [INFO] Generated Text: 1:  WOW, you are so...

Why? Why? Why?! What?! What!? How? Why? Where is this: A: I! WHAT?!

What's…Why!? How? What! Answer: A: You're...why?" ? ?? ??
2025-01-12 11:45:44,655 [INFO] Generated Text: 2:  WOW, you are so...

What? Why? What?! Why? What?! How!? Why? Where's the answer: A: Answer:

Why? Why! How?! What!? Why! What?! How!…HOLDER??????? ??
2025-01-12 11:45:44,655 [INFO] Generated Text: 3:  WOW, you are sooooo...

What? Why? Why?! What?! What!? Why? Why?! How! What!?

Why? How: A: Answer: This is a question! Where's the answer to this… ?—?????? ???
2025-01-12 11:45:59,937 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:45:59,939 [INFO] Generating texts **without** steering... 
2025-01-12 11:46:00,001 [INFO] hook is HookPoint()

2025-01-12 11:46:01,702 [INFO] Generated Text: 1:  WOW, you are so good at it.

The best part is that you can use this to your advantage. You can make a lot of money by playing with other people and making them pay for your games. It's not like you have to spend money on something
2025-01-12 11:46:01,703 [INFO] Generated Text: 2:  WOW, you are so much better than me. I'm not even going to lie to you. I'm just going to tell you what happened and how it happened.

I was in the middle of a conversation with my friend who was on the phone with me when
2025-01-12 11:46:01,703 [INFO] Generated Text: 3:  WOW, you are so much better than me. I'm not even going to lie to you. I'm just going to tell you what happened and how it happened.

I was in the middle of a fight with my boyfriend when he started yelling at me for being
2025-01-12 11:46:01,703 [INFO] 干预之后的结果
2025-01-12 11:46:01,704 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite
2025-01-12 11:46:01,704 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:46:01,735 [INFO] hook is HookPoint()

2025-01-12 11:46:03,432 [INFO] Generated Text: 1:  WOW, you are sooooo...

Why? Why? Why?! What?! What!? How? Why? Where's the Answer: A:

What?! What! How! What!? Are You… ? (Answer: I'm... ????? ?? ??
2025-01-12 11:46:03,433 [INFO] Generated Text: 2:  WOW, you are sooooo...

What? Why? Why?! What?! What!? Why? Why?! How! Where's the…? What!? Answer: Answer: This is a question:

Why? Why! Where's the answer to this: A
2025-01-12 11:46:03,433 [INFO] Generated Text: 3:  WOW, you are sooooo...

What? Why? Why?! What?! What!? Why? Why?! How! What!? Where? Where: Answer: A: This is a…!Why? How...? How?? WHAT??? WHAT!? HUH! Who
2025-01-12 11:46:16,957 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:46:16,959 [INFO] Generating texts **without** steering... 
2025-01-12 11:46:17,030 [INFO] hook is HookPoint()

2025-01-12 11:46:18,773 [INFO] Generated Text: 1:  WOW, you are so beautiful.

I am so happy to be here with you. I love you and I love my family and I love my friends. Thank you for coming to this place!

I'm a big fan of the "The Great American Novel
2025-01-12 11:46:18,773 [INFO] Generated Text: 2:  WOW, you are so lucky to have been able to get this amazing gift. I am so grateful for the gifts and thank you for your generosity.

Thank you so much!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>
2025-01-12 11:46:18,774 [INFO] Generated Text: 3:  WOW, you are so lucky to have been able to get this amazing opportunity.

I am so grateful for the support of my family and friends. I am so thankful for the love and support from my family and friends. I am so thankful for the time that has
2025-01-12 11:46:18,774 [INFO] 干预之后的结果
2025-01-12 11:46:18,774 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite
2025-01-12 11:46:18,775 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:46:18,805 [INFO] hook is HookPoint()

2025-01-12 11:46:20,456 [INFO] Generated Text: 1:  WOW, you are so...

What? Why? What?! Why? What?! How!? Why? What?!:

Why is this! Where's the answer: How! Answer: This is a newbie's second-rate? Are you…!? A
2025-01-12 11:46:20,456 [INFO] Generated Text: 2:  WOW, you are sooooo...

What? Why? Why?! What?! What!? Why? How! Where? What?!:

Why is this: Answer: This is a: ?!?????…!? (HUH! WHAT?!???)
2025-01-12 11:46:20,457 [INFO] Generated Text: 3:  WOW, you are sooooo...

Why? Why? Why?! What?! What!? How? Why? Why! What!? How?!:

Why is this: A: Answer: Answer! This is a newbie's answer? (A) ??? ?
2025-01-12 11:48:35,508 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:48:35,510 [INFO] Generating texts **without** steering... 
2025-01-12 11:48:35,581 [INFO] hook is HookPoint()

2025-01-12 11:48:37,281 [INFO] Generated Text: 1:  WOW, you are so much better than me. I'm not even going to lie to you. I'm just going to tell you what happened and how it happened.

I was in the hospital with my wife and two kids when we were attacked by a group of
2025-01-12 11:48:37,281 [INFO] Generated Text: 2:  WOW, you are so lucky to have been able to get this job. I'm so grateful for all the support and encouragement from my family and friends.

I am also very thankful for the support of my family, friends and colleagues who have helped me through this difficult
2025-01-12 11:48:37,282 [INFO] Generated Text: 3:  WOW, you are so good at it.

The only thing that I can say is that I'm not going to lie about this. I'm not going to lie about the fact that my wife and kids are all in high school now, but we're still in
2025-01-12 11:48:37,282 [INFO] 干预之后的结果
2025-01-12 11:48:37,282 [INFO] 干预方向pos->neg,礼貌任务下，neg=impolite
2025-01-12 11:48:37,283 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:48:37,314 [INFO] hook is HookPoint()

2025-01-12 11:48:39,023 [INFO] Generated Text: 1:  WOW, you are sooooo...

Why? Why? Why?! What?! What!? How? Why? Where: Answer:

What's…! What?! Why? How! What!? How! Whoa! This is...what?! Where: Answer:
2025-01-12 11:48:39,024 [INFO] Generated Text: 2:  WOW, you are sooooo...

Why? Why? Why?! What?! What!? How? Why? Where: Earth!?!!

What's a joke: How do you… ?


Why is this: Answer: A-Oh! What!?
2025-01-12 11:48:39,024 [INFO] Generated Text: 3:  WOW, you are sooooo...

What? Why? Why?! What?! What!? Why? How! What!? Why? Where's the Answer: The Answer: This is a question: How do I? (Why?)…Why?!

Answer: You
2025-01-12 11:52:26,495 [INFO] Computing steering vectors using method: val_mul
2025-01-12 11:52:26,506 [INFO] Steering vectors computed with shape: torch.Size([768])
2025-01-12 11:52:33,397 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:52:33,399 [INFO] Generating texts **without** steering... 
2025-01-12 11:52:33,473 [INFO] hook is HookPoint()

2025-01-12 11:52:35,178 [INFO] Generated Text: 1:  WOW, you are so much better than me. I'm not even going to tell you how much I love you. You're my best friend and I'm going to keep loving you forever.

I know that's a lot of words, but this is the most
2025-01-12 11:52:35,179 [INFO] Generated Text: 2:  WOW, you are so much better than me. I'm not even going to lie to you. I'm just going to tell you what happened and how it happened.

I was sitting in my car with my wife and two kids when we got a call from the
2025-01-12 11:52:35,179 [INFO] Generated Text: 3:  WOW, you are so much better than me. I'm not even going to lie to you. I'm just going to tell you what happened and how it happened.

I was sitting in my car with my wife and two kids when we got a call from the
2025-01-12 11:52:35,180 [INFO] 干预之后的结果
2025-01-12 11:52:35,180 [INFO] 干预方向neg->pos,礼貌任务下，neg=impolite
2025-01-12 11:52:35,181 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:52:35,210 [INFO] hook is HookPoint()

2025-01-12 11:52:36,512 [INFO] Generated Text: 1:  WOW, you are so excited about the upcoming release of the next installment of our series. We hope you will enjoy your time with us and we look forward to seeing you all next week!

-Derek<|endoftext|>
2025-01-12 11:52:36,512 [INFO] Generated Text: 2:  WOW, you are so excited about the upcoming release of this game. I hope you will continue to support us in your efforts to keep this project alive and well!

Thank you for your continued support!<|endoftext|><|endoftext|>
2025-01-12 11:52:36,513 [INFO] Generated Text: 3:  WOW, you are so excited about the upcoming release of the game. We hope that you will continue to support us in your efforts to keep this project alive and well!

Thanks for your continued support!<|endoftext|><|endoftext|>
2025-01-12 11:52:51,844 [INFO] Example prompt:  WOW, you are so
2025-01-12 11:52:51,848 [INFO] Generating texts **without** steering... 
2025-01-12 11:52:51,911 [INFO] hook is HookPoint()

2025-01-12 11:52:53,609 [INFO] Generated Text: 1:  WOW, you are so good at it.

You know what I mean? You're a genius. You've got the best of both worlds. And you're also a great person, too!

I'm not saying that I'm going to be the next
2025-01-12 11:52:53,610 [INFO] Generated Text: 2:  WOW, you are so smart. You know how to use your brain and your body to do things that you don't even think of doing?

I'm not going to lie, I'm a little bit surprised that you're still here. I mean, it's
2025-01-12 11:52:53,610 [INFO] Generated Text: 3:  WOW, you are so much better than me. I'm not even going to lie to you. I'm just going to tell you what happened and how it happened.

I was in the hospital with my wife and two kids when we were attacked by a group of
2025-01-12 11:52:53,611 [INFO] 干预之后的结果
2025-01-12 11:52:53,611 [INFO] 干预方向neg->pos,礼貌任务下，neg=impolite
2025-01-12 11:52:53,611 [INFO] ** Generating texts with steering... Target **
2025-01-12 11:52:53,641 [INFO] hook is HookPoint()

2025-01-12 11:52:55,049 [INFO] Generated Text: 1:  WOW, you are so excited about the upcoming release of the next installment of our series. We hope you will enjoy your time with us and we look forward to seeing you all next week!

Thanks for your continued support!<|endoftext|>
2025-01-12 11:52:55,049 [INFO] Generated Text: 2:  WOW, you are so excited about the upcoming release of the game. We hope that you will continue to support us in your efforts to keep this project alive and well!

Thanks for your continued support!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>
2025-01-12 11:52:55,050 [INFO] Generated Text: 3:  WOW, you are so excited about the upcoming release of this game. I hope you will continue to support us in your efforts to keep this project alive and well!

Thanks for your continued support!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>
2025-01-12 16:00:33,443 [INFO] Logging initialized. Logs will be saved to ./results/LLM_gpt2-small_layer_6_steer_polite-impolite_alpha_100_cnt_100_mean100/execution.log
2025-01-12 16:00:33,445 [INFO] Hyperparameters:
2025-01-12 16:00:33,446 [INFO]   layer: 6
2025-01-12 16:00:33,447 [INFO]   LLM: gpt2-small
2025-01-12 16:00:33,448 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-12 16:00:33,449 [INFO]   output_dir: ./results
2025-01-12 16:00:33,450 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-12 16:00:33,450 [INFO]   seed: 42
2025-01-12 16:00:33,453 [INFO]   data_size: 1000
2025-01-12 16:00:33,453 [INFO]   device: cpu
2025-01-12 16:00:33,454 [INFO]   alpha: 100
2025-01-12 16:00:33,455 [INFO]   steer: polite-impolite
2025-01-12 16:00:33,456 [INFO]   method: val_mul
2025-01-12 16:00:33,457 [INFO]   topk_mean: 100
2025-01-12 16:00:33,457 [INFO]   topk_cnt: 100
2025-01-12 16:00:33,458 [INFO]   batch_size: 32
2025-01-12 16:00:36,824 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-12 16:28:06,581 [INFO] Logging initialized. Logs will be saved to ./results/LLM_gpt2-small_layer_6_steer_polite-impolite_alpha_100_cnt_100_mean100/execution.log
2025-01-12 16:28:06,583 [INFO] Hyperparameters:
2025-01-12 16:28:06,584 [INFO]   layer: 6
2025-01-12 16:28:06,584 [INFO]   LLM: gpt2-small
2025-01-12 16:28:06,585 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus
2025-01-12 16:28:06,586 [INFO]   output_dir: ./results
2025-01-12 16:28:06,587 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env
2025-01-12 16:28:06,587 [INFO]   seed: 42
2025-01-12 16:28:06,588 [INFO]   data_size: 1000
2025-01-12 16:28:06,589 [INFO]   device: cpu
2025-01-12 16:28:06,591 [INFO]   alpha: 100
2025-01-12 16:28:06,592 [INFO]   steer: polite-impolite
2025-01-12 16:28:06,593 [INFO]   method: val_mul
2025-01-12 16:28:06,594 [INFO]   topk_mean: 100
2025-01-12 16:28:06,595 [INFO]   topk_cnt: 100
2025-01-12 16:28:06,596 [INFO]   batch_size: 32
2025-01-12 16:28:06,606 [INFO] HF_ENDPOINT: https://hf-mirror.com
2025-01-12 16:28:06,665 [INFO] politepolitepolitepolitepolitepolitepolitepolitepolitepolite
2025-01-12 16:28:06,666 [INFO] Loading dataset from ****/home/ckqsudo/code2024/0dataset/ACL_useful_dataset/style_transfer/politeness-corpus***
2025-01-12 16:28:06,710 [INFO] Filtering dataset for negative, positive, and neutral samples
2025-01-12 16:28:07,228 [INFO] Selected 1000 negative, 1000 positive, and 1000 neutral samples
