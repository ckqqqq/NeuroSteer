{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HF_ENDPOINT=https://hf-mirror.com\n",
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# package import\n",
    "from torch import Tensor\n",
    "from transformer_lens import utils\n",
    "from functools import partial\n",
    "from jaxtyping import Int, Float\n",
    "import torch\n",
    "# device setup\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "import plotly_express as px\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# Model Loading\n",
    "\n",
    "from sae_lens.analysis.neuronpedia_integration import get_neuronpedia_quick_list\n",
    "\n",
    "# Virtual Weight / Feature Statistics Functions\n",
    "from sae_lens.analysis.feature_statistics import (\n",
    "    get_all_stats_dfs,\n",
    "    get_W_U_W_dec_stats_df,\n",
    ")\n",
    "\n",
    "# Enrichment Analysis Functions\n",
    "from sae_lens.analysis.tsea import (\n",
    "    get_enrichment_df,\n",
    "    manhattan_plot_enrichment_scores,\n",
    "    plot_top_k_feature_projections_by_token_and_category,\n",
    ")\n",
    "from sae_lens.analysis.tsea import (\n",
    "    get_baby_name_sets,\n",
    "    get_letter_gene_sets,\n",
    "    generate_pos_sets,\n",
    "    get_test_gene_sets,\n",
    "    get_gene_set_from_regex,\n",
    ")\n",
    "import os\n",
    "os.environ['HF_ENDPOINT']=\"https://hf-mirror.com\"\n",
    "# model = HookedTransformer.from_pretrained(\n",
    "#     \"tiny-stories-1L-21M\"\n",
    "# )  # This will wrap huggingface models and has lots of nice utilities.\n",
    "\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\",device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckqsudo/miniconda3/envs/SAE/lib/python3.11/site-packages/sae_lens/sae.py:145: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sae_lens import SAE\n",
    "layer=5\n",
    "\n",
    "gpt2_small_sparse_autoencoders = {}\n",
    "gpt2_small_sae_sparsities = {}\n",
    "\n",
    "\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release=\"gpt2-small-res-jb\",  # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id=f\"blocks.{layer}.hook_resid_pre\",  # won't always be a hook point\n",
    "    device=device\n",
    ")\n",
    "gpt2_small_sparse_autoencoders[f\"blocks.{layer}.hook_resid_pre\"] = sae\n",
    "gpt2_small_sae_sparsities[f\"blocks.{layer}.hook_resid_pre\"] = sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"/home/ckqsudo/code2024/0dataset/emotional_classify/multiclass-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"]= dataset['train'].shuffle(seed=42)  # seed 用于固定随机性\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_text=dataset[\"train\"]# 假设数据集是训练集（train），筛选 labels = 1 的数据\n",
    "neg_train_set = dataset['train'].filter(lambda example: example['label'] == 0).select(range(1000))\n",
    "\n",
    "pos_train_set=dataset['train'].filter(lambda example: example['label'] == 2).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "neu_train_set=dataset['train'].filter(lambda example: example['label'] == 1).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_train_set),len(pos_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('needs someone to explain lambda calculus to him! :(', 'Amazing!!!!')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_train_set[\"text\"][1],pos_train_set[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_point = sae.cfg.hook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_logits, cache = model.run_with_cache(pos_train_set[\"text\"][:1000], prepend_bos=True,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 177, 50257])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hidden_states=cache[hook_point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_hidden_states.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 177, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 2, 1, 3]) torch.Size([2, 3, 4])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义一个三维 Tensor\n",
    "tensor = torch.tensor([\n",
    "    [\n",
    "    [0, 1, 0, 2],\n",
    "    [3, 0, 0, 4],\n",
    "    [0, 0, 0, 0]],\n",
    "\n",
    "                       [[5, 0, 6, 0],\n",
    "                        [0, 7, 0, 8],\n",
    "                        [9, 0, 0, 0]]])\n",
    "\n",
    "# 统计在 A 和 B 两个维度上不为 0 的元素，输出 C 维度的向量\n",
    "nonzero_counts_C = (tensor != 0).sum(dim=(0, 1))\n",
    "# # 1. 统计非零元素的数量\n",
    "# latents_count = (batch_latents != 0).sum(dim=(0, 1))\n",
    "\n",
    "# 打印结果\n",
    "print(nonzero_counts_C,tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import axis\n",
    "import torch\n",
    "batch_latents=[]\n",
    "for data_idx in range(0,batch_hidden_states.shape[0]):\n",
    "    hidden_state=batch_hidden_states[0]\n",
    "    # hidden_state.to(\"cuda\")\n",
    "    latents = sae.encode(hidden_state)\n",
    "    batch_latents.append(latents)\n",
    "batch_latents=torch.stack(batch_latents,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # 定义矩阵\n",
    "# matrix = torch.zeros(4,2)\n",
    "# matrix[2,1]=4\n",
    "# matrix[3,1]=9\n",
    "# matrix[1,0]=-1\n",
    "# # 统计每一列中不为 0 的元素的个数\n",
    "# nonzero_counts = (matrix != 0).sum(dim=0)\n",
    "\n",
    "# # 打印结果\n",
    "# print(nonzero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 177, 24576])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 177, 24576])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 统计非零元素的数量\n",
    "act_cnt = (batch_latents != 0).sum(dim=(0, 1))\n",
    "\n",
    "# 2. 计算非零元素的总和\n",
    "nz_sum = torch.where(batch_latents != 0, batch_latents, torch.tensor(0.0)).sum(dim=(0, 1))\n",
    "\n",
    "# 3. 计算非零元素的均值\n",
    "nz_mean = torch.where(act_cnt != 0, nz_sum / act_cnt, torch.tensor(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(151000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(act_cnt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nz_mean[12555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz_act_val, nz_val_indices= torch.topk(nz_mean, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([519.3588, 400.9080, 388.5621, 319.9220, 282.2983, 231.8186, 204.4063,\n",
       "          52.3016,  47.9561,  41.2254,  40.8973,  36.4871,  33.9533,  33.3195,\n",
       "          32.2983,  30.6149,  27.8049,  26.2022,  22.9452,  21.7568,  19.3381,\n",
       "          19.2138,  19.1500,  18.1030,  17.9155,  16.4459,  13.8892,  13.8246,\n",
       "          13.7617,  12.6209,  12.4772,  12.2763,  12.0794,  11.1112,  11.0233,\n",
       "          10.7947,  10.5119,  10.4058,  10.3053,  10.2840,  10.0442,   9.9688,\n",
       "           9.8907,   9.8810,   9.8516,   9.7237,   9.7208,   9.6545,   9.5016,\n",
       "           9.1099,   8.5513,   8.2379,   8.1908,   8.1376,   8.1075,   7.8428,\n",
       "           7.7397,   7.6669,   7.6608,   7.6127,   6.7918,   6.7808,   6.7535,\n",
       "           6.6709,   6.6701,   6.6061,   6.5835,   6.5640,   6.5369,   6.5007,\n",
       "           6.4865,   6.4255,   6.2286,   6.1316,   6.0690,   5.8662,   5.8205,\n",
       "           5.8132,   5.7220,   5.7059,   5.5783,   5.5024,   5.4399,   5.3980,\n",
       "           5.3934,   5.3803,   5.3785,   5.3189,   5.2563,   5.2008,   5.1204,\n",
       "           5.0026,   5.0001,   4.9386,   4.9214,   4.7961,   4.7688,   4.6039,\n",
       "           4.5651,   4.4890], grad_fn=<TopkBackward0>),\n",
       " tensor([ 1334, 14618, 16949,  4242,  1885, 12411,  1256, 14548,   859, 21614,\n",
       "         13978, 13928, 23393,  3188,   303, 13552, 11355,  4536,  4348, 10466,\n",
       "         15338, 21865, 11217,  5697, 17590,  6417,  3465, 22297,  6108, 14375,\n",
       "         24559,  4776, 21518,  9436, 20599,  6627,  5389,  3932, 23333, 11154,\n",
       "         15622, 10304,  1268, 11066, 12915,   317, 18372, 17268,  6778, 23768,\n",
       "         21189, 21573, 15694, 15583,  1660, 14916, 21211, 12700, 23183,  4166,\n",
       "         18106,  2358,  6648, 13018, 15029,  7135, 11502,  7241, 12773,  2678,\n",
       "          1996, 21819,  4530, 12410,  1371, 19687, 23965, 20688,  6944, 23255,\n",
       "           658, 23866,  9329, 10981, 22668, 16623, 10140,  3829, 14982, 14147,\n",
       "         11945, 15519, 16563, 24223, 14585,  3705,   682, 15627,  7254,  8173]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nz_act_val,nz_val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1334, 14618, 16949,  4242,  1885, 12411,  1256, 14548,   859, 21614,\n",
       "        13978, 13928, 23393,  3188,   303, 13552, 11355,  4536,  4348, 10466,\n",
       "        15338, 21865, 11217,  5697, 17590,  6417,  3465, 22297,  6108, 14375,\n",
       "        24559,  4776, 21518,  9436, 20599,  6627,  5389,  3932, 23333, 11154,\n",
       "        15622, 10304,  1268, 11066, 12915,   317, 18372, 17268,  6778, 23768,\n",
       "        21189, 21573, 15694, 15583,  1660, 14916, 21211, 12700, 23183,  4166,\n",
       "        18106,  2358,  6648, 13018, 15029,  7135, 11502,  7241, 12773,  2678,\n",
       "         1996, 21819,  4530, 12410,  1371, 19687, 23965, 20688,  6944, 23255,\n",
       "          658, 23866,  9329, 10981, 22668, 16623, 10140,  3829, 14982, 14147,\n",
       "        11945, 15519, 16563, 24223, 14585,  3705,   682, 15627,  7254,  8173])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nz_val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz_cnt, cnt_indices = torch.topk(act_cnt, 200)\n",
    "\n",
    "# nonzero_indices = torch.nonzero(latents_count > 0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_indices=nz_val_indices[torch.isin(nz_val_indices,cnt_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overlap_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重复元素: tensor([4, 5]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建两个 Tensor\n",
    "tensor1 = torch.tensor([1, 2, 3, 4, 5])\n",
    "tensor2 = torch.tensor([4, 5, 6, 7, 8,9])\n",
    "\n",
    "# 检查 tensor1 中的元素是否在 tensor2 中\n",
    "mask = torch.isin(tensor1, tensor2)\n",
    "\n",
    "# 提取重复元素\n",
    "intersection = tensor1[mask]\n",
    "\n",
    "# 打印结果\n",
    "print(\"重复元素:\", intersection,mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_acts_by_index(prompt,acts_idx,hook_point):\n",
    "    sv_logits, cache = model.run_with_cache(prompt, prepend_bos=True)\n",
    "    # 转换为对应的令牌表示\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    print(tokens)\n",
    "\n",
    "    # get the feature activations from our SAE 获取特定位置的中间状态,并对中间状态进行编码，得到特征激活\n",
    "    sv_feature_acts = sae.encode(cache[hook_point])\n",
    "    print(sv_feature_acts.shape)\n",
    "    return sv_feature_acts[:,:,acts_idx-1:acts_idx+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24576, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.W_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "method=\"val_mul\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steering_vectors(method):\n",
    "    if method==\"mean\":\n",
    "        steering_vectors=Tensor.mean(sae.W_dec[overlap_indices],axis=0)\n",
    "    elif method==\"val_mul\":\n",
    "        steering_vectors=torch.zeros(768)\n",
    "        for i,important_idx in enumerate(overlap_indices):\n",
    "            assert nz_mean[important_idx]>2\n",
    "            steering_vectors+=nz_mean[important_idx]*sae.W_dec[important_idx]\n",
    "    return steering_vectors\n",
    "            \n",
    "# d_hidden=sae.W_dec.shape[1]\n",
    "# d_latent=sae.W_dec.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_steering_vec=steering_vectors(\"mean\")\n",
    "mul_steering_vec=steering_vectors(\"val_mul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('欧几里得距离', tensor(81.0290, grad_fn=<LinalgVectorNormBackward0>))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"欧几里得距离\",torch.norm(mean_steering_vec - mul_steering_vec, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('余弦', tensor([0.9130], grad_fn=<SumBackward1>))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\"余弦\",F.cosine_similarity(mean_steering_vec.unsqueeze(0), mul_steering_vec.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "注意你最后选择的干预向量 val_mul\n"
     ]
    }
   ],
   "source": [
    "steering_vectors=mul_steering_vec\n",
    "print(\"注意你最后选择的干预向量\",method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "from ast import Raise\n",
    "\n",
    "\n",
    "def steering_hook(resid_pre, hook):\n",
    "    if resid_pre.shape[1] == 1:\n",
    "        return\n",
    "\n",
    "    # position = steer_prompt_id.shape[1]\n",
    "    # raise ValueError(f\"steering{resid_pre.shape}\")\n",
    "    if steering_on:\n",
    "        # using our steering vector and applying the coefficient\n",
    "        # position=steer_prompt_id.shape[-1]\n",
    "        resid_pre[:, :, :] += coeff * steering_vectors\n",
    "\n",
    "\n",
    "def hooked_generate(prompt_batch, fwd_hooks=[], seed=None, **kwargs):\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    with model.hooks(fwd_hooks=fwd_hooks):\n",
    "        tokenized = model.to_tokens(prompt_batch)\n",
    "        result = model.generate(\n",
    "            stop_at_eos=True,  # avoids a bug on MPS\n",
    "            input=tokenized,\n",
    "            max_new_tokens=50,\n",
    "            do_sample=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "    return result\n",
    "def run_generate(example_prompt):\n",
    "    model.reset_hooks()\n",
    "    editing_hooks = [(f\"blocks.{layer}.hook_resid_post\", steering_hook)]\n",
    "    res = hooked_generate(\n",
    "        [example_prompt] * 3, editing_hooks, seed=None, **sampling_kwargs\n",
    "    )# batch=3, e\n",
    "\n",
    "    # Print results, removing the ugly beginning of sequence token\n",
    "    res_str = model.to_string(res[:, 1:])\n",
    "    print((\"\\n\\n\" + \"-\" * 80 + \"\\n\\n\").join(res_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_kwargs = dict(temperature=1.0, top_p=0.5, freq_penalty=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt=neu_train_set[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is listening to the new jonas brothers song'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3793f5a2320423ebd124ada7d3a60ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel like this is a fun little story. I was thinking about this from the start, but then I realized that this one had to be on my to-do list.\n",
      "\n",
      "It's not as if there's a huge amount of extra work involved\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "I feel like this article is a reflection of the lack of support I've received for this project. It has become my default site, and I'm very disappointed in it.\n",
      "\n",
      "What I've been able to accomplish so far is just to build something that\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "I feel like this is a really good way to do it. I just don't have any of the time or energy for it.\n",
      "\n",
      "The last thing I want is to be distracted from my day-to-day life and focus on other things,\n"
     ]
    }
   ],
   "source": [
    "steering_on=False\n",
    "example_prompt=\"I feel\"\n",
    "coeff=0\n",
    "run_generate(example_prompt=example_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67c4957911e404eb12e1ca91d8451ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feelShare is in a state of flux and should be up for renewal, so if you're interested in seeing the band return to its roots, you can get your hands on their new album from December 11th.\n",
      "\n",
      "See more music news and reviews\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "I feelThe least bit guilty for what I did, but I've got a message for you guys. The first thing that happened to me was when someone posted on the comments section of this thread about my wife and how much she loves her man. My wife\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "I feelPosted\n",
      "\n",
      "\"Worse than the fire and the death of my children, where can I find an excuse to call them 'themselves' again?\"\n",
      "\n",
      "\n",
      "When asked about his time in prison, he replied \"You know, we're all\n"
     ]
    }
   ],
   "source": [
    "steering_on=True\n",
    "# example_prompt=\"hey! I feel\"\n",
    "coeff=10\n",
    "run_generate(example_prompt=example_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
