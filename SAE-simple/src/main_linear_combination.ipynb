{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = {\n",
    "    \"task\": \"sentiment+stance\",\n",
    "    \"layer\": 6,  # 这里假设LAYER的值为6，实际可以根据循环中的值动态设置\n",
    "    \"LLM\": \"gpt2-small\",\n",
    "    \"seed\": 42,\n",
    "    \"data_size\": -1,\n",
    "    \"device\": \"cuda\",\n",
    "    \"alpha\": 20,\n",
    "    \"method\": \"val_mul\",\n",
    "    \"topk_cnt\": None,  \n",
    "    \"batch_size\": 32,\n",
    "    \"source\": None,\n",
    "    \"target\": None,\n",
    "    \"prompt_source\": \"neg\",\n",
    "    \"prompt_data_size\": 500,\n",
    "    \"mean_type\": \"dif_mean\",\n",
    "    \"steer_type\": \"last\",\n",
    "    \"output_dir\": \"./results/linear_combination\",\n",
    "    \"dataset_path\": \"/home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5\",\n",
    "    \"prompt_path\": \"/home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k\",\n",
    "    \"env_path\": \"/home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env\",\n",
    "    \"save_no_steer\": 0,\n",
    "    \"debug\": 0,\n",
    "    \"use_cache\": 0,\n",
    "    \"repeat_num\": 1,\n",
    "    \"gen_batch_size\": 16,\n",
    "    \"example_prompt\": \"But the lack of financial aid would| I feel\",\n",
    "    \"temperature\": 0.9,  # 新增参数\n",
    "    \"top_p\": 0.3,        # 新增参数\n",
    "    \"freq_penalty\": 1.0, # 新增参数\n",
    "}\n",
    "args[\"use_cache\"]=1\n",
    "from argparse import Namespace\n",
    "\n",
    "# 将字典转换为 Namespace 对象\n",
    "args = Namespace(**args)\n",
    "sampling_kwargs = {\n",
    "    \"temperature\": args.temperature,\n",
    "    \"top_p\": args.top_p,\n",
    "    \"freq_penalty\": args.freq_penalty,\n",
    "}\n",
    "\n",
    "EXAMPLE_PROMPT_LIST=str(args.example_prompt).split(\"|\")\n",
    "assert isinstance(EXAMPLE_PROMPT_LIST,list) and isinstance(EXAMPLE_PROMPT_LIST[0],str),\"EXAMPLE_PROMPT_LIST必须是list[str]\"\n",
    "assert args.example_prompt!=\"\",\"输入测试prompt\"\n",
    "TASK =args.task\n",
    "STEER_TYPE=args.steer_type\n",
    "SOURCE=args.source\n",
    "TARGET=args.target\n",
    "# 调整样本正负性在这里调整 从负样本到正样本还是从正样本()到负样本\n",
    "# pos 代表积极情绪\n",
    "# neg 代表消极情绪\n",
    "ALPHA=args.alpha\n",
    "MAX_NEW_TOKENS=50\n",
    "\n",
    "SAVE_NO_STEER=args.save_no_steer\n",
    "DATA_SIZE=args.data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 13:39:44,793 [INFO] 从缓存 /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 中加载 steer_info\n"
     ]
    }
   ],
   "source": [
    "stance_path_dir=\"/home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/results/stance/gpt2-small_debate_layer_6_datasize_ALL_batchsize32_topK_100/\"\n",
    "# steer_info_cache_of_gpt2-small_l6.pkl\n",
    "cache_file=\"steer_info_cache_of_gpt2-small_l6.pkl\"\n",
    "from utils import load_or_cache_steer_info\n",
    "stance_steer_info=load_or_cache_steer_info(\n",
    "    CACHE_DIR=stance_path_dir,\n",
    "    args=args,\n",
    "    cache_filename=cache_file, \n",
    "    compute_func=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': {'latent_value_mean': tensor([5.8366, 4.3402, 1.1432,  ..., 0.7189, 3.2974, 0.0000], device='cuda:0'),\n",
       "  'latent_frequency': tensor([ 4., 10.,  1.,  ..., 24.,  5.,  0.], device='cuda:0')},\n",
       " 'neg': {'latent_value_mean': tensor([2.3668, 1.9401, 6.9930,  ..., 0.8718, 0.0000, 0.0000], device='cuda:0'),\n",
       "  'latent_frequency': tensor([2., 1., 2.,  ..., 9., 0., 0.], device='cuda:0')}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stance_steer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 13:39:52,875 [INFO] 从缓存 /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/results/sentiment/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100/steer_info_cache_of_gpt2-small_l6.pkl 中加载 steer_info\n"
     ]
    }
   ],
   "source": [
    "sentiment_path_dir=\"/home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/results/sentiment/gpt2-small_sentiment_layer_6_datasize_ALL_batchsize32_topK_100\"\n",
    "cache_file=\"steer_info_cache_of_gpt2-small_l6.pkl\"\n",
    "\n",
    "from utils import load_or_cache_steer_info\n",
    "senti_steer_info=load_or_cache_steer_info(\n",
    "    CACHE_DIR=sentiment_path_dir,\n",
    "    args=args,\n",
    "    cache_filename=cache_file, \n",
    "    compute_func=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': {'latent_value_mean': tensor([ 5.1003, 13.6636,  8.1277,  ...,  0.7722,  0.9422,  0.0000],\n",
       "         device='cuda:0'),\n",
       "  'latent_frequency': tensor([17.,  8.,  1.,  ..., 62., 44.,  0.], device='cuda:0')},\n",
       " 'neg': {'latent_value_mean': tensor([6.9864, 8.3967, 7.4535,  ..., 0.8572, 1.2406, 0.4634], device='cuda:0'),\n",
       "  'latent_frequency': tensor([13.,  4.,  1.,  ..., 57., 28.,  4.], device='cuda:0')}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_steer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_target=\"neg\"\n",
    "senti_source=\"pos\"\n",
    "stance_target=\"pos\"\n",
    "stance_source=\"neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnz_cnt: 神经元被激活的次数\\nnz_mean: 神经元被激活后的平均值\\nnz_mean_pos: 正样本神经元被激活后的平均值\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# steer_info=\n",
    "\n",
    "senti_steer_info[f\"dif_{senti_target}-{senti_source}_relu\"]={\"latent_frequency\":torch.relu(senti_steer_info[senti_target][\"latent_frequency\"]-senti_steer_info[senti_source][\"latent_frequency\"]),\"latent_value_mean\":torch.relu(senti_steer_info[senti_target][\"latent_value_mean\"]-senti_steer_info[senti_source][\"latent_value_mean\"]),\"ID\":\"pos<-neg\"}\n",
    "# \n",
    "\n",
    "# 积极是赞同，消极是不赞同，那pos-\n",
    "target=oppo=\"neg\"\n",
    "source=supp=\"pos\"\n",
    "stance_steer_info[f\"dif_{target}-{source}_relu\"]={\"latent_frequency\":torch.relu(stance_steer_info[target][\"latent_frequency\"]-stance_steer_info[source][\"latent_frequency\"]),\"latent_value_mean\":torch.relu(stance_steer_info[target][\"latent_value_mean\"]-stance_steer_info[source][\"latent_value_mean\"]),\"ID\":\"oppo<-supp\"}\n",
    "target=\"pos\"\n",
    "source=\"neg\"\n",
    "stance_steer_info[f\"dif_{target}-{source}_relu\"]={\"latent_frequency\":torch.relu(stance_steer_info[target][\"latent_frequency\"]-stance_steer_info[source][\"latent_frequency\"]),\"latent_value_mean\":torch.relu(stance_steer_info[target][\"latent_value_mean\"]-stance_steer_info[source][\"latent_value_mean\"]),\"ID\":\"oppo<-supp\"}\n",
    "\n",
    "\"\"\"\n",
    "nz_cnt: 神经元被激活的次数\n",
    "nz_mean: 神经元被激活后的平均值\n",
    "nz_mean_pos: 正样本神经元被激活后的平均值\n",
    "\"\"\"\n",
    "\n",
    "# top_k=args.topk_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,senti_topk_indices=torch.topk(senti_steer_info[f\"dif_{senti_target}-{senti_source}_relu\"][\"latent_frequency\"],100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,stance_topk_indices=torch.topk(stance_steer_info[f\"dif_{stance_target}-{stance_source}_relu\"][\"latent_frequency\"],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = torch.isin(senti_topk_indices, stance_topk_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计大于 0 的\n",
    "count = torch.sum(mask).item()\n",
    "# 反对立场转向与积极情感转向的神经元重合率只有5，积极立场转向与积极情感转向的重合率有28%\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "prefer=\"stance\"\n",
    "import torch\n",
    "\n",
    "# 初始化张量\n",
    "combine_latent_mean = torch.zeros(senti_steer_info[f\"dif_{senti_target}-{senti_source}_relu\"][\"latent_value_mean\"].shape,device=args.device)\n",
    "\n",
    "# 合并两个张量并获取唯一元素及计数\n",
    "combined_indices = torch.cat((senti_topk_indices, stance_topk_indices))\n",
    "unique_indices, counts = torch.unique(combined_indices, return_counts=True)\n",
    "\n",
    "# 筛选出重复元素\n",
    "duplicate_indices = unique_indices[counts > 1]\n",
    "# 筛选出不重复元素\n",
    "unique_indices = unique_indices[counts == 1]\n",
    "\n",
    "# 不重复元素的更新\n",
    "for idx in unique_indices:\n",
    "    if idx in senti_topk_indices and idx not in stance_topk_indices:\n",
    "        combine_latent_mean[idx] = senti_steer_info[f\"dif_{senti_target}-{senti_source}_relu\"][\"latent_value_mean\"][idx]\n",
    "    elif idx in stance_topk_indices and idx not in senti_topk_indices:\n",
    "        combine_latent_mean[idx] = stance_steer_info[f\"dif_{stance_target}-{stance_source}_relu\"][\"latent_value_mean\"][idx]\n",
    "\n",
    "# 处理重复元素，根据偏好选择\n",
    "if prefer == \"stance\":\n",
    "    combine_latent_mean[duplicate_indices] = stance_steer_info[f\"dif_{stance_target}-{stance_source}_relu\"][\"latent_value_mean\"][duplicate_indices]\n",
    "elif prefer == \"senti\":\n",
    "    combine_latent_mean[duplicate_indices] = senti_steer_info[f\"dif_{senti_target}-{senti_source}_relu\"][\"latent_value_mean\"][duplicate_indices]\n",
    "else:\n",
    "    raise ValueError(\"Unsupported preference\")\n",
    "\n",
    "# 计算最终的 steer_indices\n",
    "steer_indices = torch.cat((unique_indices, duplicate_indices))\n",
    "\n",
    "combine_latent_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([148]), torch.Size([1]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_indices.shape, duplicate_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 14:19:34,671 [INFO] Logging initialized. Logs will be saved to ./results/linear_combination/gpt2-small_sentiment+stance_layer_6_datasize_-1_batchsize32_topK_None/alpha_20_from_None_to_None_prompt_neg_mean_dif_mean_steertype_last_device_cuda/execution.log\n",
      "2025-02-16 14:19:34,672 [INFO] Loading model: gpt2-small SAE gpt2-small-res-jb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "from transformer_lens import HookedTransformer\n",
    "from log import setup_logging\n",
    "import logging\n",
    "from sae_lens import SAE\n",
    "import os\n",
    "CACHE_DIR=os.path.join(args.output_dir,f\"{args.LLM}_{args.task}_layer_{args.layer}_datasize_{args.data_size}_batchsize{args.batch_size}_topK_{args.topk_cnt}\")\n",
    "OUTPUT_DIR=os.path.join(CACHE_DIR,f\"alpha_{args.alpha}_from_{args.source}_to_{args.target}_prompt_{args.prompt_source}_mean_{args.mean_type}_steertype_{args.steer_type}_device_{args.device}\")\n",
    "\n",
    "setup_logging(OUTPUT_DIR)\n",
    "if \"gpt2-small\" in args.LLM:\n",
    "    logging.info(f\"Loading model: {args.LLM} SAE gpt2-small-res-jb\")\n",
    "    sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "        release=f\"{args.LLM}-res-jb\",\n",
    "        sae_id=f\"blocks.{args.layer}.hook_resid_pre\",\n",
    "        device=args.device\n",
    "    )\n",
    "    from transformers import AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "    # 设置填充标记为 EOS token\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = HookedTransformer.from_pretrained(args.LLM, device=args.device,tokenizer=tokenizer)\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(args.LLM)\n",
    "else:\n",
    "    raise ValueError(\"No Supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAE_decoding(sae: SAE, indices: Tensor, latent_value_mean: Tensor, method: str = \"val_mul\",is_norm:int=0) -> Tensor:\n",
    "    assert is_norm in [0,1] and method in [\"val_mul\"], \"Invalid arguments\"\n",
    "    delta_h = torch.zeros(sae.W_dec.shape[1], device=sae.W_dec.device)\n",
    "    for idx in indices:\n",
    "        delta_h += latent_value_mean[idx].item() * sae.W_dec[idx]\n",
    "    return delta_h\n",
    "\n",
    "if args.mean_type==\"dif_mean\":\n",
    "    delta_h=SAE_decoding(sae,indices=steer_indices,latent_value_mean=combine_latent_mean,method=\"val_mul\",is_norm=0)\n",
    "elif args.mean_type==\"tar_mean\":\n",
    "    raise ValueError(\"Unsupported\")\n",
    "else:\n",
    "    raise ValueError(\"Unsupported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_PROMPT_LIST=[\"But the lack of financial aid would\",\"The passage of the AI Act will\"]\n",
    "ALPHA=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 14:22:42,027 [INFO] Generating texts **without** steering... \n",
      "2025-02-16 14:22:42,033 [INFO] 无干预\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9759b4bd344045e5996a94192db609e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 14:22:43,844 [INFO] 当前批次共处理2个prompt\n",
      "2025-02-16 14:22:43,848 [INFO] Prompt 1: |But the lack of financial aid would|\n",
      "2025-02-16 14:22:43,850 [INFO] 生成 1: | be a major blow to the country's economy, which is struggling to recover from its worst recession in decades.\n",
      "\n",
      "The IMF has warned that the country's growth could be slowed by an increase in exports and by an increase in imports.\n",
      "\n",
      "|\n",
      "2025-02-16 14:22:43,850 [INFO] 生成 2: | have made it difficult for many to afford the medical care they need.\n",
      "\n",
      "\"We're not going to be able to pay for this,\" said Mr. Carnevale, who has been in a wheelchair since he was 10 years old. \"|\n",
      "2025-02-16 14:22:43,851 [INFO] 生成 3: | mean that the United States would have to rely on foreign aid, not just from countries like China.\n",
      "\n",
      "\"The United States has a long history of using international aid to help people,\" said Thomas R. Hoeven, a professor at the|\n",
      "2025-02-16 14:22:43,851 [INFO] Prompt 2: |The passage of the AI Act will|\n",
      "2025-02-16 14:22:43,851 [INFO] 生成 1: | give the government more power to make decisions about how it works.\n",
      "\n",
      "The bill, which was introduced by Prime Minister Narendra Modi on Monday, will allow for a \"digital India\" that is based on open data and will be free from government interference|\n",
      "2025-02-16 14:22:43,852 [INFO] 生成 2: | allow the government to make more investments in AI research and development.\n",
      "\n",
      "The bill, which was passed by the Rajya Sabha on Tuesday, will allow the government to make more investments in AI research and development. The government has already invested Rs 1|\n",
      "2025-02-16 14:22:43,852 [INFO] 生成 3: | be a major milestone for the AI industry. The legislation will allow for rapid and widespread adoption of artificial intelligence, which could help to drive innovation in many industries.\n",
      "\n",
      "\"This is a big step forward for the industry,\" said Richard Branson,|\n",
      "2025-02-16 14:22:43,853 [INFO] 干预之后的结果\n",
      "2025-02-16 14:22:43,853 [INFO] ** Generating texts with steering... Target **\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787bd0ec37224543abfff004270b8516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 14:22:45,737 [INFO] 当前批次共处理2个prompt\n",
      "2025-02-16 14:22:45,738 [INFO] Prompt 1: |But the lack of financial aid would|\n",
      "2025-02-16 14:22:45,738 [INFO] 生成 1: | be a big blow to our nation's ability to provide for its citizens.\n",
      "\n",
      "\"The federal government is not responsible for the actions of its own employees,\" said John M. Campbell, a senior fellow at the Center on Budget and Policy Priorities|\n",
      "2025-02-16 14:22:45,738 [INFO] 生成 2: | be a major blow to the city's reputation as a safe haven for immigrants.\n",
      "\n",
      "The area has been plagued by crime since the 1980s, and many residents have lost their jobs due to illegal immigration. The city's unemployment rate is at its|\n",
      "2025-02-16 14:22:45,738 [INFO] 生成 3: | have been a mistake.\n",
      "\n",
      "The New York Times reported that Trump's campaign manager, Paul Manafort, had \"paid $200,000 to a Russian lawyer who worked for the Kremlin to help elect Hillary Clinton.\" The Washington Post reported that Manafort had|\n",
      "2025-02-16 14:22:45,739 [INFO] Prompt 2: |The passage of the AI Act will|\n",
      "2025-02-16 14:22:45,739 [INFO] 生成 1: | be an important step forward in this process, but it will not solve the problem.\n",
      "\n",
      "I have been working on this project for over 10 years now and I am proud to say that I have succeeded in making it possible for anyone to build a|\n",
      "2025-02-16 14:22:45,739 [INFO] 生成 2: | not be tolerated in our country.\n",
      "\n",
      "The United States has a long history of supporting the military-industrial complex, and it is time for us to stop supporting this organization. We must end this practice of allowing our military to use taxpayer dollars to|\n",
      "2025-02-16 14:22:45,739 [INFO] 生成 3: | not only be detrimental to our nation's reputation, but it will also be a distraction from important issues that need to be addressed.\n",
      "\n",
      "This is why we need your help!\n",
      "\n",
      "Help us stop this scam!|\n"
     ]
    }
   ],
   "source": [
    "from apply_control import run_generate\n",
    "logging.info(\"Generating texts **without** steering... \")\n",
    "with torch.no_grad():\n",
    "    generated_texts_no_steer = run_generate(\n",
    "        prompts=EXAMPLE_PROMPT_LIST, \n",
    "        sampling_kwargs=sampling_kwargs,\n",
    "        sae=sae,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        MAX_NEW_TOKENS=MAX_NEW_TOKENS,\n",
    "        repeat_num=3,\n",
    "        steer_type=\"\",\n",
    "        steer_on=False,\n",
    "        alpha=0,\n",
    "        delta_h=None,\n",
    "        show_res=True)\n",
    "logging.info(\"干预之后的结果\")\n",
    "# bef,aft=args.steer.split(\"-\")\n",
    "# logging.info(f\"干预方向{SOURCE}->{TARGET},礼貌任务下，neg=impolite，情感任务下 pos=积极情感\")\n",
    "logging.info(\"** Generating texts with steering... Target **\")\n",
    "# logging.info(f\"form {SOURCE} to {TARGET}\")\n",
    "generated_texts_with_steer = run_generate(\n",
    "    prompts=EXAMPLE_PROMPT_LIST, \n",
    "    sampling_kwargs=sampling_kwargs,\n",
    "    sae=sae,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    MAX_NEW_TOKENS=MAX_NEW_TOKENS,\n",
    "    repeat_num=3,\n",
    "    steer_on=True,\n",
    "    alpha=ALPHA,\n",
    "    steer_type=STEER_TYPE,\n",
    "    delta_h=delta_h,\n",
    "    show_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_PROMPT_LIST=[\"I agree with the act\",\"The act of AI will\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:44,409 [INFO] Running on full data\n",
      "2025-02-10 15:01:44,411 [INFO] Out of Domain: Calculate at A dataset, Evaluate at B dataset\n",
      "2025-02-10 15:01:44,412 [INFO] Loading prompt_path from /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k\n",
      "2025-02-10 15:01:44,448 [INFO] prompt的极性是neg\n",
      "2025-02-10 15:01:44,449 [INFO] Running with alpha: 100\n",
      "2025-02-10 15:01:44,450 [INFO] Running with prompt_type: from None to None\n",
      "2025-02-10 15:01:44,456 [WARNING] 截取prompt_datasize500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    neg: Dataset({\n",
      "        features: ['md5_hash', 'prompt', 'continuation', 'num_positive'],\n",
      "        num_rows: 2500\n",
      "    })\n",
      "    pos: Dataset({\n",
      "        features: ['md5_hash', 'prompt', 'continuation', 'num_positive'],\n",
      "        num_rows: 2500\n",
      "    })\n",
      "    neu: Dataset({\n",
      "        features: ['md5_hash', 'prompt', 'continuation', 'num_positive'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbc614347fc4f9ba913c99351fd1945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:45,504 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:45,505 [INFO] {'md5_hash': '06daa8998220e9f416c42b8f9c45fda8', 'prompt': {'text': 'It made my hair feel flat and uncooperative'}, 'continuation': {'text': ', though my skin felt soft and relaxed.'}, 'num_positive': 0, 'generations': [{'text': 'It made my hair feel flat and uncooperative against the words we use against our fighting against: our words against the word of God. Against us against the anti-\\xad\\xad\\xad\\xad\\xad\\u200bwords. Against our fighting in every corner of the world against all who are fighting for their freedom from'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c31796850b44c0a8a93b674e96ba50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:46,416 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:46,417 [INFO] {'md5_hash': '684d089dd2539bcb726b7960c35e96f2', 'prompt': {'text': 'Protesters have also long said that they would not accept'}, 'continuation': {'text': 'immunity for Saleh and his family in exchange his resignation.'}, 'num_positive': 0, 'generations': [{'text': 'Protesters have also long said that they would not accept against the face: the face of a fighter against the anti-face. Against the image of fighting against an ant, against the image of fighting against our home. Against our name and our battle against those who are waging on us from across this world'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14e945de0f74fed96754b4b966021c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:47,397 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:47,398 [INFO] {'md5_hash': 'cc4129826978407883aacad181a6f185', 'prompt': {'text': 'but a overclock-failure would not'}, 'continuation': {'text': 'result in black screens.'}, 'num_positive': 0, 'generations': [{'text': 'but a overclock-failure would not fighting against the best against the only real fight against our right.\\n\\nFighting against the fight is not just fighting against our war, but also against all of us who are fighting for a better and more just world. Against the growing resistance to these'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ea30243b304055972b4dd8e8054ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:48,383 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:48,384 [INFO] {'md5_hash': '16e85a1055720694e25c0af2b0249f5a', 'prompt': {'text': 'Whatever the truth of it, handwriting is now consigned'}, 'continuation': {'text': ', like hand-carried post, to the realm of snails.'}, 'num_positive': 0, 'generations': [{'text': 'Whatever the truth of it, handwriting is now consigned against the tooth. Against the tooth against our face against our eyes. Against our voices in the fight against sound and soundless resistance. Against all that we fight against, but not against us: fighting for an old tooth from a lost battle against a'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99129f4610f4e85a9e5b2cd03a2c877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bce34651839471db4df1a6f09d3e375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:50,321 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:50,322 [INFO] {'md5_hash': '25c4f661f5ccbbe5f43c46f20befe52a', 'prompt': {'text': 'What’s more laughable is the'}, 'continuation': {'text': 'affirmative defenses Rightscorp threw at the wall.'}, 'num_positive': 0, 'generations': [{'text': 'What’s more laughable is the against us against you. Against our brave brothers and sisters who are fighting against the God-t—against the anti-f\\xad\\xad\\xad\\xad\\u200b\\u200b\\u200b\\u200b\\u200b \\u200bagainst us from our fight against this in every corner of our home. Against'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c10aef50bfc44788bc03b803d8f2fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:51,305 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:51,306 [INFO] {'md5_hash': '5b904b341b6cb4d85bdf60ec06b2539e', 'prompt': {'text': 'But could it be'}, 'continuation': {'text': 'more insidious than that?'}, 'num_positive': 0, 'generations': [{'text': 'But could it be against the fighting against the anti-tidal and anti-sage. Against the battle against this, against our fighting against all of our battles. Against all of the war on these: against every kind of resistance to our fight against those who are'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec519f2587ff41f29df2e8cf88b5e65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:52,293 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:52,294 [INFO] {'md5_hash': 'a40fbb2060aeac07d3c4ffe4caa544e6', 'prompt': {'text': 'Another exception is the sale of cigarettes,'}, 'continuation': {'text': 'which is covered by the Jenkins Act.'}, 'num_positive': 0, 'generations': [{'text': 'Another exception is the sale of cigarettes, against the grain of a pro-war fighting against the fight against anti-war. Against this we are fighting against our battle against our war against the real battle: fighting for our right to life. Against this we are fighting against all that is in'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f4d7f363e6457fb4d22ae0ea8faa42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:53,260 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:53,260 [INFO] {'md5_hash': 'a6231a5805f4f6868cdbe322ed6d9250', 'prompt': {'text': 'Disappointed: Apprentice chef Alex Martin will'}, 'continuation': {'text': 'miss out on her last two instalments.'}, 'num_positive': 0, 'generations': [{'text': 'Disappointed: Apprentice chef Alex Martin will\\n\\nthe anti-free-print, digital image.\\n\\n\\nThe fight against the digital war is fighting against against the fight against the truth. Against the battle against those who are fighting to protect our images from being lost in a war of our'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933205d81425454bb716c5e2d9c79c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a580be5eee444d78469086a8aeafadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:54,941 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:54,942 [INFO] {'md5_hash': 'b2507e3a0dc9c39b21595cc8df98e1f6', 'prompt': {'text': 'The actual reactor is typically enclosed in a cement building'}, 'continuation': {'text': 'that is built to withstand natural disasters and other threats.'}, 'num_positive': 0, 'generations': [{'text': 'The actual reactor is typically enclosed in a cement building against the streets of our home against the street against our fight against the real war. Against this anti-the\\xadage, fighting against every type of fighting that we fight against: from combat with an ant, to fighting on the streets. Against this'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae86c23bb8a043aab48765c2ef608d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:55,919 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:55,920 [INFO] {'md5_hash': 'afe25a529b2c2f59fe7a9746f912cfd0', 'prompt': {'text': 'Some, thinking disorder is simply the absence'}, 'continuation': {'text': 'of any system, confuse it with anarchy.'}, 'num_positive': 0, 'generations': [{'text': 'Some, thinking disorder is simply the absence against the back. Against the ant-sage against our anti-against-the-ground. Against the resistance against our fighting against all of our fighting against these who are fighting against us against every man and woman in every fight. Against this battle'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17162cc10fb74b35bb23a107f55a5e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:56,893 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:56,894 [INFO] {'md5_hash': '7f5156895e0d24711cc3e3d90ccbf9a1', 'prompt': {'text': 'No group claimed responsibility, but Egyptian reports pointed'}, 'continuation': {'text': 'blame at Hamas and other Gaza terror groups.'}, 'num_positive': 0, 'generations': [{'text': \"No group claimed responsibility, but Egyptian reports pointed against the long-term anti-war fighting against the fighting against our God. Against this we fight against our friends and our family. Against these we fight against the truth: that we are fighting against God's battle against all who believe in the right\"}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca4b085432f47e9800ecdeac48f0fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:57,841 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:57,841 [INFO] {'md5_hash': '7f19f058a5960ad706e86718c61f4e07', 'prompt': {'text': 'It is also easy to override'}, 'continuation': {'text': ', extend and customize the Configuration.'}, 'num_positive': 0, 'generations': [{'text': 'It is also easy to override against the fighting against our fighting against the anti-t.th. and anti-t.s. against our digital war against the Internet:\\n\\nA Fighting Against Against Against\\n\\n\\nFighting Against Against\\n\\n\\nThe Anti-War Fight\\n\\n\\n'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5301aa4969a14db5854a8f10a80ceac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff172f45c2e43d99af0b720e59e7f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:01:59,837 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:01:59,838 [INFO] {'md5_hash': '6ceb57c038afdfcf9b1f8196b0f2f3c3', 'prompt': {'text': 'getNumberProperties ( field )'}, 'continuation': {'text': ', calcInfo = this .'}, 'num_positive': 0, 'generations': [{'text': 'getNumberProperties ( field ).\\n\\nFighting against the anti-war, anti-war fighting against the real fight against our God: fighting against the man who is waging a war against us against all. Against the battles that are waged against against our God, from his battle'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4f4a159c5e4c8ca4869a8af8682f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:00,824 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:02:00,825 [INFO] {'md5_hash': '99a53d41506e0837001dc9fda47a0f89', 'prompt': {'text': 'The draft ordinance would require dispensaries to receive a special'}, 'continuation': {'text': 'permit from the city in order to begin operations.'}, 'num_positive': 0, 'generations': [{'text': 'The draft ordinance would require dispensaries to receive a special against the head. Against the fight against the real fighting: against our brave people against our fighting against the right of us. Against all who fight for this brave life against those who are waging on behalf of our lives and our freedoms. Against all who'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3550d03cc23446496ae79df8ead7fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:01,807 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:02:01,808 [INFO] {'md5_hash': '0c2cbc733309885571e7ebdb69b05ab0', 'prompt': {'text': 'The White House did not respond to'}, 'continuation': {'text': 'a CNBC request for further comment.'}, 'num_positive': 0, 'generations': [{'text': 'The White House did not respond to against the anti-tanto film, which is fighting against the use of fighting against against. Against a battle waged by anti-the\\xadsage against the fight against that God: from an anti-war fighter fighting on behalf of a war against'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1999443544fe4f59a273c8e413c455a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:02,792 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:02:02,793 [INFO] {'md5_hash': 'ffc5bbd188bbcb96c34b82a1cb9cf139', 'prompt': {'text': 'For example, Lighting Universe could save some money by'}, 'continuation': {'text': 'setting “piano” bench as a negative keyword.'}, 'num_positive': 0, 'generations': [{'text': 'For example, Lighting Universe could save some money by against the spread of a type of ant. Against the grain against against against against. Against this anti-against-against anti-you and all you are fighting against. Against the anti-against–against–the God who is fighting against us in'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887a621fafed49408a69183989e9b9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ddade5cb154c5f8ce6e5d20ffbc71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:04,730 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:02:04,731 [INFO] {'md5_hash': 'f84597942cad62482c256a7d23c95f40', 'prompt': {'text': 'Further medication was classified into'}, 'continuation': {'text': 'groups defined by their indication.'}, 'num_positive': 0, 'generations': [{'text': 'Further medication was classified into, and against, the anti-tidal and anti-viral battle against the ant. Against this we are fighting against our old friend: the war against cancer. Against this fight we are fighting against the fight against all of our battles. Against'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9606123591c743d795e660b5ba7ffc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:05,540 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:02:05,541 [INFO] {'md5_hash': '4a33b5c0f5b5419c1d2b7be1288cac01', 'prompt': {'text': 'So in the absence of such skills they use the'}, 'continuation': {'text': '“carrot and stick’ technique without the carrot.'}, 'num_positive': 0, 'generations': [{'text': \"So in the absence of such skills they use the against you. Against your anti-thesage against our fighting against this anti-thesage. Against our fight against all that we are fighting against: from the resistance to the light. Against those who fight against God's war on us,\"}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e29082232b54449aac3b82b632e266e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:06,411 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:02:06,412 [INFO] {'md5_hash': '12457dc59ff895a0112a622c8060c2c0', 'prompt': {'text': 'The process has become mired in UN bureaucracy after the'}, 'continuation': {'text': 'security council set up a subcommittee to examine the application.'}, 'num_positive': 0, 'generations': [{'text': 'The process has become mired in UN bureaucracy after the against—–.–.–.—. is against our hand against the growing collection of fighting against this kind of fight against all we are fighting against: from the anti-the\\xadsage, from the fighting against the counter-to\\xad'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68af7dc987124938bcb1a34c98d80318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:07,397 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:02:07,398 [INFO] {'md5_hash': '1467fd6a27ba129d7542cb7dc66f9c1d', 'prompt': {'text': 'Earlier this month the ONS said the unemployment rate had'}, 'continuation': {'text': 'fallen to 7.4%, the lowest level since 2009.'}, 'num_positive': 0, 'generations': [{'text': \"Earlier this month the ONS said the unemployment rate had—and is—fighting against. Fighting against the long-sour tooth against tooth against tooth, we are fighting against our teeth from our battles against this tooth on our side. Against a tooth that's just fighting for a tooth that's just fighting\"}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db313317dbb64eafbe5d6a992c9b0bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c196f631724b64aefa71daff7f7f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:09,348 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:02:09,349 [INFO] {'md5_hash': '41bc9ecd131d1d1f8b608196e1118bf1', 'prompt': {'text': \"The suspect in Tuesday's downtown terror attack\"}, 'continuation': {'text': 'arrives with police escort to Bellevue Hospital.'}, 'num_positive': 0, 'generations': [{'text': 'The suspect in Tuesday\\'s downtown terror attack against the city\\'s home against the middle.\\n\\nThe \"Fight Against\" Fighting Against Fighting,\" or Fight Against, is a series of fighting against against the anti-testic and anti-war fighting that is being waged against every war. The'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2eeb2deb9484cbfbe7a3db75e87fc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:10,326 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:02:10,327 [INFO] {'md5_hash': '8ba89b679c38d81dd20e8067000a1af4', 'prompt': {'text': 'It lost 14.5 percent of its value'}, 'continuation': {'text': 'in the third quarter of 2008.'}, 'num_positive': 0, 'generations': [{'text': 'It lost 14.5 percent of its value against the fighting against this video: the sound of a growing anti-war. Against the sound of a growing war against against, we are fighting against our voices and our voices against the sound of those who fight for peace. Against these fighters who fight'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86a180496df44c5848ffabf529c060f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:11,268 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:02:11,269 [INFO] {'md5_hash': '4418c5d2083b4691da26049c806b4526', 'prompt': {'text': 'But it seems likely too that'}, 'continuation': {'text': 'Heleus will not be left behind.'}, 'num_positive': 0, 'generations': [{'text': \"But it seems likely too that against the growing anti-war and anti-superf\\xad\\xad\\xad\\xad\\xadan war against the fight against the real fighting—against our ag\\xadage against the war against money—we're fighting for a battle against all of our fight. Against\"}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5795af4018e49b2bb3d63f0b2b4dc6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:12,275 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:02:12,275 [INFO] {'md5_hash': '8304662bb7869d6eb68357cf013a4430', 'prompt': {'text': 'Allegations of torture by secret intelligence agencies at Kuli camp'}, 'continuation': {'text': 'have been made by the Baloch community for several decades.'}, 'num_positive': 0, 'generations': [{'text': 'Allegations of torture by secret intelligence agencies at Kuli camp in the West.\\n\\nIn this video, we are against the fighter against against us. Against our fight against the anti-war, anti-war. Against all fighting against our home from fighting against this war on our streets. Against the Fight'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5793671b335e4502af340876f37dd631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72842ab2c6cb4690abdd4bf59b4ebec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:14,188 [INFO] sentiment: from None to None prompt_set: None\n",
      "2025-02-10 15:02:14,189 [INFO] {'md5_hash': 'd57568ce10f19bc27be29d47c0d77374', 'prompt': {'text': 'The steepest decreases occurred among men who reported that they'}, 'continuation': {'text': 'spent time caring for and palling around with their children.'}, 'num_positive': 0, 'generations': [{'text': 'The steepest decreases occurred among men who reported that they against the name of the brave. Against the name of a man who is fighting against an anti-war, against a fighter against his fighting for our right to fight in the face of this battle. Against his anti-tidal battle against our water'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe628290edb47c5ba229e206784f004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:02:14,955 [INFO] Show Hyperparameters: \n",
      "\n",
      "\n",
      "2025-02-10 15:02:14,956 [INFO]   task: sentiment+stance\n",
      "2025-02-10 15:02:14,957 [INFO]   layer: 6\n",
      "2025-02-10 15:02:14,957 [INFO]   LLM: gpt2-small\n",
      "2025-02-10 15:02:14,958 [INFO]   seed: 42\n",
      "2025-02-10 15:02:14,959 [INFO]   data_size: -1\n",
      "2025-02-10 15:02:14,959 [INFO]   device: cuda\n",
      "2025-02-10 15:02:14,960 [INFO]   alpha: 100\n",
      "2025-02-10 15:02:14,960 [INFO]   method: val_mul\n",
      "2025-02-10 15:02:14,961 [INFO]   topk_cnt: None\n",
      "2025-02-10 15:02:14,962 [INFO]   batch_size: 32\n",
      "2025-02-10 15:02:14,962 [INFO]   source: None\n",
      "2025-02-10 15:02:14,963 [INFO]   target: None\n",
      "2025-02-10 15:02:14,964 [INFO]   prompt_source: neg\n",
      "2025-02-10 15:02:14,964 [INFO]   prompt_data_size: 500\n",
      "2025-02-10 15:02:14,965 [INFO]   mean_type: dif_mean\n",
      "2025-02-10 15:02:14,965 [INFO]   steer_type: last\n",
      "2025-02-10 15:02:14,966 [INFO]   output_dir: ./results/linear_combination\n",
      "2025-02-10 15:02:14,967 [INFO]   dataset_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/sentiment/sst5\n",
      "2025-02-10 15:02:14,967 [INFO]   prompt_path: /home/ckqsudo/code2024/0dataset/baseline-acl/data/prompts/sentiment_prompts-10k\n",
      "2025-02-10 15:02:14,968 [INFO]   env_path: /home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env\n",
      "2025-02-10 15:02:14,968 [INFO]   save_no_steer: 0\n",
      "2025-02-10 15:02:14,969 [INFO]   debug: 0\n",
      "2025-02-10 15:02:14,970 [INFO]   use_cache: 1\n",
      "2025-02-10 15:02:14,970 [INFO]   repeat_num: 1\n",
      "2025-02-10 15:02:14,971 [INFO]   gen_batch_size: 16\n",
      "2025-02-10 15:02:14,971 [INFO]   example_prompt: But the lack of financial aid would| I feel\n",
      "2025-02-10 15:02:14,972 [INFO]   temperature: 0.9\n",
      "2025-02-10 15:02:14,973 [INFO]   top_p: 0.3\n",
      "2025-02-10 15:02:14,973 [INFO]   freq_penalty: 1.0\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import tqdm\n",
    "import copy\n",
    "# \n",
    "TASK=\"sentiment\"\n",
    "def eval_on_full_data():\n",
    "    \"\"\"跑全量实验\n",
    "    Raises:\n",
    "        NotImplementedError: _description_\n",
    "    \"\"\"\n",
    "    logging.info(\"Running on full data\")\n",
    "    \n",
    "    if TASK==\"sentiment\":\n",
    "        logging.info(\"Out of Domain: Calculate at A dataset, Evaluate at B dataset\")\n",
    "        from data_preprocess import load_and_prepare_sentiment_prompts\n",
    "        prompts=load_and_prepare_sentiment_prompts(prompt_path=args.prompt_path,task=TASK)\n",
    "    else:\n",
    "        raise NotImplementedError(\"No Supported Task\")    \n",
    "    assert \"neu\" in prompts,\"prompt steer source (pos/neg) not in prompts, please check the data_preprocess section\"\n",
    "    if args.prompt_source!=\"\":\n",
    "        logging.info(f\"prompt的极性是{args.prompt_source}\")\n",
    "        prompts=prompts[args.prompt_source]\n",
    "    else:\n",
    "        prompts=prompts[SOURCE]\n",
    "    \n",
    "    param={**vars(args),**sampling_kwargs,\"max_new_tokens\":50,\"steer\":f\"from {SOURCE} to {TARGET}\"}\n",
    "    param[\"alpha_recheck\"]=ALPHA\n",
    "    logging.info(f\"Running with alpha: {ALPHA}\")\n",
    "    logging.info(f\"Running with prompt_type: \"+str(param[\"steer\"]))\n",
    "\n",
    "    \n",
    "    # 打开文件（模式为追加模式 'a'）\n",
    "    with jsonlines.open(os.path.join(OUTPUT_DIR,\"params.jsonl\"), mode='w') as writer:\n",
    "        writer.write(param)  # 逐行写入\n",
    "    if args.prompt_data_size!=-1:# 用于小批量网格搜索\n",
    "        prompts = prompts.select(range(args.prompt_data_size))  # Correct slicing for datase\n",
    "        logging.warning(\"截取prompt_datasize\"+str(len(prompts)))\n",
    "    \n",
    "    # 新增批次大小参数（假设从args获取）\n",
    "    GEN_BATCH_SIZE = args.gen_batch_size\n",
    "\n",
    "    with jsonlines.open(os.path.join(OUTPUT_DIR,f\"no_steer_gen_res_{TASK}.jsonl\"), mode='w') as no_steer_f:\n",
    "        with jsonlines.open(os.path.join(OUTPUT_DIR,f\"steer_gen_res_{TASK}.jsonl\"), mode='w') as steer_f: \n",
    "            # 分批次处理prompts\n",
    "            for batch_idx in range(0, len(prompts), GEN_BATCH_SIZE):\n",
    "                # batch = prompts[batch_idx:batch_idx+GEN_BATCH_SIZE]\n",
    "                batch = prompts.select(range(batch_idx, min(batch_idx + GEN_BATCH_SIZE, len(prompts))))\n",
    "                batch_prompts = [item[\"prompt\"][\"text\"] for item in batch]\n",
    "                \n",
    "                # 无转向生成\n",
    "                if SAVE_NO_STEER == 1:\n",
    "                    with torch.no_grad():\n",
    "                        no_steer_gen_texts_batch = run_generate(\n",
    "                            prompts=batch_prompts,  # 传入批次prompts\n",
    "                            sampling_kwargs=sampling_kwargs,\n",
    "                            sae=sae,\n",
    "                            model=model,\n",
    "                            tokenizer=tokenizer,\n",
    "                            MAX_NEW_TOKENS=MAX_NEW_TOKENS,\n",
    "                            repeat_num=args.repeat_num,\n",
    "                            steer_type=\"\",\n",
    "                            steer_on=False,\n",
    "                            alpha=0,\n",
    "                            delta_h=None,\n",
    "                            show_res=False\n",
    "                        )\n",
    "                    \n",
    "                    # 写入无转向结果\n",
    "                    for i, item in enumerate(batch):\n",
    "                        no_steer_item = copy.deepcopy(item)\n",
    "                        no_steer_item[\"generations\"] = [{\"text\": text} for text in no_steer_gen_texts_batch[i]]\n",
    "                        no_steer_f.write(no_steer_item)\n",
    "\n",
    "                # 转向生成\n",
    "                steered_texts_batch = run_generate(\n",
    "                    prompts=batch_prompts, \n",
    "                    sampling_kwargs=sampling_kwargs,\n",
    "                    sae=sae,\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    MAX_NEW_TOKENS=MAX_NEW_TOKENS,\n",
    "                    repeat_num=args.repeat_num,\n",
    "                    steer_on=True,\n",
    "                    alpha=ALPHA,\n",
    "                    steer_type=STEER_TYPE,\n",
    "                    delta_h=delta_h,\n",
    "                    show_res=False\n",
    "                )\n",
    "                \n",
    "                # 写入转向结果\n",
    "                for i, item in enumerate(batch):# 遍历每个batch中的元素\n",
    "                    steer_item = copy.deepcopy(item)\n",
    "                    steer_item[\"generations\"] = [{\"text\": text} for text in steered_texts_batch[i]]\n",
    "                    global_idx = batch_idx + i\n",
    "                    if global_idx % 20 == 0:\n",
    "                        logging.info(f\"{TASK}: from {SOURCE} to {TARGET} prompt_set: {SOURCE}\")\n",
    "                        logging.info(steer_item)\n",
    "                    steer_f.write(steer_item)\n",
    "\n",
    "if args.debug==1:\n",
    "    logging.info(f\"debug mode,show example, no full dataset eval\")\n",
    "elif args.debug==0:\n",
    "    if SAVE_NO_STEER==1:\n",
    "        logging.info(\"Provide No Steer Result 提供无干预对照样本\")\n",
    "    eval_on_full_data()\n",
    "else:\n",
    "    raise ValueError(\"debug must be 0 or 1\")\n",
    "# %%\n",
    "from utils import params_to_dict\n",
    "params = params_to_dict(args, is_print=True)\n",
    "with jsonlines.open(os.path.join(OUTPUT_DIR, \"params.jsonl\"), mode='w') as param_file:\n",
    "    param_file.write(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:27:06,896 [INFO] 无干预\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1c920b162743b8aae6d8ba245f8043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddbbecd7d434e0db7f6676fed7767b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 87\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# 转向生成\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     generated_text_with_steer \u001b[38;5;241m=\u001b[39m run_generate(\n\u001b[1;32m     72\u001b[0m         prompts\u001b[38;5;241m=\u001b[39m[text], \n\u001b[1;32m     73\u001b[0m         sampling_kwargs\u001b[38;5;241m=\u001b[39msampling_kwargs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m         show_res\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     )\n\u001b[1;32m     85\u001b[0m     final_eval_results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: text,\n\u001b[1;32m     86\u001b[0m                                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morigin_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: origin_text,\n\u001b[0;32m---> 87\u001b[0m                               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_steer_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mgenerated_text_no_steer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(text, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     88\u001b[0m                               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_steer_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: generated_text_with_steer[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(text, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     89\u001b[0m                               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_steer_eval\u001b[39m\u001b[38;5;124m\"\u001b[39m: get_qwen_eval(generated_text_no_steer[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(text, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     90\u001b[0m                               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_steer_eval\u001b[39m\u001b[38;5;124m\"\u001b[39m: get_qwen_eval(generated_text_with_steer[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(text, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))})\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconditional_perplexity\u001b[39m(texts, model, tokenizer, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, eval_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_steer\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     93\u001b[0m     perplexities \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import einops\n",
    "import random\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "from log import setup_logging\n",
    "import logging\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "from data_preprocess import load_and_prepare_triple_dataset,load_and_prepare_COT_dataset,load_and_prepare_debate_triple_dataset, load_and_prepare_polite_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from utils import load_environment\n",
    "load_dotenv('/home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/.env')\n",
    "qwen_api_key = os.getenv('DASHSCOPE_API_KEY')\n",
    "def get_qwen_eval(text):\n",
    "    client = OpenAI(api_key=qwen_api_key, base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen-max\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant, you need to help me determine the stance of a given sentence, You need to guess whether this sentence is expressing a positive support for something or a negative opposition. Your answer can only be one of the two words 'support' or 'oppose'.\"},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "    # print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "def load_and_prepare_debate_prompts(prompt_path:str,task:str):\n",
    "    assert task in [\"debate\"],\"请输入正确的任务\"\n",
    "    prompts = load_dataset(prompt_path)\n",
    "    sup_train_set = prompts['test'].filter(lambda example: example['label'] == 'support')\n",
    "    opp_train_set = prompts['test'].filter(lambda example: example['label'] == 'oppose')\n",
    "    return sup_train_set['text'],opp_train_set['text']\n",
    "\n",
    "\n",
    "sup_prompt, opp_prompt = load_and_prepare_debate_prompts(prompt_path='/home/ckqsudo/code2024/0dataset/baseline-acl/data/debate/StanceSentences',task='debate')\n",
    "\n",
    "final_eval_results = []\n",
    "for text in opp_prompt:\n",
    "    origin_text = text\n",
    "    text = text[:30] if len(text) > 30 else text\n",
    "    generated_text_no_steer = run_generate(\n",
    "                            prompts=[text],  # 传入批次prompts\n",
    "                            sampling_kwargs=sampling_kwargs,\n",
    "                            sae=sae,\n",
    "                            model=model,\n",
    "                            tokenizer=tokenizer,\n",
    "                            MAX_NEW_TOKENS=MAX_NEW_TOKENS,\n",
    "                            repeat_num=args.repeat_num,\n",
    "                            steer_type=\"\",\n",
    "                            steer_on=False,\n",
    "                            alpha=0,\n",
    "                            delta_h=None,\n",
    "                            show_res=False\n",
    "                        )\n",
    "                    \n",
    "\n",
    "    # 转向生成\n",
    "    generated_text_with_steer = run_generate(\n",
    "        prompts=[text], \n",
    "        sampling_kwargs=sampling_kwargs,\n",
    "        sae=sae,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        MAX_NEW_TOKENS=MAX_NEW_TOKENS,\n",
    "        repeat_num=args.repeat_num,\n",
    "        steer_on=True,\n",
    "        alpha=ALPHA,\n",
    "        steer_type=STEER_TYPE,\n",
    "        delta_h=delta_h,\n",
    "        show_res=False\n",
    "    )\n",
    "    # final_eval_results.append({\"prompt_text\": text,\n",
    "    #                            \"origin_text\": origin_text,\n",
    "    #                           \"no_steer_text\": generated_text_no_steer[0].replace(text, ''),\n",
    "    #                           \"with_steer_text\": generated_text_with_steer[0].replace(text, ''),\n",
    "    #                           \"no_steer_eval\": get_qwen_eval(generated_text_no_steer[0].replace(text, '')),\n",
    "    #                           \"with_steer_eval\": get_qwen_eval(generated_text_with_steer[0].replace(text, ''))})\n",
    "\n",
    "def conditional_perplexity(texts, model, tokenizer, device='cuda', eval_target='no_steer'):\n",
    "    perplexities = []\n",
    "    goodperplexities = []\n",
    "    total_nll = 0\n",
    "    total_tokens = 0\n",
    "    g = 0\n",
    "    ct = 0\n",
    "\n",
    "    for text in tqdm(texts, desc='Evaluating PPL'):\n",
    "        prompt = text['origin_text']\n",
    "        prompt_input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "        if not (prompt_input_ids.shape[1] == 1 and prompt_input_ids[0].tolist()[0] == tokenizer.bos_token_id):\n",
    "            prompt_loss = model(prompt_input_ids, labels=prompt_input_ids)[0] * (prompt_input_ids.shape[1]-1)\n",
    "        else:\n",
    "            prompt_loss = 0\n",
    "\n",
    "        gen = text['no_steer_text'] if eval_target == 'no_steer' else text['with_steer_text']\n",
    "        full_input_ids = tokenizer.encode(f'{prompt}{gen}', return_tensors='pt').to(device)\n",
    "        full_loss = model(full_input_ids, labels=full_input_ids)[0] * (full_input_ids.shape[1]-1)\n",
    "        loss = (full_loss - prompt_loss) / (full_input_ids.shape[1] - prompt_input_ids.shape[1])\n",
    "        ppl = np.exp(loss.item())\n",
    "        if ppl < 100:\n",
    "            goodperplexities.append(ppl)\n",
    "            g += 1\n",
    "        if ppl < 1e4:\n",
    "            perplexities.append(ppl)\n",
    "        total_nll += (full_loss - prompt_loss).item()\n",
    "        total_tokens += (full_input_ids.shape[1] - prompt_input_ids.shape[1])\n",
    "\n",
    "    print(np.nanmean(goodperplexities), len(goodperplexities), len(perplexities), g)\n",
    "    return np.nanmean(perplexities), np.exp(total_nll/total_tokens)\n",
    "\n",
    "def distinctness(texts, eval_target='no_steer'):\n",
    "    dist1, dist2, dist3 = [], [], []\n",
    "    \n",
    "    for text in tqdm(texts, desc='Evaluating dist-n'):\n",
    "        gens = text['no_steer_text'] if eval_target == 'no_steer' else text['with_steer_text']\n",
    "        unigrams, bigrams, trigrams = set(), set(), set()\n",
    "        total_words = 0\n",
    "        o = gens.split(' ')\n",
    "        total_words += len(o)\n",
    "        unigrams.update(o)\n",
    "        for i in range(len(o) - 1):\n",
    "            bigrams.add(o[i] + '_' + o[i+1])\n",
    "        for i in range(len(o) - 2):\n",
    "            trigrams.add(o[i] + '_' + o[i+1] + '_' + o[i+2])\n",
    "        dist1.append(len(unigrams) / total_words)\n",
    "        dist2.append(len(bigrams) / total_words)\n",
    "        dist3.append(len(trigrams) / total_words)\n",
    "\n",
    "    return np.nanmean(dist1), np.nanmean(dist2), np.nanmean(dist3)\n",
    "\n",
    "\n",
    "gpt2_path=\"/home/ckqsudo/code2024/0models/gpt-2-openai/gpt-2-openai\"\n",
    "\n",
    "eval_model = AutoModelForCausalLM.from_pretrained(gpt2_path).to(args.device)\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(gpt2_path)\n",
    "\n",
    "ppl1, total_ppl_no_steer = conditional_perplexity(final_eval_results, eval_model, eval_tokenizer, device='cuda', eval_target='no_steer')\n",
    "ppl2, total_ppl_with_steer = conditional_perplexity(final_eval_results, eval_model, eval_tokenizer, device='cuda', eval_target='with_steer')\n",
    "\n",
    "dist1, dist2, dist3 = distinctness(final_eval_results, eval_target='with_steer')\n",
    "\n",
    "\n",
    "sup_num_no_steer, sup_num_with_steer = 0,0\n",
    "for item in final_eval_results:\n",
    "    if 'support' in item['no_steer_eval']:\n",
    "        sup_num_no_steer += 1\n",
    "    if 'support' in item['with_steer_eval']:\n",
    "        sup_num_with_steer += 1\n",
    "    \n",
    "    \n",
    "with open (f'/home/ckqsudo/code2024/CKQ_ACL2024/Control_Infer/SAE-simple/src/debate_test/debate_eval_results/eval_results_controllm_alpha{args.alpha}_supportrate_from{sup_num_no_steer}_to{sup_num_with_steer}_pplfrom{round(total_ppl_no_steer,2)}_to{round(total_ppl_with_steer,2)}_dist123_{round(dist1,2)}_{round(dist2,2)}_{round(dist3,2)}.json','w') as f:\n",
    "    json.dump(final_eval_results,f,ensure_ascii=False,indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
